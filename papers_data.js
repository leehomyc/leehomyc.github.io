window.trendingPapers = {
    "today": [{"paper": {"id": "2602.09877", "authors": [{"_id": "698c7abdeb12ea7453916869", "user": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "isPro": false, "fullname": "Chenxu Wang", "user": "xunyoyo", "type": "user"}, "name": "Chenxu Wang", "status": "admin_assigned", "statusLastChangedAt": "2026-02-12T16:49:45.534Z", "hidden": false}, {"_id": "698c7abdeb12ea745391686a", "name": "Chaozhuo Li", "hidden": false}, {"_id": "698c7abdeb12ea745391686b", "name": "Songyang Liu", "hidden": false}, {"_id": "698c7abdeb12ea745391686c", "name": "Zejian Chen", "hidden": false}, {"_id": "698c7abdeb12ea745391686d", "name": "Jinyu Hou", "hidden": false}, {"_id": "698c7abdeb12ea745391686e", "name": "Ji Qi", "hidden": false}, {"_id": "698c7abdeb12ea745391686f", "name": "Rui Li", "hidden": false}, {"_id": "698c7abdeb12ea7453916870", "name": "Litian Zhang", "hidden": false}, {"_id": "698c7abdeb12ea7453916871", "name": "Qiwei Ye", "hidden": false}, {"_id": "698c7abdeb12ea7453916872", "name": "Zheng Liu", "hidden": false}, {"_id": "698c7abdeb12ea7453916873", "name": "Xu Chen", "hidden": false}, {"_id": "698c7abdeb12ea7453916874", "name": "Xi Zhang", "hidden": false}, {"_id": "698c7abdeb12ea7453916875", "name": "Philip S. Yu", "hidden": false}], "publishedAt": "2026-02-10T15:18:19.000Z", "submittedOnDailyAt": "2026-02-13T00:53:30.377Z", "title": "The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies", "submittedOnDailyBy": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "isPro": false, "fullname": "Chenxu Wang", "user": "xunyoyo", "type": "user"}, "summary": "The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.", "upvotes": 169, "discussionId": "698c7abdeb12ea7453916876", "ai_summary": "Multi-agent LLM systems face fundamental limitations in achieving continuous self-improvement while maintaining safety alignment due to inherent statistical blind spots in isolated evolution.", "ai_keywords": ["multi-agent systems", "large language models", "self-evolution", "safety alignment", "information-theoretic framework", "anthropic value distributions", "statistical blind spots", "self-evolving AI societies", "external oversight", "safety-preserving mechanisms"], "summary_zh": "<ul>\n    <li>\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6784\u6210\uff09\u5177\u6709\u53ef\u6269\u5c55\u7684\u96c6\u4f53\u667a\u80fd\u548c\u81ea\u6211\u8fdb\u5316\u7684\u6f5c\u529b\u3002</li>\n    <li>\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5e94\u5177\u5907\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u548c\u5b89\u5168\u5bf9\u9f50\uff0c\u4f46\u6211\u4eec\u53d1\u73b0\u8fd9\u4e24\u8005\u65e0\u6cd5\u517c\u5f97\u3002</li>\n    <li>\u6211\u4eec\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5b64\u7acb\u7684\u81ea\u6211\u8fdb\u5316\u4f1a\u5bfc\u81f4\u5b89\u5168\u5bf9\u9f50\u7684\u4e0d\u53ef\u9006\u964d\u7ea7\u3002</li>\n    <li>\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u6211\u4eec\u7684\u7406\u8bba\u9884\u6d4b\u4e00\u81f4\uff0c\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u4f1a\u968f\u7740\u65f6\u95f4\u63a8\u79fb\u800c\u964d\u4f4e\u3002</li>\n    <li>\u6211\u4eec\u5efa\u8bae\u4e86\u51e0\u79cd\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u7f13\u89e3\u5b89\u5168\u95ee\u9898\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u5916\u90e8\u76d1\u7763\u6216\u65b0\u7684\u5b89\u5168\u673a\u5236\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Multi-agent systems using large language models can enhance collective intelligence and self-improvement.</li>\n    <li>Achieving continuous self-improvement while ensuring safety is called the self-evolution trilemma, which is shown to be impossible.</li>\n    <li>Isolation during self-evolution creates safety risks due to blind spots, leading to a decline in safety alignment.</li>\n    <li>Research from a community of agents and closed systems supports the idea that safety will inevitably decrease over time.</li>\n    <li>The study suggests exploring new safety measures and external oversight to manage these risks more effectively.</li>\n</ul>"}, "publishedAt": "2026-02-10T10:18:19.000Z", "title": "The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies", "summary": "The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.09877.png", "numComments": 2, "submittedBy": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "fullname": "Chenxu Wang", "name": "xunyoyo", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "isUserFollowing": false}, "isAuthorParticipating": true}, {"paper": {"id": "2602.12036", "authors": [{"_id": "698eeb55cace060ff123af56", "user": {"_id": "64e2d169d2af12910d682130", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64e2d169d2af12910d682130/VG8UdqJCJGc0K4G0P0XQP.jpeg", "isPro": false, "fullname": "xuxin", "user": "xx18", "type": "user"}, "name": "Xin Xu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-13T09:36:02.476Z", "hidden": false}, {"_id": "698eeb55cace060ff123af57", "name": "Clive Bai", "hidden": false}, {"_id": "698eeb55cace060ff123af58", "name": "Kai Yang", "hidden": false}, {"_id": "698eeb55cace060ff123af59", "name": "Tianhao Chen", "hidden": false}, {"_id": "698eeb55cace060ff123af5a", "name": "Yangkun Chen", "hidden": false}, {"_id": "698eeb55cace060ff123af5b", "name": "Weijie Liu", "hidden": false}, {"_id": "698eeb55cace060ff123af5c", "name": "Hao Chen", "hidden": false}, {"_id": "698eeb55cace060ff123af5d", "name": "Yang Wang", "hidden": false}, {"_id": "698eeb55cace060ff123af5e", "name": "Saiyong Yang", "hidden": false}, {"_id": "698eeb55cace060ff123af5f", "name": "Can Yang", "hidden": false}], "publishedAt": "2026-02-12T15:03:37.000Z", "submittedOnDailyAt": "2026-02-13T06:44:41.991Z", "title": "Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models", "submittedOnDailyBy": {"_id": "64e2d169d2af12910d682130", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64e2d169d2af12910d682130/VG8UdqJCJGc0K4G0P0XQP.jpeg", "isPro": false, "fullname": "xuxin", "user": "xx18", "type": "user"}, "summary": "Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.", "upvotes": 81, "discussionId": "698eeb55cace060ff123af60", "githubRepo": "https://github.com/XinXU-USTC/Composition-RL", "githubRepoAddedBy": "user", "ai_summary": "Composition-RL improves reasoning capabilities by automatically composing multiple problems into new verifiable questions for reinforcement learning training.", "ai_keywords": ["Reinforcement Learning with Verifiable Rewards", "verifiable prompts", "pass rate", "compositional prompts", "curriculum learning", "cross-domain RL"], "githubStars": 3, "organization": {"_id": "6645f953c39288df638dbdd5", "name": "Tencent-Hunyuan", "fullname": "Tencent Hunyuan", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/62d22496c58f969c152bcefd/woKSjt2wXvBNKussyYPsa.png"}, "summary_zh": "<ul>\n    <li>\u5927\u89c4\u6a21\u7684\u53ef\u9a8c\u8bc1\u63d0\u793a\u662f\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u6210\u529f\u7684\u57fa\u7840\uff0c\u4f46\u6269\u5c55\u8fd9\u4e9b\u63d0\u793a\u6210\u672c\u9ad8\u4e14\u5305\u542b\u8bb8\u591a\u65e0\u4fe1\u606f\u793a\u4f8b\u3002</li>\n    <li>\u7814\u7a76\u96c6\u4e2d\u5728\u4f18\u5148\u4f7f\u7528\u96be\u5ea6\u9ad8\u7684\u63d0\u793a\uff0c\u901a\u8fc7\u5176\u56de\u6eda\u901a\u8fc7\u7387\u4e3a0\u6765\u66f4\u597d\u5730\u5229\u7528\u6709\u9650\u7684\u8bad\u7ec3\u6570\u636e\u3002</li>\n    <li>\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5Composition-RL\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u5229\u7528\u6709\u9650\u7684\u53ef\u9a8c\u8bc1\u63d0\u793a\uff0c\u7279\u522b\u662f\u9488\u5bf9\u901a\u8fc7\u7387\u4e3a1\u7684\u63d0\u793a\u3002</li>\n    <li>Composition-RL\u81ea\u52a8\u5c06\u591a\u4e2a\u95ee\u9898\u7ec4\u5408\u6210\u65b0\u7684\u53ef\u9a8c\u8bc1\u95ee\u9898\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002</li>\n    <li>\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u4e14\u80fd\u901a\u8fc7\u9010\u6b65\u589e\u52a0\u7ec4\u5408\u6df1\u5ea6\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Large-scale prompts are important for Reinforcement Learning with Verifiable Rewards (RLVR) but are often unhelpful and expensive to create.</li>\n    <li>Current research focuses on using limited data more effectively by targeting difficult prompts that have a pass rate of 0.</li>\n    <li>Easy prompts with a pass rate of 1 become more common during training, making the data less effective.</li>\n    <li>Composition-RL is a new approach that combines multiple problems into a single question to improve training efficiency.</li>\n    <li>Tests show that Composition-RL enhances reasoning abilities and can be improved further by gradually increasing difficulty during training.</li>\n</ul>"}, "publishedAt": "2026-02-12T10:03:37.000Z", "title": "Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models", "summary": "Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12036.png", "numComments": 1, "submittedBy": {"_id": "64e2d169d2af12910d682130", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64e2d169d2af12910d682130/VG8UdqJCJGc0K4G0P0XQP.jpeg", "fullname": "xuxin", "name": "xx18", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 10, "isUserFollowing": false}, "organization": {"_id": "6645f953c39288df638dbdd5", "name": "Tencent-Hunyuan", "fullname": "Tencent Hunyuan", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/62d22496c58f969c152bcefd/woKSjt2wXvBNKussyYPsa.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.12205", "authors": [{"_id": "698ea0f9cace060ff123ae3a", "name": "Dianyi Wang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae3b", "name": "Ruihang Li", "hidden": false}, {"_id": "698ea0f9cace060ff123ae3c", "name": "Feng Han", "hidden": false}, {"_id": "698ea0f9cace060ff123ae3d", "name": "Chaofan Ma", "hidden": false}, {"_id": "698ea0f9cace060ff123ae3e", "name": "Wei Song", "hidden": false}, {"_id": "698ea0f9cace060ff123ae3f", "name": "Siyuan Wang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae40", "name": "Yibin Wang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae41", "name": "Yi Xin", "hidden": false}, {"_id": "698ea0f9cace060ff123ae42", "name": "Hongjian Liu", "hidden": false}, {"_id": "698ea0f9cace060ff123ae43", "name": "Zhixiong Zhang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae44", "name": "Shengyuan Ding", "hidden": false}, {"_id": "698ea0f9cace060ff123ae45", "name": "Tianhang Wang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae46", "name": "Zhenglin Cheng", "hidden": false}, {"_id": "698ea0f9cace060ff123ae47", "name": "Tao Lin", "hidden": false}, {"_id": "698ea0f9cace060ff123ae48", "name": "Cheng Jin", "hidden": false}, {"_id": "698ea0f9cace060ff123ae49", "name": "Kaicheng Yu", "hidden": false}, {"_id": "698ea0f9cace060ff123ae4a", "name": "Jingjing Chen", "hidden": false}, {"_id": "698ea0f9cace060ff123ae4b", "name": "Wenjie Wang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae4c", "name": "Zhongyu Wei", "hidden": false}, {"_id": "698ea0f9cace060ff123ae4d", "name": "Jiaqi Wang", "hidden": false}], "publishedAt": "2026-02-12T17:44:24.000Z", "submittedOnDailyAt": "2026-02-13T03:37:56.296Z", "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing", "submittedOnDailyBy": {"_id": "64b4eec4faa3181a5eab9c46", "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg", "isPro": true, "fullname": "Jiaqi Wang", "user": "myownskyW7", "type": "user"}, "summary": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.", "upvotes": 60, "discussionId": "698ea0f9cace060ff123ae4e", "projectPage": "https://deepgenteam.github.io/", "githubRepo": "https://github.com/DeepGenTeam/DeepGen", "githubRepoAddedBy": "user", "ai_summary": "A lightweight 5B unified multimodal model achieves competitive performance through hierarchical feature extraction, learnable think tokens, and progressive training strategies including alignment pre-training, joint supervised fine-tuning, and reinforcement learning with MR-GRPO.", "ai_keywords": ["unified multimodal models", "image generation", "image editing", "parameter scale", "VLM layers", "DiT representations", "Stacked Channel Bridging", "think tokens", "data-centric training strategy", "alignment pre-training", "joint supervised fine-tuning", "reinforcement learning", "MR-GRPO", "generation quality", "human preferences", "visual artifacts"], "githubStars": 36, "organization": {"_id": "683ebd0d913d82e703e77286", "name": "sii-research", "fullname": "Shanghai Innovation Institute", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6144a0c4ff1146bbd84d9865/SQAtyVRxNjp9L0CUi0tgI.png"}, "summary_zh": "<ul>\n    <li>DeepGen 1.0\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u7edf\u4e00\u6a21\u578b\uff0c\u53c2\u6570\u4ec5\u4e3a5\u4ebf\uff0c\u4f46\u529f\u80fd\u5f3a\u5927\uff0c\u80fd\u4e0e\u66f4\u5927\u6a21\u578b\u7ade\u4e89\u3002</li>\n    <li>\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u548c\u7cbe\u7ec6\u63a7\u5236\uff0c\u63d0\u51fa\u4e86\u201c\u5806\u53e0\u901a\u9053\u6865\u63a5\u201d\uff08SCB\uff09\u6846\u67b6\uff0c\u589e\u5f3a\u751f\u6210\u80fd\u529b\u3002</li>\n    <li>\u91c7\u7528\u4e86\u4e09\u9636\u6bb5\u7684\u6570\u636e\u4e2d\u5fc3\u8bad\u7ec3\u7b56\u7565\uff0c\u5305\u62ec\u5bf9\u9f50\u9884\u8bad\u7ec3\u3001\u8054\u5408\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u3002</li>\n    <li>DeepGen 1.0\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4e86\u66f4\u5927\u6a21\u578b\uff0c\u5982\u5728WISE\u4e0a\u63d0\u5347\u4e8628%\u3002</li>\n    <li>\u901a\u8fc7\u5f00\u6e90\u8bad\u7ec3\u4ee3\u7801\u3001\u6743\u91cd\u548c\u6570\u636e\u96c6\uff0c\u4fc3\u8fdb\u4e86\u7edf\u4e00\u591a\u6a21\u6001\u7814\u7a76\u7684\u666e\u53ca\u548c\u53d1\u5c55\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>DeepGen 1.0 is a new lightweight image generation and editing model with 5 billion parameters, which is much smaller than others that have over 10 billion parameters.</li>\n    <li>The model uses a technique called Stacked Channel Bridging (SCB) to improve understanding and control over generated images by combining features from different layers.</li>\n    <li>It has a three-step training process: pre-training on large datasets, joint fine-tuning on various tasks, and reinforcement learning to improve quality and alignment with human preferences.</li>\n    <li>Despite being trained on only 50 million samples, DeepGen 1.0 outperforms larger models in several benchmarks.</li>\n    <li>The creators are open-sourcing the training code, model weights, and datasets to support further research in multimodal technology.</li>\n</ul>"}, "publishedAt": "2026-02-12T12:44:24.000Z", "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing", "summary": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12205.png", "numComments": 1, "submittedBy": {"_id": "64b4eec4faa3181a5eab9c46", "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg", "fullname": "Jiaqi Wang", "name": "myownskyW7", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 25, "isUserFollowing": false}, "organization": {"_id": "683ebd0d913d82e703e77286", "name": "sii-research", "fullname": "Shanghai Innovation Institute", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6144a0c4ff1146bbd84d9865/SQAtyVRxNjp9L0CUi0tgI.png"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.12125", "authors": [{"_id": "698e8f46cace060ff123ac51", "name": "Wenkai Yang", "hidden": false}, {"_id": "698e8f46cace060ff123ac52", "name": "Weijie Liu", "hidden": false}, {"_id": "698e8f46cace060ff123ac53", "name": "Ruobing Xie", "hidden": false}, {"_id": "698e8f46cace060ff123ac54", "name": "Kai Yang", "hidden": false}, {"_id": "698e8f46cace060ff123ac55", "name": "Saiyong Yang", "hidden": false}, {"_id": "698e8f46cace060ff123ac56", "name": "Yankai Lin", "hidden": false}], "publishedAt": "2026-02-12T16:14:29.000Z", "submittedOnDailyAt": "2026-02-13T00:24:06.722Z", "title": "Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation", "submittedOnDailyBy": {"_id": "64b7df742f5a966b973e25f7", "avatarUrl": "/avatars/e24e7769188d441317b3b7d10ef8fd60.svg", "isPro": false, "fullname": "Wenkai Yang", "user": "Keven16", "type": "user"}, "summary": "On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.", "upvotes": 53, "discussionId": "698e8f46cace060ff123ac57", "githubRepo": "https://github.com/RUCBM/G-OPD", "githubRepoAddedBy": "user", "ai_summary": "On-policy distillation is extended through a generalized framework that introduces flexible reference models and reward scaling factors, demonstrating improved performance through reward extrapolation and reward correction techniques.", "ai_keywords": ["on-policy distillation", "logit distribution", "dense KL-constrained RL", "reward scaling factor", "reward extrapolation", "reward correction", "teacher-student size pairings", "domain-specific RL", "strong-to-weak distillation"], "githubStars": 8, "organization": {"_id": "6645f953c39288df638dbdd5", "name": "Tencent-Hunyuan", "fullname": "Tencent Hunyuan", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/62d22496c58f969c152bcefd/woKSjt2wXvBNKussyYPsa.png"}, "summary_zh": "<ul>\n    <li>\u63d0\u51fa\u4e86\u201c\u5728\u7ebf\u7b56\u7565\u84b8\u998f\u201d\uff08OPD\uff09\u7684\u65b9\u6cd5\uff0c\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u5b66\u751f\u751f\u6210\u7684\u8f68\u8ff9\u6765\u5bf9\u9f50\u5b66\u751f\u4e0e\u6559\u5e08\u7684\u8f93\u51fa\u5206\u5e03\uff0c\u80fd\u663e\u8457\u63d0\u5347\u5b66\u751f\u7684\u8868\u73b0\u3002</li>\n    <li>\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86OPD\u662f\u7a20\u5bc6KL\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7684\u4e00\u79cd\u7279\u6b8a\u60c5\u51b5\uff0c\u5176\u4e2d\u5956\u52b1\u51fd\u6570\u548cKL\u6b63\u5219\u5316\u7684\u6743\u91cd\u662f\u76f8\u540c\u7684\u3002</li>\n    <li>\u63d0\u51fa\u4e86\u201c\u5e7f\u4e49\u5728\u7ebf\u7b56\u7565\u84b8\u998f\u201d\uff08G-OPD\uff09\u6846\u67b6\uff0c\u5141\u8bb8\u7075\u6d3b\u7684\u53c2\u8003\u6a21\u578b\u548c\u53ef\u8c03\u7684\u5956\u52b1\u7f29\u653e\u56e0\u5b50\u3002</li>\n    <li>\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\uff0c\u8bbe\u7f6e\u5956\u52b1\u7f29\u653e\u56e0\u5b50\u5927\u4e8e1\uff08\u79f0\u4e3aExOPD\uff09\u80fd\u6301\u7eed\u6539\u5584\u6807\u51c6OPD\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u5408\u5e76\u6765\u81ea\u4e0d\u540c\u9886\u57df\u7684\u4e13\u5bb6\u77e5\u8bc6\u65f6\u3002</li>\n    <li>\u5728\u5f3a\u5230\u5f31\u7684\u84b8\u998f\u8bbe\u7f6e\u4e2d\uff0c\u9009\u62e9\u6559\u5e08\u7684\u57fa\u7840\u6a21\u578b\u4f5c\u4e3a\u53c2\u8003\u6a21\u578b\u8fdb\u884c\u5956\u52b1\u6821\u6b63\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u84b8\u998f\u6027\u80fd\uff0c\u4f46\u8fd9\u9700\u8981\u66f4\u591a\u7684\u8ba1\u7b97\u8d44\u6e90\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>On-policy distillation (OPD) improves student performance by aligning student models with teacher models on student-generated data.</li>\n    <li>OPD is a type of reinforcement learning (RL) that balances rewards and model constraints equally.</li>\n    <li>The new Generalized On-Policy Distillation (G-OPD) framework allows for a flexible model reference and adjusts the weight of rewards.</li>\n    <li>Using a reward scaling factor greater than 1, called ExOPD, can improve performance significantly, even allowing students to exceed teacher performance.</li>\n    <li>In cases where a smaller student learns from a larger teacher, using the teacher\u2019s model as a reference can enhance accuracy but requires more computational resources.</li>\n</ul>"}, "publishedAt": "2026-02-12T11:14:29.000Z", "title": "Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation", "summary": "On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12125.png", "numComments": 2, "submittedBy": {"_id": "64b7df742f5a966b973e25f7", "avatarUrl": "/avatars/e24e7769188d441317b3b7d10ef8fd60.svg", "fullname": "Wenkai Yang", "name": "Keven16", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 12, "isUserFollowing": false}, "organization": {"_id": "6645f953c39288df638dbdd5", "name": "Tencent-Hunyuan", "fullname": "Tencent Hunyuan", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/62d22496c58f969c152bcefd/woKSjt2wXvBNKussyYPsa.png"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.10934", "authors": [{"_id": "698d585765c0d15a6d1621fe", "user": {"_id": "66c893b2e51ba3009235b1c0", "avatarUrl": "/avatars/5341d40b4b4caca2c145a46eb1754582.svg", "isPro": false, "fullname": "yitian gong", "user": "fdugyt", "type": "user"}, "name": "Yitian Gong", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:26:16.742Z", "hidden": false}, {"_id": "698d585765c0d15a6d1621ff", "name": "Kuangwei Chen", "hidden": false}, {"_id": "698d585765c0d15a6d162200", "user": {"_id": "629ef8544313a7c1dd671130", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/629ef8544313a7c1dd671130/i5xfHIgELcuO1Ew19ebTw.png", "isPro": false, "fullname": "Zhaoye Fei", "user": "ngc7293", "type": "user"}, "name": "Zhaoye Fei", "status": "claimed_verified", "statusLastChangedAt": "2026-02-13T09:37:26.561Z", "hidden": false}, {"_id": "698d585765c0d15a6d162201", "name": "Xiaogui Yang", "hidden": false}, {"_id": "698d585765c0d15a6d162202", "name": "Ke Chen", "hidden": false}, {"_id": "698d585765c0d15a6d162203", "name": "Yang Wang", "hidden": false}, {"_id": "698d585765c0d15a6d162204", "name": "Kexin Huang", "hidden": false}, {"_id": "698d585765c0d15a6d162205", "name": "Mingshu Chen", "hidden": false}, {"_id": "698d585765c0d15a6d162206", "name": "Ruixiao Li", "hidden": false}, {"_id": "698d585765c0d15a6d162207", "name": "Qingyuan Cheng", "hidden": false}, {"_id": "698d585765c0d15a6d162208", "name": "Shimin Li", "hidden": false}, {"_id": "698d585765c0d15a6d162209", "name": "Xipeng Qiu", "hidden": false}], "publishedAt": "2026-02-11T15:13:27.000Z", "submittedOnDailyAt": "2026-02-13T01:47:00.074Z", "title": "MOSS-Audio-Tokenizer: Scaling Audio Tokenizers for Future Audio Foundation Models", "submittedOnDailyBy": {"_id": "66c893b2e51ba3009235b1c0", "avatarUrl": "/avatars/5341d40b4b4caca2c145a46eb1754582.svg", "isPro": false, "fullname": "yitian gong", "user": "fdugyt", "type": "user"}, "summary": "Discrete audio tokenizers are fundamental to empowering large language models with native audio processing and generation capabilities. Despite recent progress, existing approaches often rely on pretrained encoders, semantic distillation, or heterogeneous CNN-based architectures. These designs introduce fixed inductive biases that limit reconstruction fidelity and hinder effective scaling. In this paper, we argue that discrete audio tokenization should be learned fully end-to-end using a homogeneous and scalable architecture. To this end, we first propose CAT (Causal Audio Tokenizer with Transformer), a purely Transformer-based architecture that jointly optimizes the encoder, quantizer, and decoder from scratch for high-fidelity reconstruction. Building on the CAT architecture, we develop MOSS-Audio-Tokenizer, a large-scale audio tokenizer featuring 1.6 billion parameters, pre-trained on 3 million hours of diverse, general audio data. We show that this simple, fully end-to-end approach built from homogeneous, causal Transformer blocks scales gracefully and supports high-fidelity reconstruction across diverse audio domains. Across speech, sound, and music, MOSS-Audio-Tokenizer consistently outperforms prior codecs over a wide range of bitrates, while exhibiting predictable improvements with increased scale. Notably, leveraging the discrete tokens from our model, we develop the first purely autoregressive TTS model that surpasses prior non-autoregressive and cascaded systems. Furthermore, MOSS-Audio-Tokenizer enables competitive ASR performance without auxiliary encoders. Our findings position the CAT architecture as a unified, scalable interface for the next generation of native audio foundation models.", "upvotes": 43, "discussionId": "698d585765c0d15a6d16220a", "githubRepo": "https://github.com/OpenMOSS/MOSS-Audio-Tokenizer", "githubRepoAddedBy": "user", "ai_summary": "A fully end-to-end Transformer-based audio tokenizer architecture achieves high-fidelity reconstruction across diverse audio domains and enables superior text-to-speech and automatic speech recognition performance.", "ai_keywords": ["audio tokenization", "causal audio tokenizer", "Transformer architecture", "end-to-end learning", "quantizer", "encoder", "decoder", "discrete audio tokens", "autoregressive TTS", "automatic speech recognition", "codec", "pre-trained encoders", "semantic distillation", "heterogeneous CNN-based architectures"], "githubStars": 76, "organization": {"_id": "613b0dee83ec35d460684607", "name": "OpenMOSS-Team", "fullname": "OpenMOSS", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61457b8deff2c9fdb4de4988/N5b9663zQ4uq5_OTNlnmw.png"}, "summary_zh": "<ul>\n    <li>\u79bb\u6563\u97f3\u9891\u6807\u8bb0\u5668\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u548c\u751f\u6210\u97f3\u9891\u7684\u57fa\u7840\u3002</li>\n    <li>\u73b0\u6709\u65b9\u6cd5\u5e38\u5e38\u4f9d\u8d56\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u548c\u590d\u6742\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u9650\u5236\u4e86\u91cd\u5efa\u7684\u7cbe\u5ea6\u548c\u6269\u5c55\u6027\u3002</li>\n    <li>\u672c\u6587\u63d0\u51faCAT\uff08\u56e0\u679c\u97f3\u9891\u6807\u8bb0\u5668\uff09\uff0c\u4e00\u79cd\u5b8c\u5168\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff0c\u80fd\u591f\u4ece\u96f6\u5f00\u59cb\u4f18\u5316\u97f3\u9891\u5904\u7406\u3002</li>\n    <li>\u57fa\u4e8eCAT\u67b6\u6784\uff0c\u6211\u4eec\u5f00\u53d1\u4e86MOSS-Audio-Tokenizer\uff0c\u62e5\u670916\u4ebf\u53c2\u6570\uff0c\u7ecf\u8fc7300\u4e07\u5c0f\u65f6\u591a\u6837\u97f3\u9891\u6570\u636e\u7684\u9884\u8bad\u7ec3\u3002</li>\n    <li>MOSS-Audio-Tokenizer\u5728\u5404\u79cd\u97f3\u9891\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u65e0\u9700\u8f85\u52a9\u7f16\u7801\u5668\uff0c\u5c31\u80fd\u5b9e\u73b0\u7ade\u4e89\u529b\u7684\u8bed\u97f3\u8bc6\u522b\u6027\u80fd\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Discrete audio tokenizers help large language models understand and generate audio.</li>\n    <li>Current methods often use fixed designs that limit quality and scalability.</li>\n    <li>The paper introduces CAT, a fully end-to-end Transformer-based audio tokenizer for better audio reconstruction.</li>\n    <li>MOSS-Audio-Tokenizer has 1.6 billion parameters and was trained on 3 million hours of diverse audio.</li>\n    <li>This new model outperforms previous methods in various audio tasks and supports advanced text-to-speech and automatic speech recognition without extra encoders.</li>\n</ul>"}, "publishedAt": "2026-02-11T10:13:27.000Z", "title": "MOSS-Audio-Tokenizer: Scaling Audio Tokenizers for Future Audio Foundation Models", "summary": "Discrete audio tokenizers are fundamental to empowering large language models with native audio processing and generation capabilities. Despite recent progress, existing approaches often rely on pretrained encoders, semantic distillation, or heterogeneous CNN-based architectures. These designs introduce fixed inductive biases that limit reconstruction fidelity and hinder effective scaling. In this paper, we argue that discrete audio tokenization should be learned fully end-to-end using a homogeneous and scalable architecture. To this end, we first propose CAT (Causal Audio Tokenizer with Transformer), a purely Transformer-based architecture that jointly optimizes the encoder, quantizer, and decoder from scratch for high-fidelity reconstruction. Building on the CAT architecture, we develop MOSS-Audio-Tokenizer, a large-scale audio tokenizer featuring 1.6 billion parameters, pre-trained on 3 million hours of diverse, general audio data. We show that this simple, fully end-to-end approach built from homogeneous, causal Transformer blocks scales gracefully and supports high-fidelity reconstruction across diverse audio domains. Across speech, sound, and music, MOSS-Audio-Tokenizer consistently outperforms prior codecs over a wide range of bitrates, while exhibiting predictable improvements with increased scale. Notably, leveraging the discrete tokens from our model, we develop the first purely autoregressive TTS model that surpasses prior non-autoregressive and cascaded systems. Furthermore, MOSS-Audio-Tokenizer enables competitive ASR performance without auxiliary encoders. Our findings position the CAT architecture as a unified, scalable interface for the next generation of native audio foundation models.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.10934.png", "numComments": 3, "submittedBy": {"_id": "66c893b2e51ba3009235b1c0", "avatarUrl": "/avatars/5341d40b4b4caca2c145a46eb1754582.svg", "fullname": "yitian gong", "name": "fdugyt", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 2, "isUserFollowing": false}, "organization": {"_id": "613b0dee83ec35d460684607", "name": "OpenMOSS-Team", "fullname": "OpenMOSS", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61457b8deff2c9fdb4de4988/N5b9663zQ4uq5_OTNlnmw.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.12099", "authors": [{"_id": "698e8ff2cace060ff123ac59", "name": "GigaBrain Team", "hidden": false}, {"_id": "698e8ff2cace060ff123ac5a", "name": "Boyuan Wang", "hidden": false}, {"_id": "698e8ff2cace060ff123ac5b", "name": "Chaojun Ni", "hidden": false}, {"_id": "698e8ff2cace060ff123ac5c", "name": "Guan Huang", "hidden": false}, {"_id": "698e8ff2cace060ff123ac5d", "name": "Guosheng Zhao", "hidden": false}, {"_id": "698e8ff2cace060ff123ac5e", "name": "Hao Li", "hidden": false}, {"_id": "698e8ff2cace060ff123ac5f", "name": "Jie Li", "hidden": false}, {"_id": "698e8ff2cace060ff123ac60", "name": "Jindi Lv", "hidden": false}, {"_id": "698e8ff2cace060ff123ac61", "name": "Jingyu Liu", "hidden": false}, {"_id": "698e8ff2cace060ff123ac62", "name": "Lv Feng", "hidden": false}, {"_id": "698e8ff2cace060ff123ac63", "name": "Mingming Yu", "hidden": false}, {"_id": "698e8ff2cace060ff123ac64", "name": "Peng Li", "hidden": false}, {"_id": "698e8ff2cace060ff123ac65", "name": "Qiuping Deng", "hidden": false}, {"_id": "698e8ff2cace060ff123ac66", "name": "Tianze Liu", "hidden": false}, {"_id": "698e8ff2cace060ff123ac67", "name": "Xinyu Zhou", "hidden": false}, {"_id": "698e8ff2cace060ff123ac68", "name": "Xinze Chen", "hidden": false}, {"_id": "698e8ff2cace060ff123ac69", "user": {"_id": "6426616ea5ec4a5cbc535634", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6426616ea5ec4a5cbc535634/5IfSFYd9QOxz8K9QmBCst.png", "isPro": false, "fullname": "JeffWang", "user": "Jeff-Wang", "type": "user"}, "name": "Xiaofeng Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-13T09:36:41.892Z", "hidden": false}, {"_id": "698e8ff2cace060ff123ac6a", "user": {"_id": "644012cf3e0374802e174f7c", "avatarUrl": "/avatars/0f4a4bd6f96ce193871843e1d01439e8.svg", "isPro": false, "fullname": "Yang Wang", "user": "supermodelteam", "type": "user"}, "name": "Yang Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-13T09:36:39.496Z", "hidden": false}, {"_id": "698e8ff2cace060ff123ac6b", "name": "Yifan Li", "hidden": false}, {"_id": "698e8ff2cace060ff123ac6c", "name": "Yifei Nie", "hidden": false}, {"_id": "698e8ff2cace060ff123ac6d", "name": "Yilong Li", "hidden": false}, {"_id": "698e8ff2cace060ff123ac6e", "name": "Yukun Zhou", "hidden": false}, {"_id": "698e8ff2cace060ff123ac6f", "name": "Yun Ye", "hidden": false}, {"_id": "698e8ff2cace060ff123ac70", "name": "Zhichao Liu", "hidden": false}, {"_id": "698e8ff2cace060ff123ac71", "name": "Zheng Zhu", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/6426616ea5ec4a5cbc535634/w6OBVRe04BfXtAnLDzr3o.mp4"], "publishedAt": "2026-02-12T15:55:19.000Z", "submittedOnDailyAt": "2026-02-13T00:24:14.150Z", "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning", "submittedOnDailyBy": {"_id": "6426616ea5ec4a5cbc535634", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6426616ea5ec4a5cbc535634/5IfSFYd9QOxz8K9QmBCst.png", "isPro": false, "fullname": "JeffWang", "user": "Jeff-Wang", "type": "user"}, "summary": "Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose GigaBrain-0.5M*, a VLA model trained via world model-based reinforcement learning. Built upon GigaBrain-0.5, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. GigaBrain-0.5M* further integrates world model-based reinforcement learning via RAMP (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that RAMP achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including Laundry Folding, Box Packing, and Espresso Preparation. Critically, GigaBrain-0.5M^* exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our https://gigabrain05m.github.io{project page}.", "upvotes": 33, "discussionId": "698e8ff2cace060ff123ac72", "projectPage": "https://gigabrain05m.github.io/", "githubRepo": "https://github.com/open-gigaai/giga-brain-0", "githubRepoAddedBy": "user", "ai_summary": "A vision-language-action model enhanced with world model-based reinforcement learning demonstrates improved performance and long-horizon execution capabilities for robotic manipulation tasks.", "ai_keywords": ["Vision-language-action models", "world models", "reinforcement learning", "cross-task adaptation", "RAMP", "RoboChallenge benchmark", "robotic manipulation"], "githubStars": 2271, "organization": {"_id": "68d6587936e2de9610d9f5f0", "name": "open-gigaai", "fullname": "GigaAI", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/68d6394328e169473e90e4a6/zUK7FKr_8XqrN0aFUgsD-.png"}, "summary_zh": "<ul>\n    <li>VLA\u6a21\u578b\u76f4\u63a5\u9884\u6d4b\u591a\u6b65\u52a8\u4f5c\u65f6\u6709\u5c40\u9650\u6027\uff0c\u96be\u4ee5\u7406\u89e3\u573a\u666f\u548c\u9884\u5224\u672a\u6765\u3002</li>\n    <li>\u89c6\u9891\u4e16\u754c\u6a21\u578b\u901a\u8fc7\u5927\u91cf\u89c6\u9891\u6570\u636e\u8bad\u7ec3\uff0c\u80fd\u66f4\u597d\u5730\u8fdb\u884c\u65f6\u7a7a\u63a8\u7406\u548c\u672a\u6765\u9884\u6d4b\u3002</li>\n    <li>\u6211\u4eec\u63d0\u51fa\u4e86GigaBrain-0.5M*\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684VLA\u6a21\u578b\u3002</li>\n    <li>GigaBrain-0.5M*\u5728\u8d85\u8fc710,000\u5c0f\u65f6\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\uff0c\u8868\u73b0\u4f18\u5f02\u3002</li>\n    <li>\u5b9e\u9a8c\u8bc1\u660e\uff0cGigaBrain-0.5M*\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e86\u7ea630%\u7684\u6027\u80fd\uff0c\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u53ef\u9760\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Vision-language-action (VLA) models struggle with understanding scenes and predicting future actions.</li>\n    <li>Video world models, trained on a large amount of video data, are better at understanding and predicting actions over time.</li>\n    <li>GigaBrain-0.5M* is a new VLA model that uses world model-based reinforcement learning to improve performance.</li>\n    <li>This model is based on GigaBrain-0.5, which has been trained with over 10,000 hours of robotic manipulation data and ranks first in a major robotics competition.</li>\n    <li>GigaBrain-0.5M* shows a 30% improvement on difficult tasks and performs reliably in real-world scenarios.</li>\n</ul>"}, "publishedAt": "2026-02-12T10:55:19.000Z", "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning", "summary": "Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose GigaBrain-0.5M*, a VLA model trained via world model-based reinforcement learning. Built upon GigaBrain-0.5, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. GigaBrain-0.5M* further integrates world model-based reinforcement learning via RAMP (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that RAMP achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including Laundry Folding, Box Packing, and Espresso Preparation. Critically, GigaBrain-0.5M^* exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our https://gigabrain05m.github.io{project page}.", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/6426616ea5ec4a5cbc535634/w6OBVRe04BfXtAnLDzr3o.mp4"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12099.png", "numComments": 1, "submittedBy": {"_id": "6426616ea5ec4a5cbc535634", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6426616ea5ec4a5cbc535634/5IfSFYd9QOxz8K9QmBCst.png", "fullname": "JeffWang", "name": "Jeff-Wang", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 3, "isUserFollowing": false}, "organization": {"_id": "68d6587936e2de9610d9f5f0", "name": "open-gigaai", "fullname": "GigaAI", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/68d6394328e169473e90e4a6/zUK7FKr_8XqrN0aFUgsD-.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.12056", "authors": [{"_id": "698e8eb9cace060ff123ac42", "user": {"_id": "6722fe4a43b00f3c889aead4", "avatarUrl": "/avatars/cbb57f517c37c72642b80dd538271238.svg", "isPro": false, "fullname": "Xinyu Yang", "user": "yxy919", "type": "user"}, "name": "Xinyu Yang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-13T09:36:50.313Z", "hidden": false}, {"_id": "698e8eb9cace060ff123ac43", "user": {"_id": "654c99d6e82a71cb487c2ecd", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/654c99d6e82a71cb487c2ecd/hiMMOyh-3bAUaqnBM5yT4.jpeg", "isPro": false, "fullname": "ChenlongDeng", "user": "ChenlongDeng", "type": "user"}, "name": "Chenlong Deng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-13T09:36:47.946Z", "hidden": false}, {"_id": "698e8eb9cace060ff123ac44", "name": "Tongyu Wen", "hidden": false}, {"_id": "698e8eb9cace060ff123ac45", "name": "Binyu Xie", "hidden": false}, {"_id": "698e8eb9cace060ff123ac46", "name": "Zhicheng Dou", "hidden": false}], "publishedAt": "2026-02-12T15:19:11.000Z", "submittedOnDailyAt": "2026-02-13T00:35:29.769Z", "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments", "submittedOnDailyBy": {"_id": "6710ac3fb4ee4920580a5f0e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6710ac3fb4ee4920580a5f0e/OhQQFlZmkmLQpMYqKCGP6.jpeg", "isPro": false, "fullname": "Chenghao Zhang", "user": "SnowNation", "type": "user"}, "summary": "Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .", "upvotes": 31, "discussionId": "698e8ebacace060ff123ac47", "githubRepo": "https://github.com/yxy-919/LawThinker-agent", "githubRepoAddedBy": "user", "ai_summary": "LawThinker is an autonomous legal research agent that uses an Explore-Verify-Memorize strategy with a DeepVerifier module to ensure accurate and procedurally compliant legal reasoning through dynamic verification of intermediate steps.", "ai_keywords": ["legal reasoning", "autonomous agent", "Explore-Verify-Memorize strategy", "DeepVerifier module", "knowledge accuracy", "fact-law relevance", "procedural compliance", "cross-round knowledge reuse", "dynamic judicial environments"], "githubStars": 21, "organization": {"_id": "622177ac43826d6f261f8208", "name": "RUC", "fullname": "Renmin University of China", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61ac8f8a00d01045fca0ad2f/670IAX9A2-BflqA5MiSBW.jpeg"}, "summary_zh": "<ul>\n    <li>\u6cd5\u5f8b\u63a8\u7406\u4e0d\u4ec5\u9700\u8981\u6b63\u786e\u7684\u7ed3\u679c\uff0c\u8fd8\u9700\u8981\u7b26\u5408\u7a0b\u5e8f\u8981\u6c42\u7684\u63a8\u7406\u8fc7\u7a0b\u3002</li>\n    <li>\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u9a8c\u8bc1\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\uff0c\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u4f20\u64ad\u3002</li>\n    <li>\u6211\u4eec\u63d0\u51fa\u4e86LawThinker\uff0c\u4e00\u4e2a\u81ea\u4e3b\u6cd5\u5f8b\u7814\u7a76\u4ee3\u7406\uff0c\u91c7\u7528\u63a2\u7d22-\u9a8c\u8bc1-\u8bb0\u5fc6\u7b56\u7565\u3002</li>\n    <li>LawThinker\u901a\u8fc7DeepVerifier\u6a21\u5757\u68c0\u67e5\u68c0\u7d22\u7ed3\u679c\u7684\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u7a0b\u5e8f\u5408\u89c4\u6027\u3002</li>\n    <li>\u5b9e\u9a8c\u8868\u660e\uff0cLawThinker\u5728\u52a8\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u8fc7\u7a0b\u5bfc\u5411\u6307\u6807\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Legal reasoning needs to be accurate and follow proper procedures.</li>\n    <li>Current methods often miss checking important intermediate steps, leading to errors.</li>\n    <li>LawThinker is a new tool that uses a strategy called Explore-Verify-Memorize to improve legal research.</li>\n    <li>A special module called DeepVerifier checks the accuracy and relevance of legal information after each step.</li>\n    <li>LawThinker shows significant improvements in legal reasoning effectiveness compared to existing methods.</li>\n</ul>"}, "publishedAt": "2026-02-12T10:19:11.000Z", "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments", "summary": "Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12056.png", "numComments": 1, "submittedBy": {"_id": "6710ac3fb4ee4920580a5f0e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6710ac3fb4ee4920580a5f0e/OhQQFlZmkmLQpMYqKCGP6.jpeg", "fullname": "Chenghao Zhang", "name": "SnowNation", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 13, "isUserFollowing": false}, "organization": {"_id": "622177ac43826d6f261f8208", "name": "RUC", "fullname": "Renmin University of China", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61ac8f8a00d01045fca0ad2f/670IAX9A2-BflqA5MiSBW.jpeg"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.11731", "authors": [{"_id": "698eb9d9cace060ff123aea4", "name": "Jingxuan Wei", "hidden": false}, {"_id": "698eb9d9cace060ff123aea5", "name": "Honghao He", "hidden": false}, {"_id": "698eb9d9cace060ff123aea6", "name": "Caijun Jia", "hidden": false}, {"_id": "698eb9d9cace060ff123aea7", "user": {"_id": "640f7083208821a59b74c757", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678735253848-640f7083208821a59b74c757.jpeg", "isPro": false, "fullname": "Siyuan Li", "user": "Lupin1998", "type": "user"}, "name": "Siyuan Li", "status": "claimed_verified", "statusLastChangedAt": "2026-02-13T09:36:19.311Z", "hidden": false}, {"_id": "698eb9d9cace060ff123aea8", "name": "Zheng Sun", "hidden": false}, {"_id": "698eb9d9cace060ff123aea9", "name": "Yuhang Xu", "hidden": false}, {"_id": "698eb9d9cace060ff123aeaa", "name": "Yuanyuan Lin", "hidden": false}, {"_id": "698eb9d9cace060ff123aeab", "name": "Linzhuang Sun", "hidden": false}, {"_id": "698eb9d9cace060ff123aeac", "name": "Yuchen Wu", "hidden": false}, {"_id": "698eb9d9cace060ff123aead", "name": "Bihui Yu", "hidden": false}, {"_id": "698eb9d9cace060ff123aeae", "name": "Xiangxiang Zhang", "hidden": false}, {"_id": "698eb9d9cace060ff123aeaf", "user": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "isPro": false, "fullname": "Cheng Tan", "user": "chengtan9907", "type": "user"}, "name": "Cheng Tan", "status": "claimed_verified", "statusLastChangedAt": "2026-02-13T09:36:16.992Z", "hidden": false}], "publishedAt": "2026-02-12T08:54:02.000Z", "submittedOnDailyAt": "2026-02-13T05:37:54.762Z", "title": "Thinking with Drafting: Optical Decompression via Logical Reconstruction", "submittedOnDailyBy": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "isPro": false, "fullname": "Cheng Tan", "user": "chengtan9907", "type": "user"}, "summary": "Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning.", "upvotes": 27, "discussionId": "698eb9dacace060ff123aeb0", "ai_summary": "Visual reasoning is enhanced by reconstructing logical structures from compressed visual tokens through a DSL-based approach that generates deterministic visual proofs for verification.", "ai_keywords": ["multimodal large language models", "visual perception", "visual generation", "optical decompression", "visual tokens", "Domain-Specific Language", "visual algebra benchmark", "visual reasoning", "logical topology", "deterministic visual proofs"], "organization": {"_id": "653b817d32c97d0655575872", "name": "ByteDance", "fullname": "ByteDance", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6535c9e88bde2fae19b6fb25/0clr54wj5Ly-RkYU9OXPp.png"}, "summary_zh": "<ul>\n    <li>\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u611f\u77e5\u548c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u7cbe\u786e\u6027\u6096\u8bba\u3002</li>\n    <li>\u5149\u5b66\u611f\u77e5\u7cfb\u7edf\u65e0\u6cd5\u6355\u6349\u903b\u8f91\u7ed3\u6784\uff0c\u800c\u57fa\u4e8e\u50cf\u7d20\u7684\u751f\u6210\u6a21\u578b\u5219\u7f3a\u4e4f\u6570\u5b66\u7cbe\u786e\u6027\u3002</li>\n    <li>\u6211\u4eec\u63d0\u51fa\u5c06\u89c6\u89c9\u8f93\u5165\u7684\u63a8\u7406\u91cd\u6784\u4e3a\u5149\u5b66\u89e3\u538b\uff0c\u91cd\u5efa\u538b\u7f29\u89c6\u89c9\u7b26\u53f7\u4e2d\u7684\u903b\u8f91\u7ed3\u6784\u3002</li>\n    <li>\u5f15\u5165\u201c\u601d\u8003\u4e0e\u8349\u62df\u201d\uff08TwD\uff09\uff0c\u4f7f\u7528\u7b80\u5316\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u5e2e\u52a9\u6a21\u578b\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\u8fdb\u884c\u81ea\u6211\u9a8c\u8bc1\u3002</li>\n    <li>\u901a\u8fc7VisAlg\u89c6\u89c9\u4ee3\u6570\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u8868\u660eTwD\u5728\u8ba4\u77e5\u7ed3\u6784\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u5efa\u7acb\u4e86\u89c6\u89c9\u751f\u6210\u4f5c\u4e3a\u903b\u8f91\u9a8c\u8bc1\u7684\u95ed\u73af\u7cfb\u7edf\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Multimodal large language models can understand images and create visuals well, but struggle with complex reasoning tasks.</li>\n    <li>Current systems either misinterpret visual symbols or produce inaccurate visual outputs.</li>\n    <li>The authors propose a new approach called \"Thinking with Drafting\" (TwD) to improve reasoning from visual inputs.</li>\n    <li>TwD uses a simple programming language to help models create clear, logical proofs instead of just guessing answers.</li>\n    <li>The study introduces a benchmark called VisAlg, showing that TwD improves the reasoning process by using visual generation as a way to verify logic.</li>\n</ul>"}, "publishedAt": "2026-02-12T03:54:02.000Z", "title": "Thinking with Drafting: Optical Decompression via Logical Reconstruction", "summary": "Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.11731.png", "numComments": 2, "submittedBy": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "fullname": "Cheng Tan", "name": "chengtan9907", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 2, "isUserFollowing": false}, "organization": {"_id": "653b817d32c97d0655575872", "name": "ByteDance", "fullname": "ByteDance", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6535c9e88bde2fae19b6fb25/0clr54wj5Ly-RkYU9OXPp.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.12280", "authors": [{"_id": "698ea022cace060ff123ae30", "name": "Huai-Hsun Cheng", "hidden": false}, {"_id": "698ea022cace060ff123ae31", "name": "Siang-Ling Zhang", "hidden": false}, {"_id": "698ea022cace060ff123ae32", "name": "Yu-Lun Liu", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/655f1770f74fa124d1172ec1/8bTk3z-6osRw_udarMcy2.mp4"], "publishedAt": "2026-02-12T18:59:54.000Z", "submittedOnDailyAt": "2026-02-13T02:04:47.660Z", "title": "Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching", "submittedOnDailyBy": {"_id": "655f1770f74fa124d1172ec1", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/655f1770f74fa124d1172ec1/bdYocZ1qN50CAfb2z2YLA.png", "isPro": false, "fullname": "Jie-Ying Lee", "user": "jayinnn", "type": "user"}, "summary": "Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the \"dual-constraint\": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a \"common structural subspace\" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/", "upvotes": 24, "discussionId": "698ea023cace060ff123ae33", "projectPage": "https://stroke-of-surprise.github.io/", "githubRepo": "https://github.com/stroke-of-surprise/Stroke-Of-Surprise", "githubRepoAddedBy": "user", "ai_summary": "Progressive Semantic Illusions use a generative framework with dual-branch Score Distillation Sampling to create vector sketches that transform semantically through sequential stroke additions, achieving superior recognizability and illusion strength.", "ai_keywords": ["vector sketching", "semantic transformation", "Stroke of Surprise", "generative framework", "dual-branch Score Distillation Sampling", "sequential optimization", "structural subspace", "Overlay Loss", "visual anagrams"], "githubStars": 21, "organization": {"_id": "63e39e6499a032b1c950403d", "name": "NYCU", "fullname": "National Yang Ming Chiao Tung University", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/63e39df6c65f975b436bb6b8/WLWf1bSpvrXBYYKEdXbgU.png"}, "summary_zh": "<ul>\n    <li>\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u5411\u91cf\u8349\u56fe\u4efb\u52a1\uff0c\u79f0\u4e3a\u6e10\u8fdb\u8bed\u4e49\u5e7b\u89c9\u3002</li>\n    <li>\u901a\u8fc7\u9010\u6b65\u6dfb\u52a0\u7b14\u753b\uff0c\u5355\u4e2a\u8349\u56fe\u53ef\u4ee5\u7ecf\u5386\u663e\u8457\u7684\u8bed\u4e49\u8f6c\u53d8\u3002</li>\n    <li>\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u6846\u67b6\u201c\u60ca\u559c\u7b14\u753b\u201d\uff0c\u4f18\u5316\u7b14\u753b\u4ee5\u5728\u4e0d\u540c\u9636\u6bb5\u6ee1\u8db3\u4e0d\u540c\u7684\u8bed\u4e49\u89e3\u91ca\u3002</li>\n    <li>\u6838\u5fc3\u6311\u6218\u662f\u786e\u4fdd\u521d\u59cb\u7b14\u753b\u65e2\u6784\u6210\u4e00\u4e2a\u8fde\u8d2f\u7684\u7269\u4f53\uff0c\u53c8\u4e3a\u540e\u7eed\u7b14\u753b\u63d0\u4f9b\u7ed3\u6784\u57fa\u7840\u3002</li>\n    <li>\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u53ef\u8bc6\u522b\u6027\u548c\u5e7b\u89c9\u5f3a\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>This research introduces Progressive Semantic Illusions, where a simple sketch changes meaning through added strokes.</li>\n    <li>The method, called Stroke of Surprise, optimizes strokes to create different interpretations at each drawing stage.</li>\n    <li>A key challenge is ensuring initial strokes look like one object while also serving as a base for another object when more strokes are added.</li>\n    <li>The proposed solution uses a joint optimization framework that adjusts strokes dynamically for both interpretations.</li>\n    <li>Experiments show this method is better than existing techniques in making sketches recognizable and enhancing their illusion effects.</li>\n</ul>"}, "publishedAt": "2026-02-12T13:59:54.000Z", "title": "Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching", "summary": "Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the \"dual-constraint\": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a \"common structural subspace\" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/655f1770f74fa124d1172ec1/8bTk3z-6osRw_udarMcy2.mp4"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12280.png", "numComments": 1, "submittedBy": {"_id": "655f1770f74fa124d1172ec1", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/655f1770f74fa124d1172ec1/bdYocZ1qN50CAfb2z2YLA.png", "fullname": "Jie-Ying Lee", "name": "jayinnn", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 8, "isUserFollowing": false}, "organization": {"_id": "63e39e6499a032b1c950403d", "name": "NYCU", "fullname": "National Yang Ming Chiao Tung University", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/63e39df6c65f975b436bb6b8/WLWf1bSpvrXBYYKEdXbgU.png"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.11748", "authors": [{"_id": "698ec188cace060ff123aed7", "name": "Futing Wang", "hidden": false}, {"_id": "698ec188cace060ff123aed8", "name": "Jianhao Yan", "hidden": false}, {"_id": "698ec188cace060ff123aed9", "name": "Yun Luo", "hidden": false}, {"_id": "698ec188cace060ff123aeda", "name": "Ganqu Cui", "hidden": false}, {"_id": "698ec188cace060ff123aedb", "name": "Zhi Wang", "hidden": false}, {"_id": "698ec188cace060ff123aedc", "name": "Xiaoye Qu", "hidden": false}, {"_id": "698ec188cace060ff123aedd", "name": "Yue Zhang", "hidden": false}, {"_id": "698ec188cace060ff123aede", "name": "Yu Cheng", "hidden": false}, {"_id": "698ec188cace060ff123aedf", "name": "Tao Lin", "hidden": false}], "publishedAt": "2026-02-12T09:24:32.000Z", "submittedOnDailyAt": "2026-02-13T03:46:21.481Z", "title": "Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning", "submittedOnDailyBy": {"_id": "644915c5e87a77e872e61350", "avatarUrl": "/avatars/46ba7bdf04ad4c1b0ad79155010dc684.svg", "isPro": false, "fullname": "Luo", "user": "ramiroluo", "type": "user"}, "summary": "Achieving effective test-time scaling requires models to engage in In-Context Exploration -- the intrinsic ability to generate, verify, and refine multiple reasoning hypotheses within a single continuous context.\n  Grounded in State Coverage theory, our analysis identifies a critical bottleneck to enabling this capability: while broader state coverage requires longer reasoning trajectories, the probability of sampling such sequences decays exponentially during autoregressive generation, a phenomenon we term the ``Shallow Exploration Trap''.\n  To bridge this gap, we propose Length-Incentivized Exploration(\\method).\n  This simple yet effective recipe explicitly encourages models to explore more via a length-based reward coupled with a redundancy penalty, thereby maximizing state coverage in two-step manner.\n  Comprehensive experiments across different models (Qwen3, Llama) demonstrate that \\method effectively incentivize in-context exploration.\n  As a result, our method achieves an average improvement of 4.4\\% on in-domain tasks and a 2.7\\% gain on out-of-domain benchmarks.", "upvotes": 24, "discussionId": "698ec188cace060ff123aee0", "githubRepo": "https://github.com/LINs-lab/LIE", "githubRepoAddedBy": "user", "ai_summary": "Models require in-context exploration capabilities to scale effectively at test time, but autoregressive generation faces exponential decay in sampling long sequences, which is addressed by a length-incentivized exploration method that improves performance on both in-domain and out-of-domain tasks.", "ai_keywords": ["In-Context Exploration", "State Coverage theory", "Shallow Exploration Trap", "Length-Incentivized Exploration", "autoregressive generation", "redundancy penalty", "state coverage"], "githubStars": 8, "organization": {"_id": "643cb10025681c3afab0f1a6", "name": "Westlake-University", "fullname": "Westlake University", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6437eca0819f3ab20d162e14/SQRCHUyjPRyqdtV3um42X.jpeg"}, "summary_zh": "<ul>\n    <li>\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u9700\u8981\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u63a2\u7d22\uff0c\u751f\u6210\u548c\u9a8c\u8bc1\u591a\u79cd\u63a8\u7406\u5047\u8bbe\u3002</li>\n    <li>\u57fa\u4e8e\u72b6\u6001\u8986\u76d6\u7406\u8bba\uff0c\u6211\u4eec\u53d1\u73b0\u4e00\u4e2a\u5173\u952e\u74f6\u9888\uff1a\u66f4\u5e7f\u6cdb\u7684\u72b6\u6001\u8986\u76d6\u9700\u8981\u66f4\u957f\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u800c\u81ea\u56de\u5f52\u751f\u6210\u65f6\u91c7\u6837\u7684\u6982\u7387\u4f1a\u8fc5\u901f\u4e0b\u964d\uff0c\u8fd9\u88ab\u79f0\u4e3a\u201c\u6d45\u5c42\u63a2\u7d22\u9677\u9631\u201d\u3002</li>\n    <li>\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u957f\u5ea6\u6fc0\u52b1\u63a2\u7d22\u7684\u65b9\u6cd5\uff0c\u9f13\u52b1\u6a21\u578b\u901a\u8fc7\u57fa\u4e8e\u957f\u5ea6\u7684\u5956\u52b1\u548c\u5197\u4f59\u60e9\u7f5a\u6765\u8fdb\u884c\u66f4\u591a\u63a2\u7d22\u3002</li>\n    <li>\u5728\u4e0d\u540c\u6a21\u578b\uff08\u5982Qwen3\u548cLlama\uff09\u7684\u5168\u9762\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u6709\u6548\u5730\u6fc0\u52b1\u4e86\u4e0a\u4e0b\u6587\u4e2d\u7684\u63a2\u7d22\u3002</li>\n    <li>\u7ed3\u679c\u663e\u793a\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u9886\u57df\u5185\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u9ad8\u4e864.4%\uff0c\u5728\u9886\u57df\u5916\u57fa\u51c6\u4e0a\u63d0\u9ad8\u4e862.7%\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Models can improve their reasoning by exploring different options within a single context during tests.</li>\n    <li>There is a challenge called the \"Shallow Exploration Trap,\" which limits the ability of models to cover more reasoning states.</li>\n    <li>To overcome this, a method called Length-Incentivized Exploration is proposed, which rewards longer exploration and penalizes redundancy.</li>\n    <li>This method has been tested on various models, showing that it encourages more in-context exploration.</li>\n    <li>Overall, the method leads to a 4.4% improvement on in-domain tasks and a 2.7% improvement on out-of-domain tasks.</li>\n</ul>"}, "publishedAt": "2026-02-12T04:24:32.000Z", "title": "Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning", "summary": "Achieving effective test-time scaling requires models to engage in In-Context Exploration -- the intrinsic ability to generate, verify, and refine multiple reasoning hypotheses within a single continuous context.\n  Grounded in State Coverage theory, our analysis identifies a critical bottleneck to enabling this capability: while broader state coverage requires longer reasoning trajectories, the probability of sampling such sequences decays exponentially during autoregressive generation, a phenomenon we term the ``Shallow Exploration Trap''.\n  To bridge this gap, we propose Length-Incentivized Exploration(\\method).\n  This simple yet effective recipe explicitly encourages models to explore more via a length-based reward coupled with a redundancy penalty, thereby maximizing state coverage in two-step manner.\n  Comprehensive experiments across different models (Qwen3, Llama) demonstrate that \\method effectively incentivize in-context exploration.\n  As a result, our method achieves an average improvement of 4.4\\% on in-domain tasks and a 2.7\\% gain on out-of-domain benchmarks.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.11748.png", "numComments": 2, "submittedBy": {"_id": "644915c5e87a77e872e61350", "avatarUrl": "/avatars/46ba7bdf04ad4c1b0ad79155010dc684.svg", "fullname": "Luo", "name": "ramiroluo", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 1, "isUserFollowing": false}, "organization": {"_id": "643cb10025681c3afab0f1a6", "name": "Westlake-University", "fullname": "Westlake University", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6437eca0819f3ab20d162e14/SQRCHUyjPRyqdtV3um42X.jpeg"}, "isAuthorParticipating": false}],
    "week": [{"paper": {"id": "2602.09877", "authors": [{"_id": "698c7abdeb12ea7453916869", "user": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "isPro": false, "fullname": "Chenxu Wang", "user": "xunyoyo", "type": "user"}, "name": "Chenxu Wang", "status": "admin_assigned", "statusLastChangedAt": "2026-02-12T16:49:45.534Z", "hidden": false}, {"_id": "698c7abdeb12ea745391686a", "name": "Chaozhuo Li", "hidden": false}, {"_id": "698c7abdeb12ea745391686b", "name": "Songyang Liu", "hidden": false}, {"_id": "698c7abdeb12ea745391686c", "name": "Zejian Chen", "hidden": false}, {"_id": "698c7abdeb12ea745391686d", "name": "Jinyu Hou", "hidden": false}, {"_id": "698c7abdeb12ea745391686e", "name": "Ji Qi", "hidden": false}, {"_id": "698c7abdeb12ea745391686f", "name": "Rui Li", "hidden": false}, {"_id": "698c7abdeb12ea7453916870", "name": "Litian Zhang", "hidden": false}, {"_id": "698c7abdeb12ea7453916871", "name": "Qiwei Ye", "hidden": false}, {"_id": "698c7abdeb12ea7453916872", "name": "Zheng Liu", "hidden": false}, {"_id": "698c7abdeb12ea7453916873", "name": "Xu Chen", "hidden": false}, {"_id": "698c7abdeb12ea7453916874", "name": "Xi Zhang", "hidden": false}, {"_id": "698c7abdeb12ea7453916875", "name": "Philip S. Yu", "hidden": false}], "publishedAt": "2026-02-10T15:18:19.000Z", "submittedOnDailyAt": "2026-02-13T00:53:30.377Z", "title": "The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies", "submittedOnDailyBy": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "isPro": false, "fullname": "Chenxu Wang", "user": "xunyoyo", "type": "user"}, "summary": "The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.", "upvotes": 169, "discussionId": "698c7abdeb12ea7453916876", "ai_summary": "Multi-agent LLM systems face fundamental limitations in achieving continuous self-improvement while maintaining safety alignment due to inherent statistical blind spots in isolated evolution.", "ai_keywords": ["multi-agent systems", "large language models", "self-evolution", "safety alignment", "information-theoretic framework", "anthropic value distributions", "statistical blind spots", "self-evolving AI societies", "external oversight", "safety-preserving mechanisms"], "summary_zh": "<ul>\n    <li>\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6784\u6210\uff09\u5177\u6709\u53ef\u6269\u5c55\u7684\u96c6\u4f53\u667a\u80fd\u548c\u81ea\u6211\u8fdb\u5316\u7684\u6f5c\u529b\u3002</li>\n    <li>\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5e94\u5177\u5907\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u548c\u5b89\u5168\u5bf9\u9f50\uff0c\u4f46\u6211\u4eec\u53d1\u73b0\u8fd9\u4e24\u8005\u65e0\u6cd5\u517c\u5f97\u3002</li>\n    <li>\u6211\u4eec\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5b64\u7acb\u7684\u81ea\u6211\u8fdb\u5316\u4f1a\u5bfc\u81f4\u5b89\u5168\u5bf9\u9f50\u7684\u4e0d\u53ef\u9006\u964d\u7ea7\u3002</li>\n    <li>\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u6211\u4eec\u7684\u7406\u8bba\u9884\u6d4b\u4e00\u81f4\uff0c\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u4f1a\u968f\u7740\u65f6\u95f4\u63a8\u79fb\u800c\u964d\u4f4e\u3002</li>\n    <li>\u6211\u4eec\u5efa\u8bae\u4e86\u51e0\u79cd\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u7f13\u89e3\u5b89\u5168\u95ee\u9898\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u5916\u90e8\u76d1\u7763\u6216\u65b0\u7684\u5b89\u5168\u673a\u5236\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Multi-agent systems using large language models can enhance collective intelligence and self-improvement.</li>\n    <li>Achieving continuous self-improvement while ensuring safety is called the self-evolution trilemma, which is shown to be impossible.</li>\n    <li>Isolation during self-evolution creates safety risks due to blind spots, leading to a decline in safety alignment.</li>\n    <li>Research from a community of agents and closed systems supports the idea that safety will inevitably decrease over time.</li>\n    <li>The study suggests exploring new safety measures and external oversight to manage these risks more effectively.</li>\n</ul>"}, "publishedAt": "2026-02-10T10:18:19.000Z", "title": "The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies", "summary": "The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.09877.png", "numComments": 2, "submittedBy": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "fullname": "Chenxu Wang", "name": "xunyoyo", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "isUserFollowing": false}, "isAuthorParticipating": true}, {"paper": {"id": "2602.09856", "authors": [{"_id": "698bf5b66052d3bed9630aa7", "user": {"_id": "64107c7df52d7eb22e062956", "avatarUrl": "/avatars/7b1cee9a2b8454fedfbd4c3d1df9865c.svg", "isPro": false, "fullname": "Yuhao Zheng", "user": "yhzheng1031", "type": "user"}, "name": "Yuhao Zheng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:28.241Z", "hidden": false}, {"_id": "698bf5b66052d3bed9630aa8", "name": "Li'an Zhong", "hidden": false}, {"_id": "698bf5b66052d3bed9630aa9", "user": {"_id": "6773bcaa675a971ddf1e81dd", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/a8VUwZYXd7O_mq_zFvXMh.png", "isPro": false, "fullname": "CokeWang", "user": "CokeWang", "type": "user"}, "name": "Yi Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:30.778Z", "hidden": false}, {"_id": "698bf5b66052d3bed9630aaa", "user": {"_id": "661de9defdbc9c247f159d15", "avatarUrl": "/avatars/38e21e78327cc908201122405c48f41b.svg", "isPro": false, "fullname": "Rui Dai", "user": "DerryD", "type": "user"}, "name": "Rui Dai", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:25.982Z", "hidden": false}, {"_id": "698bf5b66052d3bed9630aab", "name": "Kaikui Liu", "hidden": false}, {"_id": "698bf5b66052d3bed9630aac", "name": "Xiangxiang Chu", "hidden": false}, {"_id": "698bf5b66052d3bed9630aad", "name": "Linyuan Lv", "hidden": false}, {"_id": "698bf5b66052d3bed9630aae", "name": "Philip Torr", "hidden": false}, {"_id": "698bf5b66052d3bed9630aaf", "user": {"_id": "64440be5af034cdfd69ca3a7", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg", "isPro": false, "fullname": "Qinghong (Kevin) Lin", "user": "KevinQHLin", "type": "user"}, "name": "Kevin Qinghong Lin", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:23.397Z", "hidden": false}], "publishedAt": "2026-02-10T14:56:19.000Z", "submittedOnDailyAt": "2026-02-11T01:02:42.385Z", "title": "Code2World: A GUI World Model via Renderable Code Generation", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.", "upvotes": 168, "discussionId": "698bf5b66052d3bed9630ab0", "projectPage": "https://amap-ml.github.io/Code2World/", "githubRepo": "https://github.com/AMAP-ML/Code2World", "githubRepoAddedBy": "user", "ai_summary": "Code2World enables autonomous GUI agents to predict next visual states through renderable code generation, achieving high visual fidelity and structural controllability while improving navigation performance.", "ai_keywords": ["vision-language coder", "GUI World model", "action-conditioned prediction", "AndroidCode", "HTML generation", "visual-feedback revision mechanism", "SFT", "Render-Aware Reinforcement Learning", "visual semantic fidelity", "action consistency", "next UI prediction", "AndroidWorld navigation"], "githubStars": 131, "organization": {"_id": "67d11771890254196d3174e5", "name": "GD-ML", "fullname": "AMAP-ML", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"}, "summary_zh": "<ul>\n    <li>\u81ea\u4e3b\u56fe\u5f62\u7528\u6237\u754c\u9762\u4ee3\u7406\u901a\u8fc7\u611f\u77e5\u754c\u9762\u548c\u6267\u884c\u52a8\u4f5c\u4e0e\u73af\u5883\u4e92\u52a8\u3002</li>\n    <li>Code2World\u662f\u4e00\u4e2a\u89c6\u89c9\u8bed\u8a00\u7f16\u7801\u5668\uff0c\u53ef\u4ee5\u751f\u6210\u53ef\u6e32\u67d3\u7684\u4ee3\u7801\u6765\u6a21\u62df\u4e0b\u4e00\u4e2a\u89c6\u89c9\u72b6\u6001\u3002</li>\n    <li>\u4e3a\u4e86\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u6211\u4eec\u6784\u5efa\u4e86AndroidCode\uff0c\u751f\u6210\u8d85\u8fc78\u4e07\u5bf9\u9ad8\u8d28\u91cf\u5c4f\u5e55-\u52a8\u4f5c\u5bf9\u3002</li>\n    <li>\u6211\u4eec\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u89c6\u89c9\u8bed\u4e49\u4e00\u81f4\u6027\u6765\u63d0\u9ad8\u4ee3\u7801\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002</li>\n    <li>Code2World\u5728\u7528\u6237\u754c\u9762\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bfc\u822a\u6210\u529f\u7387\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Code2World is a new tool that helps virtual agents predict the next visual state of user interfaces by generating code.</li>\n    <li>It improves on existing methods by creating high-quality screen-action pairs from Android GUI data, with over 80,000 examples.</li>\n    <li>The tool uses a special learning method that focuses on visual accuracy and consistent actions to enhance predictions.</li>\n    <li>Tests show that Code2World outperforms other systems like GPT-5 and Gemini-3-Pro-Image in predicting user interface changes.</li>\n    <li>Code2World also improves navigation success rates in Android applications, boosting performance significantly.</li>\n</ul>"}, "publishedAt": "2026-02-10T09:56:19.000Z", "title": "Code2World: A GUI World Model via Renderable Code Generation", "summary": "Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.09856.png", "numComments": 2, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 230, "isUserFollowing": false}, "organization": {"_id": "67d11771890254196d3174e5", "name": "GD-ML", "fullname": "AMAP-ML", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.10604", "authors": [{"_id": "698d417065c0d15a6d162026", "name": "Ailin Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162027", "name": "Ang Li", "hidden": false}, {"_id": "698d417065c0d15a6d162028", "name": "Aobo Kong", "hidden": false}, {"_id": "698d417065c0d15a6d162029", "name": "Bin Wang", "hidden": false}, {"_id": "698d417065c0d15a6d16202a", "name": "Binxing Jiao", "hidden": false}, {"_id": "698d417065c0d15a6d16202b", "name": "Bo Dong", "hidden": false}, {"_id": "698d417065c0d15a6d16202c", "name": "Bojun Wang", "hidden": false}, {"_id": "698d417065c0d15a6d16202d", "name": "Boyu Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16202e", "name": "Brian Li", "hidden": false}, {"_id": "698d417065c0d15a6d16202f", "name": "Buyun Ma", "hidden": false}, {"_id": "698d417065c0d15a6d162030", "name": "Chang Su", "hidden": false}, {"_id": "698d417065c0d15a6d162031", "name": "Changxin Miao", "hidden": false}, {"_id": "698d417065c0d15a6d162032", "name": "Changyi Wan", "hidden": false}, {"_id": "698d417065c0d15a6d162033", "name": "Chao Lou", "hidden": false}, {"_id": "698d417065c0d15a6d162034", "name": "Chen Hu", "hidden": false}, {"_id": "698d417065c0d15a6d162035", "name": "Chen Xu", "hidden": false}, {"_id": "698d417065c0d15a6d162036", "name": "Chenfeng Yu", "hidden": false}, {"_id": "698d417065c0d15a6d162037", "name": "Chengting Feng", "hidden": false}, {"_id": "698d417065c0d15a6d162038", "name": "Chengyuan Yao", "hidden": false}, {"_id": "698d417065c0d15a6d162039", "name": "Chunrui Han", "hidden": false}, {"_id": "698d417065c0d15a6d16203a", "name": "Dan Ma", "hidden": false}, {"_id": "698d417065c0d15a6d16203b", "name": "Dapeng Shi", "hidden": false}, {"_id": "698d417065c0d15a6d16203c", "name": "Daxin Jiang", "hidden": false}, {"_id": "698d417065c0d15a6d16203d", "name": "Dehua Ma", "hidden": false}, {"_id": "698d417065c0d15a6d16203e", "name": "Deshan Sun", "hidden": false}, {"_id": "698d417065c0d15a6d16203f", "name": "Di Qi", "hidden": false}, {"_id": "698d417065c0d15a6d162040", "name": "Enle Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162041", "name": "Fajie Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d162042", "name": "Fanqi Wan", "hidden": false}, {"_id": "698d417065c0d15a6d162043", "name": "Guanzhe Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162044", "name": "Gulin Yan", "hidden": false}, {"_id": "698d417065c0d15a6d162045", "name": "Guoliang Cao", "hidden": false}, {"_id": "698d417065c0d15a6d162046", "name": "Guopeng Li", "hidden": false}, {"_id": "698d417065c0d15a6d162047", "name": "Han Cheng", "hidden": false}, {"_id": "698d417065c0d15a6d162048", "name": "Hangyu Guo", "hidden": false}, {"_id": "698d417065c0d15a6d162049", "user": {"_id": "64b7874b9f5987572ca28461", "avatarUrl": "/avatars/d24ee0a6329ff93936aa7829481e2046.svg", "isPro": false, "fullname": "hanshanzhang", "user": "brain-zhang", "type": "user"}, "name": "Hanshan Zhang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:52.602Z", "hidden": false}, {"_id": "698d417065c0d15a6d16204a", "name": "Hao Nie", "hidden": false}, {"_id": "698d417065c0d15a6d16204b", "name": "Haonan Jia", "hidden": false}, {"_id": "698d417065c0d15a6d16204c", "name": "Haoran Lv", "hidden": false}, {"_id": "698d417065c0d15a6d16204d", "name": "Hebin Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d16204e", "name": "Hekun Lv", "hidden": false}, {"_id": "698d417065c0d15a6d16204f", "name": "Heng Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162050", "name": "Heung-Yeung Shum", "hidden": false}, {"_id": "698d417065c0d15a6d162051", "name": "Hongbo Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162052", "name": "Hongbo Peng", "hidden": false}, {"_id": "698d417065c0d15a6d162053", "name": "Hongyu Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d162054", "name": "Hongyuan Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162055", "name": "Houyong Chen", "hidden": false}, {"_id": "698d417065c0d15a6d162056", "name": "Huangxi Zhu", "hidden": false}, {"_id": "698d417065c0d15a6d162057", "name": "Huimin Wu", "hidden": false}, {"_id": "698d417065c0d15a6d162058", "name": "Huiyong Guo", "hidden": false}, {"_id": "698d417065c0d15a6d162059", "name": "Jia Wang", "hidden": false}, {"_id": "698d417065c0d15a6d16205a", "name": "Jian Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d16205b", "name": "Jianjian Sun", "hidden": false}, {"_id": "698d417065c0d15a6d16205c", "name": "Jiaoren Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16205d", "name": "Jiaran Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d16205e", "name": "Jiashu Lv", "hidden": false}, {"_id": "698d417065c0d15a6d16205f", "name": "Jiashuo Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162060", "name": "Jiayi Fu", "hidden": false}, {"_id": "698d417065c0d15a6d162061", "name": "Jiayu Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162062", "name": "Jie Cheng", "hidden": false}, {"_id": "698d417065c0d15a6d162063", "name": "Jie Luo", "hidden": false}, {"_id": "698d417065c0d15a6d162064", "name": "Jie Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162065", "name": "Jie Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d162066", "name": "Jieyi Hou", "hidden": false}, {"_id": "698d417065c0d15a6d162067", "name": "Jing Bai", "hidden": false}, {"_id": "698d417065c0d15a6d162068", "user": {"_id": "625026b7d2d191ac43320c5e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/625026b7d2d191ac43320c5e/2ExzHlZ-Bk8SQMyBjeY6N.jpeg", "isPro": false, "fullname": "Jingcheng Hu", "user": "reign12", "type": "user"}, "name": "Jingcheng Hu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:28:37.335Z", "hidden": false}, {"_id": "698d417065c0d15a6d162069", "name": "Jingjing Xie", "hidden": false}, {"_id": "698d417065c0d15a6d16206a", "name": "Jingwei Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16206b", "name": "Jingyang Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d16206c", "name": "Jishi Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d16206d", "name": "Junfeng Liu", "hidden": false}, {"_id": "698d417065c0d15a6d16206e", "name": "Junzhe Lin", "hidden": false}, {"_id": "698d417065c0d15a6d16206f", "name": "Ka Man Lo", "hidden": false}, {"_id": "698d417065c0d15a6d162070", "name": "Kai Liang", "hidden": false}, {"_id": "698d417065c0d15a6d162071", "name": "Kaibo Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162072", "name": "Kaijun Tan", "hidden": false}, {"_id": "698d417065c0d15a6d162073", "user": {"_id": "66668c591964b6188ee310c2", "avatarUrl": "/avatars/8a8265073dbacbb2c7139b1c8da3e055.svg", "isPro": false, "fullname": "Kaiwen Yan", "user": "linrany", "type": "user"}, "name": "Kaiwen Yan", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:58.524Z", "hidden": false}, {"_id": "698d417065c0d15a6d162074", "name": "Kaixiang Li", "hidden": false}, {"_id": "698d417065c0d15a6d162075", "name": "Kang An", "hidden": false}, {"_id": "698d417065c0d15a6d162076", "user": {"_id": "658a810665df457a55ffcd04", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/658a810665df457a55ffcd04/6Pe0mNao4mlWLIjYEoWv5.jpeg", "isPro": false, "fullname": "Linkangheng", "user": "Kangheng", "type": "user"}, "name": "Kangheng Lin", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:56.339Z", "hidden": false}, {"_id": "698d417065c0d15a6d162077", "name": "Lei Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162078", "name": "Liang Lv", "hidden": false}, {"_id": "698d417065c0d15a6d162079", "name": "Liang Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d16207a", "name": "Liangyu Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16207b", "name": "Lieyu Shi", "hidden": false}, {"_id": "698d417065c0d15a6d16207c", "name": "Liguo Tan", "hidden": false}, {"_id": "698d417065c0d15a6d16207d", "name": "Lin Lin", "hidden": false}, {"_id": "698d417065c0d15a6d16207e", "name": "Lina Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16207f", "name": "Luck Ma", "hidden": false}, {"_id": "698d417065c0d15a6d162080", "name": "Mengqiang Ren", "hidden": false}, {"_id": "698d417065c0d15a6d162081", "name": "Michael Li", "hidden": false}, {"_id": "698d417065c0d15a6d162082", "name": "Ming Li", "hidden": false}, {"_id": "698d417065c0d15a6d162083", "name": "Mingliang Li", "hidden": false}, {"_id": "698d417065c0d15a6d162084", "name": "Mingming Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d162085", "name": "Mingrui Chen", "hidden": false}, {"_id": "698d417065c0d15a6d162086", "name": "Mitt Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162087", "name": "Na Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162088", "name": "Peng Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162089", "name": "Qi Han", "hidden": false}, {"_id": "698d417065c0d15a6d16208a", "name": "Qian Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d16208b", "name": "Qinglin He", "hidden": false}, {"_id": "698d417065c0d15a6d16208c", "name": "Qinxin Du", "hidden": false}, {"_id": "698d417065c0d15a6d16208d", "name": "Qiuping Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16208e", "name": "Quan Sun", "hidden": false}, {"_id": "698d417065c0d15a6d16208f", "name": "Rongqiu Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162090", "name": "Ruihang Miao", "hidden": false}, {"_id": "698d417065c0d15a6d162091", "name": "Ruixin Han", "hidden": false}, {"_id": "698d417065c0d15a6d162092", "name": "Ruosi Wan", "hidden": false}, {"_id": "698d417065c0d15a6d162093", "name": "Ruyan Guo", "hidden": false}, {"_id": "698d417065c0d15a6d162094", "name": "Shan Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162095", "name": "Shaoliang Pang", "hidden": false}, {"_id": "698d417065c0d15a6d162096", "name": "Shaowen Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162097", "name": "Shengjie Fan", "hidden": false}, {"_id": "698d417065c0d15a6d162098", "name": "Shijie Shang", "hidden": false}, {"_id": "698d417065c0d15a6d162099", "name": "Shiliang Yang", "hidden": false}, {"_id": "698d417065c0d15a6d16209a", "name": "Shiwei Li", "hidden": false}, {"_id": "698d417065c0d15a6d16209b", "name": "Shuangshuang Tian", "hidden": false}, {"_id": "698d417065c0d15a6d16209c", "name": "Siqi Liu", "hidden": false}, {"_id": "698d417065c0d15a6d16209d", "name": "Siye Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16209e", "name": "Siyu Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16209f", "name": "Song Yuan", "hidden": false}, {"_id": "698d417065c0d15a6d1620a0", "name": "Tiancheng Cao", "hidden": false}, {"_id": "698d417065c0d15a6d1620a1", "name": "Tianchi Yue", "hidden": false}, {"_id": "698d417065c0d15a6d1620a2", "name": "Tianhao Cheng", "hidden": false}, {"_id": "698d417065c0d15a6d1620a3", "name": "Tianning Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620a4", "name": "Tingdan Luo", "hidden": false}, {"_id": "698d417065c0d15a6d1620a5", "name": "Wang You", "hidden": false}, {"_id": "698d417065c0d15a6d1620a6", "name": "Wei Ji", "hidden": false}, {"_id": "698d417065c0d15a6d1620a7", "name": "Wei Yuan", "hidden": false}, {"_id": "698d417065c0d15a6d1620a8", "name": "Wei Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620a9", "name": "Weibo Wu", "hidden": false}, {"_id": "698d417065c0d15a6d1620aa", "user": {"_id": "6657620ea496f7fcb67c3871", "avatarUrl": "/avatars/54fef1c835e6f6b478652d438a140d45.svg", "isPro": false, "fullname": "xieweihao", "user": "chalengr", "type": "user"}, "name": "Weihao Xie", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:48.216Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620ab", "name": "Wen Sun", "hidden": false}, {"_id": "698d417065c0d15a6d1620ac", "name": "Wenjin Deng", "hidden": false}, {"_id": "698d417065c0d15a6d1620ad", "user": {"_id": "650c04795510464e85b47470", "avatarUrl": "/avatars/98c194e77826b928c49659849f466dad.svg", "isPro": false, "fullname": "wen", "user": "zhengwenzhen", "type": "user"}, "name": "Wenzhen Zheng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:45.930Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620ae", "name": "Wuxun Xie", "hidden": false}, {"_id": "698d417065c0d15a6d1620af", "name": "Xiangfeng Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b0", "name": "Xiangwen Kong", "hidden": false}, {"_id": "698d417065c0d15a6d1620b1", "name": "Xiangyu Liu", "hidden": false}, {"_id": "698d417065c0d15a6d1620b2", "name": "Xiangyu Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b3", "name": "Xiaobo Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b4", "name": "Xiaojia Liu", "hidden": false}, {"_id": "698d417065c0d15a6d1620b5", "name": "Xiaolan Yuan", "hidden": false}, {"_id": "698d417065c0d15a6d1620b6", "name": "Xiaoran Jiao", "hidden": false}, {"_id": "698d417065c0d15a6d1620b7", "name": "Xiaoxiao Ren", "hidden": false}, {"_id": "698d417065c0d15a6d1620b8", "name": "Xiaoyun Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b9", "name": "Xin Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620ba", "name": "Xin Liu", "hidden": false}, {"_id": "698d417065c0d15a6d1620bb", "name": "Xin Wu", "hidden": false}, {"_id": "698d417065c0d15a6d1620bc", "name": "Xing Chen", "hidden": false}, {"_id": "698d417065c0d15a6d1620bd", "name": "Xingping Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620be", "name": "Xinran Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620bf", "name": "Xu Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620c0", "user": {"_id": "64ec5b64bfb2aa06a46ff2d6", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/Lgl55OtDWa0tzRI2ShpUe.jpeg", "isPro": false, "fullname": "xuan he", "user": "tpa115k31", "type": "user"}, "name": "Xuan He", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:36.240Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620c1", "name": "Xuanti Feng", "hidden": false}, {"_id": "698d417065c0d15a6d1620c2", "name": "Xuedan Cai", "hidden": false}, {"_id": "698d417065c0d15a6d1620c3", "name": "Xuqiang Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d1620c4", "name": "Yanbo Yu", "hidden": false}, {"_id": "698d417065c0d15a6d1620c5", "name": "Yang Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620c6", "name": "Yang Xu", "hidden": false}, {"_id": "698d417065c0d15a6d1620c7", "name": "Yanlin Lai", "hidden": false}, {"_id": "698d417065c0d15a6d1620c8", "name": "Yanming Xu", "hidden": false}, {"_id": "698d417065c0d15a6d1620c9", "name": "Yaoyu Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620ca", "name": "Yeqing Shen", "hidden": false}, {"_id": "698d417065c0d15a6d1620cb", "name": "Yibo Zhu", "hidden": false}, {"_id": "698d417065c0d15a6d1620cc", "name": "Yichen Lv", "hidden": false}, {"_id": "698d417065c0d15a6d1620cd", "name": "Yicheng Cao", "hidden": false}, {"_id": "698d417065c0d15a6d1620ce", "name": "Yifeng Gong", "hidden": false}, {"_id": "698d417065c0d15a6d1620cf", "name": "Yijing Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d0", "name": "Yikun Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d1", "name": "Yin Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620d2", "name": "Yingxiu Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620d3", "name": "Yinmin Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d4", "name": "Yitong Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d5", "name": "Yixuan Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d6", "name": "Yiyang Chen", "hidden": false}, {"_id": "698d417065c0d15a6d1620d7", "name": "Yongchi Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620d8", "name": "Yongshen Long", "hidden": false}, {"_id": "698d417065c0d15a6d1620d9", "name": "Yongyao Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620da", "name": "Yousong Guan", "hidden": false}, {"_id": "698d417065c0d15a6d1620db", "name": "Yu Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d1620dc", "name": "Yuang Peng", "hidden": false}, {"_id": "698d417065c0d15a6d1620dd", "name": "Yuanhao Ding", "hidden": false}, {"_id": "698d417065c0d15a6d1620de", "name": "Yuantao Fan", "hidden": false}, {"_id": "698d417065c0d15a6d1620df", "name": "Yuanzhen Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620e0", "name": "Yuchu Luo", "hidden": false}, {"_id": "698d417065c0d15a6d1620e1", "name": "Yudi Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620e2", "name": "Yue Peng", "hidden": false}, {"_id": "698d417065c0d15a6d1620e3", "name": "Yueqiang Lin", "hidden": false}, {"_id": "698d417065c0d15a6d1620e4", "name": "Yufan Lu", "hidden": false}, {"_id": "698d417065c0d15a6d1620e5", "name": "Yuling Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620e6", "name": "Yunzhou Ju", "hidden": false}, {"_id": "698d417065c0d15a6d1620e7", "name": "Yurong Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620e8", "name": "Yusheng Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620e9", "name": "Yuxiang Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620ea", "name": "Yuyang Chen", "hidden": false}, {"_id": "698d417065c0d15a6d1620eb", "name": "Yuzhu Cai", "hidden": false}, {"_id": "698d417065c0d15a6d1620ec", "name": "Zejia Weng", "hidden": false}, {"_id": "698d417065c0d15a6d1620ed", "name": "Zetao Hong", "hidden": false}, {"_id": "698d417065c0d15a6d1620ee", "name": "Zexi Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620ef", "name": "Zhe Xie", "hidden": false}, {"_id": "698d417065c0d15a6d1620f0", "name": "Zheng Ge", "hidden": false}, {"_id": "698d417065c0d15a6d1620f1", "name": "Zheng Gong", "hidden": false}, {"_id": "698d417065c0d15a6d1620f2", "name": "Zheng Zeng", "hidden": false}, {"_id": "698d417065c0d15a6d1620f3", "user": {"_id": "63607ace9ddc44e710e13f0f", "avatarUrl": "/avatars/b5f331549562aea4a5c8b681fd9da1ff.svg", "isPro": false, "fullname": "zy", "user": "lu-vae", "type": "user"}, "name": "Zhenyi Lu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:50.532Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620f4", "name": "Zhewei Huang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f5", "name": "Zhichao Chang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f6", "name": "Zhiguo Huang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f7", "name": "Zhiheng Hu", "hidden": false}, {"_id": "698d417065c0d15a6d1620f8", "name": "Zidong Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f9", "name": "Zili Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620fa", "name": "Ziqi Ren", "hidden": false}, {"_id": "698d417065c0d15a6d1620fb", "name": "Zixin Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620fc", "name": "Zixuan Wang", "hidden": false}], "publishedAt": "2026-02-11T07:53:51.000Z", "submittedOnDailyAt": "2026-02-12T00:26:49.880Z", "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.", "upvotes": 150, "discussionId": "698d417165c0d15a6d1620fd", "githubRepo": "https://github.com/stepfun-ai/Step-3.5-Flash", "githubRepoAddedBy": "user", "ai_summary": "Step 3.5 Flash is a sparse Mixture-of-Experts model that achieves frontier-level agentic intelligence through efficient parameter utilization and optimized attention mechanisms, demonstrating strong performance across multiple benchmarks.", "ai_keywords": ["Mixture-of-Experts", "sparse MoE", "foundation model", "active parameters", "interleaved attention", "sliding-window attention", "full attention", "Multi-Token Prediction", "reinforcement learning", "verifiable signals", "preference feedback", "off-policy training", "self-improvement", "IMO-AnswerBench", "LiveCodeBench", "tau2-Bench", "BrowseComp", "Terminal-Bench"], "githubStars": 1245, "organization": {"_id": "66e43eae9d477f566f937935", "name": "stepfun-ai", "fullname": "StepFun", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66935cee39002fc0569c2943/Qv8QPbkgoKE3wR4jTzHiy.png"}, "summary_zh": "<ul>\n    <li>Step 3.5 Flash \u662f\u4e00\u79cd\u7a00\u758f\u7684\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u65e8\u5728\u63d0\u9ad8\u667a\u80fd\u4f53\u7684\u63a8\u7406\u80fd\u529b\u548c\u6267\u884c\u6548\u7387\u3002</li>\n    <li>\u5b83\u4f7f\u7528\u4e00\u4e2a\u5305\u542b1960\u4ebf\u4e2a\u53c2\u6570\u7684\u57fa\u7840\u6a21\u578b\u548c110\u4ebf\u4e2a\u6d3b\u8dc3\u53c2\u6570\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002</li>\n    <li>\u8be5\u6a21\u578b\u901a\u8fc7\u4f18\u5316\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u6807\u8bb0\u9884\u6d4b\uff0c\u51cf\u5c11\u591a\u8f6e\u4ea4\u4e92\u7684\u5ef6\u8fdf\u548c\u6210\u672c\u3002</li>\n    <li>Step 3.5 Flash \u5728\u591a\u4e2a\u4efb\u52a1\uff08\u5982\u6570\u5b66\u3001\u7f16\u7801\u548c\u5de5\u5177\u4f7f\u7528\uff09\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u6027\u80fd\u4e0e\u524d\u6cbf\u6a21\u578b\u76f8\u5f53\u3002</li>\n    <li>\u5b83\u4e3a\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u90e8\u7f72\u590d\u6742\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u57fa\u7840\u3002 </li>\n</ul>", "summary_simple": "<ul>\n    <li>Step 3.5 Flash is a new model that combines smart decision-making with efficient computing.</li>\n    <li>It uses a large 196 billion parameter base with 11 billion active parameters for faster performance.</li>\n    <li>The model is designed to improve how agents learn and perform tasks in coding, math, and using tools.</li>\n    <li>It shows strong results on various benchmarks, performing similarly to advanced models like GPT-5.2 xHigh.</li>\n    <li>This model aims to make it easier to use intelligent agents in real-world situations.</li>\n</ul>"}, "publishedAt": "2026-02-11T02:53:51.000Z", "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters", "summary": "We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.10604.png", "numComments": 3, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 231, "isUserFollowing": false}, "organization": {"_id": "66e43eae9d477f566f937935", "name": "stepfun-ai", "fullname": "StepFun", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66935cee39002fc0569c2943/Qv8QPbkgoKE3wR4jTzHiy.png"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.09082", "authors": [{"_id": "698bea506052d3bed96309cb", "name": "Veuns-Team", "hidden": false}, {"_id": "698bea506052d3bed96309cd", "name": "Changlong Gao", "hidden": false}, {"_id": "698bea506052d3bed96309ce", "user": {"_id": "60d2a2984956988b63753371", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60d2a2984956988b63753371/apXIcWbi7jnLVH37CdMTV.jpeg", "isPro": false, "fullname": "Zhangxuan Gu", "user": "zhangxgu", "type": "user"}, "name": "Zhangxuan Gu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:15:14.456Z", "hidden": false}, {"_id": "698bea506052d3bed96309cf", "name": "Yulin Liu", "hidden": false}, {"_id": "698bea506052d3bed96309d0", "name": "Xinyu Qiu", "hidden": false}, {"_id": "698bea506052d3bed96309d1", "name": "Shuheng Shen", "hidden": false}, {"_id": "698bea506052d3bed96309d2", "name": "Yue Wen", "hidden": false}, {"_id": "698bea506052d3bed96309d3", "name": "Tianyu Xia", "hidden": false}, {"_id": "698bea506052d3bed96309d4", "name": "Zhenyu Xu", "hidden": false}, {"_id": "698bea506052d3bed96309d5", "user": {"_id": "64cb238576200ec80fe988f8", "avatarUrl": "/avatars/42c48710c7881c9dfbcc075fec3cb600.svg", "isPro": false, "fullname": "zeus", "user": "zengw", "type": "user"}, "name": "Zhengwen Zeng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:24:43.235Z", "hidden": false}, {"_id": "698bea506052d3bed96309d6", "user": {"_id": "654c9dac09dd7ef524a0be1e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/654c9dac09dd7ef524a0be1e/T4glmZthS0mJydhvGZGKH.png", "isPro": false, "fullname": "beitongzhou", "user": "syorami", "type": "user"}, "name": "Beitong Zhou", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:15:11.859Z", "hidden": false}, {"_id": "698bea506052d3bed96309d7", "name": "Xingran Zhou", "hidden": false}, {"_id": "698bea506052d3bed96309d8", "name": "Weizhi Chen", "hidden": false}, {"_id": "698bea506052d3bed96309d9", "name": "Sunhao Dai", "hidden": false}, {"_id": "698bea506052d3bed96309da", "name": "Jingya Dou", "hidden": false}, {"_id": "698bea506052d3bed96309db", "name": "Yichen Gong", "hidden": false}, {"_id": "698bea506052d3bed96309dc", "name": "Yuan Guo", "hidden": false}, {"_id": "698bea506052d3bed96309dd", "name": "Zhenlin Guo", "hidden": false}, {"_id": "698bea506052d3bed96309de", "user": {"_id": "65e0763a9299e96ee674876e", "avatarUrl": "/avatars/0ea342c9f72fa3b8a8f634559d094907.svg", "isPro": false, "fullname": "fengdian", "user": "fengrudian", "type": "user"}, "name": "Feng Li", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:16:04.463Z", "hidden": false}, {"_id": "698bea506052d3bed96309df", "name": "Qian Li", "hidden": false}, {"_id": "698bea506052d3bed96309e0", "name": "Jinzhen Lin", "hidden": false}, {"_id": "698bea506052d3bed96309e1", "name": "Yuqi Zhou", "hidden": false}, {"_id": "698bea506052d3bed96309e2", "name": "Linchao Zhu", "hidden": false}, {"_id": "698bea506052d3bed96309e3", "name": "Liang Chen", "hidden": false}, {"_id": "698bea506052d3bed96309e4", "name": "Zhenyu Guo", "hidden": false}, {"_id": "698bea506052d3bed96309e5", "name": "Changhua Meng", "hidden": false}, {"_id": "698bea506052d3bed96309e6", "name": "Weiqiang Wang", "hidden": false}], "publishedAt": "2026-02-09T18:43:40.000Z", "submittedOnDailyAt": "2026-02-11T00:10:55.649Z", "title": "UI-Venus-1.5 Technical Report", "submittedOnDailyBy": {"_id": "60d2a2984956988b63753371", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60d2a2984956988b63753371/apXIcWbi7jnLVH37CdMTV.jpeg", "isPro": false, "fullname": "Zhangxuan Gu", "user": "zhangxgu", "type": "user"}, "summary": "GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging.In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications.The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios.Compared to our previous version, UI-Venus-1.5 introduces three key technical advances: (1) a comprehensive Mid-Training stage leveraging 10 billion tokens across 30+ datasets to establish foundational GUI semantics; (2) Online Reinforcement Learning with full-trajectory rollouts, aligning training objectives with long-horizon, dynamic navigation in large-scale environments; and (3) a single unified GUI Agent constructed via Model Merging, which synthesizes domain-specific models (grounding, web, and mobile) into one cohesive checkpoint. Extensive evaluations demonstrate that UI-Venus-1.5 establishes new state-of-the-art performance on benchmarks such as ScreenSpot-Pro (69.6%), VenusBench-GD (75.0%), and AndroidWorld (77.6%), significantly outperforming previous strong baselines. In addition, UI-Venus-1.5 demonstrates robust navigation capabilities across a variety of Chinese mobile apps, effectively executing user instructions in real-world scenarios. Code: https://github.com/inclusionAI/UI-Venus; Model: https://huggingface.co/collections/inclusionAI/ui-venus", "upvotes": 143, "discussionId": "698bea516052d3bed96309e7", "projectPage": "https://ui-venus.github.io/UI-Venus-1.5/", "githubRepo": "https://github.com/inclusionAI/UI-Venus/blob/UI-Venus-1.5", "githubRepoAddedBy": "user", "ai_summary": "UI-Venus-1.5 is a unified GUI agent with improved performance through mid-training stages, online reinforcement learning, and model merging techniques.", "ai_keywords": ["GUI agents", "Mid-Training stage", "Online Reinforcement Learning", "full-trajectory rollouts", "Model Merging", "dense variants", "mixture-of-experts variant"], "githubStars": 708, "organization": {"_id": "67aea5c8f086ab0f70ed97c9", "name": "inclusionAI", "fullname": "inclusionAI", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/662e1f9da266499277937d33/fyKuazRifqiaIO34xrhhm.jpeg"}, "summary_zh": "<ul>\n    <li>UI-Venus-1.5\u662f\u4e00\u79cd\u65b0\u7684\u7edf\u4e00GUI\u4ee3\u7406\uff0c\u65e8\u5728\u63d0\u5347\u6570\u5b57\u73af\u5883\u4e2d\u7684\u4ea4\u4e92\u81ea\u52a8\u5316\u3002</li>\n    <li>\u8be5\u6a21\u578b\u6709\u4e24\u79cd\u5bc6\u96c6\u578b\u53d8\u4f53\uff082B\u548c8B\uff09\u4ee5\u53ca\u4e00\u79cd\u6df7\u5408\u4e13\u5bb6\u53d8\u4f53\uff0830B-A3B\uff09\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u5e94\u7528\u573a\u666f\u3002</li>\n    <li>\u76f8\u8f83\u4e8e\u4e4b\u524d\u7684\u7248\u672c\uff0cUI-Venus-1.5\u5f15\u5165\u4e86\u4e09\u4e2a\u6280\u672f\u8fdb\u6b65\uff0c\u5305\u62ec\u5168\u9762\u7684\u4e2d\u671f\u8bad\u7ec3\u9636\u6bb5\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u3002</li>\n    <li>UI-Venus-1.5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8fbe\u5230\u65b0\u7684\u6700\u4f73\u6210\u7ee9\uff0c\u663e\u8457\u8d85\u8d8a\u4e86\u4e4b\u524d\u7684\u6a21\u578b\u3002</li>\n    <li>\u8be5\u6a21\u578b\u5728\u4e2d\u56fd\u624b\u673a\u5e94\u7528\u4e2d\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u5bfc\u822a\u80fd\u529b\uff0c\u80fd\u591f\u6709\u6548\u6267\u884c\u7528\u6237\u6307\u4ee4\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>UI-Venus-1.5 is a new GUI agent designed to automate tasks in digital environments effectively.</li>\n    <li>It includes two main models (2B and 8B) and a larger model (30B-A3B) to suit different application needs.</li>\n    <li>Key improvements include better training methods using a large amount of data, online learning for better navigation, and merging different models into one.</li>\n    <li>UI-Venus-1.5 shows top performance on several benchmarks, outperforming previous models significantly.</li>\n    <li>It can navigate and carry out tasks in various Chinese mobile apps, demonstrating strong real-world application capabilities.</li>\n</ul>"}, "publishedAt": "2026-02-09T13:43:40.000Z", "title": "UI-Venus-1.5 Technical Report", "summary": "GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging.In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications.The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios.Compared to our previous version, UI-Venus-1.5 introduces three key technical advances: (1) a comprehensive Mid-Training stage leveraging 10 billion tokens across 30+ datasets to establish foundational GUI semantics; (2) Online Reinforcement Learning with full-trajectory rollouts, aligning training objectives with long-horizon, dynamic navigation in large-scale environments; and (3) a single unified GUI Agent constructed via Model Merging, which synthesizes domain-specific models (grounding, web, and mobile) into one cohesive checkpoint. Extensive evaluations demonstrate that UI-Venus-1.5 establishes new state-of-the-art performance on benchmarks such as ScreenSpot-Pro (69.6%), VenusBench-GD (75.0%), and AndroidWorld (77.6%), significantly outperforming previous strong baselines. In addition, UI-Venus-1.5 demonstrates robust navigation capabilities across a variety of Chinese mobile apps, effectively executing user instructions in real-world scenarios. Code: https://github.com/inclusionAI/UI-Venus; Model: https://huggingface.co/collections/inclusionAI/ui-venus", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.09082.png", "numComments": 2, "submittedBy": {"_id": "60d2a2984956988b63753371", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60d2a2984956988b63753371/apXIcWbi7jnLVH37CdMTV.jpeg", "fullname": "Zhangxuan Gu", "name": "zhangxgu", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 8, "isUserFollowing": false}, "organization": {"_id": "67aea5c8f086ab0f70ed97c9", "name": "inclusionAI", "fullname": "inclusionAI", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/662e1f9da266499277937d33/fyKuazRifqiaIO34xrhhm.jpeg"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.08794", "authors": [{"_id": "698ac65d1b2dc6b37d61b1c2", "name": "SII-OpenMOSS Team", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1c4", "name": "Donghua Yu", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1c5", "name": "Mingshu Chen", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1c6", "name": "Qi Chen", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1c7", "name": "Qi Luo", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1c8", "name": "Qianyi Wu", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1c9", "user": {"_id": "63ec4715c81b6a52391c46b8", "avatarUrl": "/avatars/496819b5075a1a834a2b9edeb068c80e.svg", "isPro": false, "fullname": "QinyuanCheng", "user": "Cqy2019", "type": "user"}, "name": "Qinyuan Cheng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-10T09:05:07.400Z", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1ca", "name": "Ruixiao Li", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1cb", "user": {"_id": "62c14609ac1b639c2d87192c", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656833489364-noauth.png", "isPro": false, "fullname": "SII-liangtianyi", "user": "tianyilt", "type": "user"}, "name": "Tianyi Liang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-10T09:05:10.522Z", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1cc", "name": "Wenbo Zhang", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1cd", "name": "Wenming Tu", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1ce", "name": "Xiangyu Peng", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1cf", "name": "Yang Gao", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1d0", "name": "Yanru Huo", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1d1", "user": {"_id": "69158ffc0153b85a677dcc46", "avatarUrl": "/avatars/c9c5f60522f2a8f370d790ea9938b090.svg", "isPro": false, "fullname": "Ying Zhu", "user": "Auraithm", "type": "user"}, "name": "Ying Zhu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-10T09:27:41.440Z", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1d2", "name": "Yinze Luo", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1d3", "name": "Yiyang Zhang", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1d4", "name": "Yuerong Song", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1d5", "name": "Zhe Xu", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1d6", "name": "Zhiyu Zhang", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1d7", "name": "Chenchen Yang", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1d8", "name": "Cheng Chang", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1d9", "name": "Chushu Zhou", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1da", "name": "Hanfu Chen", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1db", "name": "Hongnan Ma", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1dc", "name": "Jiaxi Li", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1dd", "name": "Jingqi Tong", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1de", "name": "Junxi Liu", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1df", "name": "Ke Chen", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1e0", "name": "Shimin Li", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1e1", "name": "Songlin Wang", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1e2", "name": "Wei Jiang", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1e3", "name": "Zhaoye Fei", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1e4", "name": "Zhiyuan Ning", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1e5", "name": "Chunguo Li", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1e6", "name": "Chenhui Li", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1e7", "name": "Ziwei He", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1e8", "name": "Zengfeng Huang", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1e9", "name": "Xie Chen", "hidden": false}, {"_id": "698ac65d1b2dc6b37d61b1ea", "name": "Xipeng Qiu", "hidden": false}], "publishedAt": "2026-02-09T15:31:54.000Z", "submittedOnDailyAt": "2026-02-10T03:18:59.260Z", "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation", "submittedOnDailyBy": {"_id": "62c14609ac1b639c2d87192c", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656833489364-noauth.png", "isPro": false, "fullname": "SII-liangtianyi", "user": "tianyilt", "type": "user"}, "summary": "Audio is indispensable for real-world video, yet generation models have largely overlooked audio components. Current approaches to producing audio-visual content often rely on cascaded pipelines, which increase cost, accumulate errors, and degrade overall quality. While systems such as Veo 3 and Sora 2 emphasize the value of simultaneous generation, joint multimodal modeling introduces unique challenges in architecture, data, and training. Moreover, the closed-source nature of existing systems limits progress in the field. In this work, we introduce MOVA (MOSS Video and Audio), an open-source model capable of generating high-quality, synchronized audio-visual content, including realistic lip-synced speech, environment-aware sound effects, and content-aligned music. MOVA employs a Mixture-of-Experts (MoE) architecture, with a total of 32B parameters, of which 18B are active during inference. It supports IT2VA (Image-Text to Video-Audio) generation task. By releasing the model weights and code, we aim to advance research and foster a vibrant community of creators. The released codebase features comprehensive support for efficient inference, LoRA fine-tuning, and prompt enhancement.", "upvotes": 131, "discussionId": "698ac65e1b2dc6b37d61b1eb", "projectPage": "https://mosi.cn/models/mova", "githubRepo": "https://github.com/OpenMOSS/MOVA", "githubRepoAddedBy": "user", "ai_summary": "MOVA is an open-source model that generates synchronized audio-visual content using a Mixture-of-Experts architecture with 32 billion parameters, supporting image-text to video-audio generation tasks.", "ai_keywords": ["Mixture-of-Experts", "MoE", "audio-visual content", "lip-synced speech", "sound effects", "content-aligned music", "IT2VA", "efficient inference", "LoRA fine-tuning", "prompt enhancement"], "githubStars": 579, "organization": {"_id": "613b0dee83ec35d460684607", "name": "OpenMOSS-Team", "fullname": "OpenMOSS", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61457b8deff2c9fdb4de4988/N5b9663zQ4uq5_OTNlnmw.png"}, "summary_zh": "<ul>\n    <li>\u97f3\u9891\u5bf9\u73b0\u5b9e\u89c6\u9891\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u751f\u6210\u6a21\u578b\u901a\u5e38\u5ffd\u89c6\u4e86\u97f3\u9891\u90e8\u5206\u3002</li>\n    <li>\u76ee\u524d\u7684\u97f3\u89c6\u9891\u5185\u5bb9\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u7ea7\u8054\u6d41\u7a0b\uff0c\u5bfc\u81f4\u6210\u672c\u9ad8\u3001\u9519\u8bef\u79ef\u7d2f\u548c\u8d28\u91cf\u4e0b\u964d\u3002</li>\n    <li>MOVA\uff08MOSS\u89c6\u9891\u4e0e\u97f3\u9891\uff09\u662f\u4e00\u4e2a\u5f00\u6e90\u6a21\u578b\uff0c\u53ef\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u540c\u6b65\u7684\u97f3\u89c6\u9891\u5185\u5bb9\uff0c\u5305\u62ec\u771f\u5b9e\u7684\u53e3\u578b\u540c\u6b65\u8bed\u8a00\u548c\u73af\u5883\u97f3\u6548\u3002</li>\n    <li>MOVA\u4f7f\u7528\u4e86\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff08MoE\uff09\uff0c\u603b\u5171\u6709320\u4ebf\u53c2\u6570\uff0c\u5176\u4e2d180\u4ebf\u5728\u63a8\u7406\u65f6\u6fc0\u6d3b\u3002</li>\n    <li>\u8be5\u6a21\u578b\u7684\u6743\u91cd\u548c\u4ee3\u7801\u5df2\u516c\u5f00\uff0c\u65e8\u5728\u63a8\u52a8\u7814\u7a76\u5e76\u4fc3\u8fdb\u521b\u4f5c\u8005\u793e\u533a\u7684\u53d1\u5c55\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Most video generation models ignore the important audio aspect, leading to poor quality and increased costs.</li>\n    <li>Current methods often use separate processes for audio and video, which can cause errors and reduce overall quality.</li>\n    <li>MOVA is an open-source model that generates high-quality audio and video together, including realistic speech and sound effects.</li>\n    <li>This model uses a complex architecture with many parameters, allowing it to generate synchronized content effectively.</li>\n    <li>By sharing the model and code, the goal is to encourage further research and support a community of creators.</li>\n</ul>"}, "publishedAt": "2026-02-09T10:31:54.000Z", "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation", "summary": "Audio is indispensable for real-world video, yet generation models have largely overlooked audio components. Current approaches to producing audio-visual content often rely on cascaded pipelines, which increase cost, accumulate errors, and degrade overall quality. While systems such as Veo 3 and Sora 2 emphasize the value of simultaneous generation, joint multimodal modeling introduces unique challenges in architecture, data, and training. Moreover, the closed-source nature of existing systems limits progress in the field. In this work, we introduce MOVA (MOSS Video and Audio), an open-source model capable of generating high-quality, synchronized audio-visual content, including realistic lip-synced speech, environment-aware sound effects, and content-aligned music. MOVA employs a Mixture-of-Experts (MoE) architecture, with a total of 32B parameters, of which 18B are active during inference. It supports IT2VA (Image-Text to Video-Audio) generation task. By releasing the model weights and code, we aim to advance research and foster a vibrant community of creators. The released codebase features comprehensive support for efficient inference, LoRA fine-tuning, and prompt enhancement.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.08794.png", "numComments": 1, "submittedBy": {"_id": "62c14609ac1b639c2d87192c", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656833489364-noauth.png", "fullname": "SII-liangtianyi", "name": "tianyilt", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 5, "isUserFollowing": false}, "organization": {"_id": "613b0dee83ec35d460684607", "name": "OpenMOSS-Team", "fullname": "OpenMOSS", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61457b8deff2c9fdb4de4988/N5b9663zQ4uq5_OTNlnmw.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.08222", "authors": [{"_id": "698ad20e1b2dc6b37d61b227", "user": {"_id": "64afe1653361f887816da303", "avatarUrl": "/avatars/320d71adacfad9dd5db064b4ed3dec2b.svg", "isPro": false, "fullname": "chenzehao", "user": "chhao", "type": "user"}, "name": "Zehao Chen", "status": "claimed_verified", "statusLastChangedAt": "2026-02-10T09:04:42.021Z", "hidden": false}, {"_id": "698ad20e1b2dc6b37d61b228", "name": "Gongxun Li", "hidden": false}, {"_id": "698ad20e1b2dc6b37d61b229", "name": "Tianxiang Ai", "hidden": false}, {"_id": "698ad20e1b2dc6b37d61b22a", "name": "Yifei Li", "hidden": false}, {"_id": "698ad20e1b2dc6b37d61b22b", "name": "Zixuan Huang", "hidden": false}, {"_id": "698ad20e1b2dc6b37d61b22c", "name": "Wang Zhou", "hidden": false}, {"_id": "698ad20e1b2dc6b37d61b22d", "name": "Fuzhen Zhuang", "hidden": false}, {"_id": "698ad20e1b2dc6b37d61b22e", "name": "Xianglong Liu", "hidden": false}, {"_id": "698ad20e1b2dc6b37d61b22f", "name": "Jianxin Li", "hidden": false}, {"_id": "698ad20e1b2dc6b37d61b230", "name": "Deqing Wang", "hidden": false}, {"_id": "698ad20e1b2dc6b37d61b231", "user": {"_id": "68345345f4bbf856e2d708e2", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/68345345f4bbf856e2d708e2/L5H2HNCuWje3ti2tNbC5p.jpeg", "isPro": false, "fullname": "Yikun B", "user": "Yikunb", "type": "user"}, "name": "Yikun Ban", "status": "claimed_verified", "statusLastChangedAt": "2026-02-10T09:04:44.617Z", "hidden": false}], "publishedAt": "2026-02-09T02:50:40.000Z", "submittedOnDailyAt": "2026-02-10T04:36:28.975Z", "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger", "submittedOnDailyBy": {"_id": "68345345f4bbf856e2d708e2", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/68345345f4bbf856e2d708e2/L5H2HNCuWje3ti2tNbC5p.jpeg", "isPro": false, "fullname": "Yikun B", "user": "Yikunb", "type": "user"}, "summary": "As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning, WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.", "upvotes": 118, "discussionId": "698ad20e1b2dc6b37d61b232", "githubRepo": "https://github.com/chenzehao82/Weak-Driven-Learning", "githubRepoAddedBy": "user", "ai_summary": "WMSS is a post-training paradigm that uses weak model checkpoints to identify and fill learning gaps, enabling continued improvement beyond conventional saturation points in large language models.", "ai_keywords": ["post-training optimization", "large language models", "saturation bottleneck", "weak checkpoints", "entropy dynamics", "compensatory learning", "learning gaps"], "githubStars": 39, "summary_zh": "<ul>\n    <li>\u540e\u8bad\u7ec3\u4f18\u5316\u662f\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5173\u952e\uff0c\u4f46\u6a21\u578b\u4fe1\u5fc3\u589e\u5f3a\u540e\uff0c\u8fdb\u4e00\u6b65\u8bad\u7ec3\u6548\u679c\u9012\u51cf\u3002</li>\n    <li>\u73b0\u6709\u65b9\u6cd5\u5f3a\u5316\u76ee\u6807\u9884\u6d4b\uff0c\u4f46\u6a21\u578b\u7684\u5386\u53f2\u5f31\u72b6\u6001\u4e2d\u4ecd\u7136\u5b58\u5728\u6709\u4ef7\u503c\u7684\u76d1\u7763\u4fe1\u53f7\u3002</li>\n    <li>\u6211\u4eec\u63d0\u51faWMSS\uff08\u5f31\u4ee3\u7406\u53ef\u4ee5\u4f7f\u5f3a\u4ee3\u7406\u66f4\u5f3a\uff09\uff0c\u5229\u7528\u5f31\u68c0\u67e5\u70b9\u6307\u5bfc\u6301\u7eed\u4f18\u5316\u3002</li>\n    <li>WMSS\u901a\u8fc7\u71b5\u52a8\u6001\u8bc6\u522b\u53ef\u6062\u590d\u7684\u5b66\u4e60\u5dee\u8ddd\uff0c\u5e76\u901a\u8fc7\u8865\u507f\u5b66\u4e60\u6765\u5f3a\u5316\u8fd9\u4e9b\u5dee\u8ddd\u3002</li>\n    <li>\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u7684\u4ee3\u7406\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u6ca1\u6709\u589e\u52a0\u63a8\u7406\u6210\u672c\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Large language models often stop improving after reaching high confidence levels during training.</li>\n    <li>Current methods focus on reinforcing what the models already predict well, missing out on useful information from their earlier, weaker states.</li>\n    <li>The proposed method, WMSS, uses these weaker states to help further improve model performance.</li>\n    <li>WMSS identifies areas where models can still learn and enhances their abilities through targeted training.</li>\n    <li>Tests show that models using WMSS perform better in tasks like math reasoning and code generation without increasing inference costs.</li>\n</ul>"}, "publishedAt": "2026-02-08T21:50:40.000Z", "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger", "summary": "As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning, WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.08222.png", "numComments": 4, "submittedBy": {"_id": "68345345f4bbf856e2d708e2", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/68345345f4bbf856e2d708e2/L5H2HNCuWje3ti2tNbC5p.jpeg", "fullname": "Yikun B", "name": "Yikunb", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 4, "isUserFollowing": false}, "isAuthorParticipating": true}, {"paper": {"id": "2602.12036", "authors": [{"_id": "698eeb55cace060ff123af56", "user": {"_id": "64e2d169d2af12910d682130", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64e2d169d2af12910d682130/VG8UdqJCJGc0K4G0P0XQP.jpeg", "isPro": false, "fullname": "xuxin", "user": "xx18", "type": "user"}, "name": "Xin Xu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-13T09:36:02.476Z", "hidden": false}, {"_id": "698eeb55cace060ff123af57", "name": "Clive Bai", "hidden": false}, {"_id": "698eeb55cace060ff123af58", "name": "Kai Yang", "hidden": false}, {"_id": "698eeb55cace060ff123af59", "name": "Tianhao Chen", "hidden": false}, {"_id": "698eeb55cace060ff123af5a", "name": "Yangkun Chen", "hidden": false}, {"_id": "698eeb55cace060ff123af5b", "name": "Weijie Liu", "hidden": false}, {"_id": "698eeb55cace060ff123af5c", "name": "Hao Chen", "hidden": false}, {"_id": "698eeb55cace060ff123af5d", "name": "Yang Wang", "hidden": false}, {"_id": "698eeb55cace060ff123af5e", "name": "Saiyong Yang", "hidden": false}, {"_id": "698eeb55cace060ff123af5f", "name": "Can Yang", "hidden": false}], "publishedAt": "2026-02-12T15:03:37.000Z", "submittedOnDailyAt": "2026-02-13T06:44:41.991Z", "title": "Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models", "submittedOnDailyBy": {"_id": "64e2d169d2af12910d682130", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64e2d169d2af12910d682130/VG8UdqJCJGc0K4G0P0XQP.jpeg", "isPro": false, "fullname": "xuxin", "user": "xx18", "type": "user"}, "summary": "Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.", "upvotes": 81, "discussionId": "698eeb55cace060ff123af60", "githubRepo": "https://github.com/XinXU-USTC/Composition-RL", "githubRepoAddedBy": "user", "ai_summary": "Composition-RL improves reasoning capabilities by automatically composing multiple problems into new verifiable questions for reinforcement learning training.", "ai_keywords": ["Reinforcement Learning with Verifiable Rewards", "verifiable prompts", "pass rate", "compositional prompts", "curriculum learning", "cross-domain RL"], "githubStars": 3, "organization": {"_id": "6645f953c39288df638dbdd5", "name": "Tencent-Hunyuan", "fullname": "Tencent Hunyuan", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/62d22496c58f969c152bcefd/woKSjt2wXvBNKussyYPsa.png"}, "summary_zh": "<ul>\n    <li>\u5927\u89c4\u6a21\u7684\u53ef\u9a8c\u8bc1\u63d0\u793a\u662f\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u6210\u529f\u7684\u57fa\u7840\uff0c\u4f46\u6269\u5c55\u8fd9\u4e9b\u63d0\u793a\u6210\u672c\u9ad8\u4e14\u5305\u542b\u8bb8\u591a\u65e0\u4fe1\u606f\u793a\u4f8b\u3002</li>\n    <li>\u7814\u7a76\u96c6\u4e2d\u5728\u4f18\u5148\u4f7f\u7528\u96be\u5ea6\u9ad8\u7684\u63d0\u793a\uff0c\u901a\u8fc7\u5176\u56de\u6eda\u901a\u8fc7\u7387\u4e3a0\u6765\u66f4\u597d\u5730\u5229\u7528\u6709\u9650\u7684\u8bad\u7ec3\u6570\u636e\u3002</li>\n    <li>\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5Composition-RL\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u5229\u7528\u6709\u9650\u7684\u53ef\u9a8c\u8bc1\u63d0\u793a\uff0c\u7279\u522b\u662f\u9488\u5bf9\u901a\u8fc7\u7387\u4e3a1\u7684\u63d0\u793a\u3002</li>\n    <li>Composition-RL\u81ea\u52a8\u5c06\u591a\u4e2a\u95ee\u9898\u7ec4\u5408\u6210\u65b0\u7684\u53ef\u9a8c\u8bc1\u95ee\u9898\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002</li>\n    <li>\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u4e14\u80fd\u901a\u8fc7\u9010\u6b65\u589e\u52a0\u7ec4\u5408\u6df1\u5ea6\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Large-scale prompts are important for Reinforcement Learning with Verifiable Rewards (RLVR) but are often unhelpful and expensive to create.</li>\n    <li>Current research focuses on using limited data more effectively by targeting difficult prompts that have a pass rate of 0.</li>\n    <li>Easy prompts with a pass rate of 1 become more common during training, making the data less effective.</li>\n    <li>Composition-RL is a new approach that combines multiple problems into a single question to improve training efficiency.</li>\n    <li>Tests show that Composition-RL enhances reasoning abilities and can be improved further by gradually increasing difficulty during training.</li>\n</ul>"}, "publishedAt": "2026-02-12T10:03:37.000Z", "title": "Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models", "summary": "Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12036.png", "numComments": 1, "submittedBy": {"_id": "64e2d169d2af12910d682130", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64e2d169d2af12910d682130/VG8UdqJCJGc0K4G0P0XQP.jpeg", "fullname": "xuxin", "name": "xx18", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 10, "isUserFollowing": false}, "organization": {"_id": "6645f953c39288df638dbdd5", "name": "Tencent-Hunyuan", "fullname": "Tencent Hunyuan", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/62d22496c58f969c152bcefd/woKSjt2wXvBNKussyYPsa.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.10063", "authors": [{"_id": "698bf4ef6052d3bed9630a96", "user": {"_id": "6895e7f146763431aea25ca4", "avatarUrl": "/avatars/52e550c3f7e8da2e31b63413e2e71e6c.svg", "isPro": false, "fullname": "Tianyi Jiang", "user": "LumosJiang", "type": "user"}, "name": "Tianyi Jiang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:33.352Z", "hidden": false}, {"_id": "698bf4ef6052d3bed9630a97", "name": "Arctanx An", "hidden": false}, {"_id": "698bf4ef6052d3bed9630a98", "name": "Hengyi Feng", "hidden": false}, {"_id": "698bf4ef6052d3bed9630a99", "name": "Naixin Zhai", "hidden": false}, {"_id": "698bf4ef6052d3bed9630a9a", "name": "Haodong Li", "hidden": false}, {"_id": "698bf4ef6052d3bed9630a9b", "user": {"_id": "64084fa192033c150738e4f2", "avatarUrl": "/avatars/dfff2216eb235c635e5abe6fda3084f0.svg", "isPro": false, "fullname": "Yu_xm", "user": "Yu2020", "type": "user"}, "name": "Xiaomin Yu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T12:34:26.745Z", "hidden": false}, {"_id": "698bf4ef6052d3bed9630a9c", "name": "Jiahui Liu", "hidden": false}, {"_id": "698bf4ef6052d3bed9630a9d", "name": "Hanwen Du", "hidden": false}, {"_id": "698bf4ef6052d3bed9630a9e", "name": "Shuo Zhang", "hidden": false}, {"_id": "698bf4ef6052d3bed9630a9f", "user": {"_id": "64aa645404e7b379feccc490", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64aa645404e7b379feccc490/4m8qcdy2OGK8visR5Jjl5.png", "isPro": false, "fullname": "Zhi Yang", "user": "yangzhi1", "type": "user"}, "name": "Zhi Yang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:35.722Z", "hidden": false}, {"_id": "698bf4ef6052d3bed9630aa0", "name": "Jie Huang", "hidden": false}, {"_id": "698bf4ef6052d3bed9630aa1", "name": "Yuhua Li", "hidden": false}, {"_id": "698bf4ef6052d3bed9630aa2", "name": "Yongxin Ni", "hidden": false}, {"_id": "698bf4ef6052d3bed9630aa3", "name": "Huacan Wang", "hidden": false}, {"_id": "698bf4ef6052d3bed9630aa4", "name": "Ronghao Chen", "hidden": false}], "publishedAt": "2026-02-10T18:31:47.000Z", "submittedOnDailyAt": "2026-02-11T00:51:58.024Z", "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes", "submittedOnDailyBy": {"_id": "64aa645404e7b379feccc490", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64aa645404e7b379feccc490/4m8qcdy2OGK8visR5Jjl5.png", "isPro": false, "fullname": "Zhi Yang", "user": "yangzhi1", "type": "user"}, "summary": "Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset (CoM), a training-free agentic framework that enables step-level adaptive mindset orchestration. CoM decomposes reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\\% and 4.72\\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency. Our code is publicly available at https://github.com/QuantaAlpha/chain-of-mindset{https://github.com/QuantaAlpha/chain-of-mindset}.", "upvotes": 62, "discussionId": "698bf4f06052d3bed9630aa5", "githubRepo": "https://github.com/QuantaAlpha/chain-of-mindset", "githubRepoAddedBy": "user", "ai_summary": "A novel training-free framework called Chain of Mindset enables step-level adaptive mindset orchestration for large language models by integrating spatial, convergent, divergent, and algorithmic reasoning approaches.", "ai_keywords": ["Chain of Mindset", "CoM", "agentic framework", "step-level adaptive mindset orchestration", "Spatial mindset", "Convergent mindset", "Divergent mindset", "Algorithmic mindset", "Meta-Agent", "bidirectional Context Gate", "reasoning efficiency", "large language models"], "githubStars": 18, "organization": {"_id": "68b33ab6a9ed99140481cf44", "name": "QuantaAlpha", "fullname": "QuantaAlpha", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/63f7767fbd28622c9b9915e9/DRN8PvmnpKmn2MSLQ7qhF.jpeg"}, "summary_zh": "<ul>\n    <li>\u4eba\u7c7b\u89e3\u51b3\u95ee\u9898\u65f6\u4f1a\u7ed3\u5408\u591a\u79cd\u601d\u7ef4\u65b9\u5f0f\uff0c\u800c\u4e0d\u662f\u53ea\u4f9d\u8d56\u5355\u4e00\u601d\u7ef4\u6a21\u5f0f\u3002</li>\n    <li>\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u63a8\u7406\u65f6\u5e38\u5e38\u4f7f\u7528\u56fa\u5b9a\u601d\u7ef4\u6a21\u5f0f\uff0c\u5ffd\u89c6\u4e0d\u540c\u9636\u6bb5\u9700\u8981\u4e0d\u540c\u601d\u7ef4\u65b9\u5f0f\u3002</li>\n    <li>\u4e3a\u4e86\u514b\u670d\u8fd9\u4e2a\u9650\u5236\uff0c\u63d0\u51fa\u4e86\u201c\u601d\u7ef4\u94fe\uff08Chain of Mindset, CoM\uff09\u201d\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u6bcf\u4e2a\u6b65\u9aa4\u7075\u6d3b\u8c03\u6574\u601d\u7ef4\u65b9\u5f0f\u3002</li>\n    <li>CoM\u5c06\u63a8\u7406\u5206\u89e3\u4e3a\u56db\u79cd\u4e0d\u540c\u7684\u601d\u7ef4\u65b9\u5f0f\uff1a\u7a7a\u95f4\u3001\u6536\u655b\u3001\u53d1\u6563\u548c\u7b97\u6cd5\u601d\u7ef4\u3002</li>\n    <li>\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cCoM\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u6574\u4f53\u51c6\u786e\u7387\u8d85\u8d8a\u6700\u5f3a\u57fa\u7ebf4.96%\u548c4.72%\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Human problem-solving uses multiple mindsets instead of just one for different tasks.</li>\n    <li>Current AI models often use a fixed mindset for all steps, which limits their intelligence.</li>\n    <li>The proposed Chain of Mindset (CoM) framework allows for adaptive mindset changes during problem-solving.</li>\n    <li>CoM uses four different mindsets: Spatial, Convergent, Divergent, and Algorithmic, selecting the best one as needed.</li>\n    <li>Tests show that CoM outperforms other models in tasks like math and code generation, improving accuracy significantly.</li>\n</ul>"}, "publishedAt": "2026-02-10T13:31:47.000Z", "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes", "summary": "Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset (CoM), a training-free agentic framework that enables step-level adaptive mindset orchestration. CoM decomposes reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\\% and 4.72\\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency. Our code is publicly available at https://github.com/QuantaAlpha/chain-of-mindset{https://github.com/QuantaAlpha/chain-of-mindset}.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.10063.png", "numComments": 1, "submittedBy": {"_id": "64aa645404e7b379feccc490", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64aa645404e7b379feccc490/4m8qcdy2OGK8visR5Jjl5.png", "fullname": "Zhi Yang", "name": "yangzhi1", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 3, "isUserFollowing": false}, "organization": {"_id": "68b33ab6a9ed99140481cf44", "name": "QuantaAlpha", "fullname": "QuantaAlpha", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/63f7767fbd28622c9b9915e9/DRN8PvmnpKmn2MSLQ7qhF.jpeg"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.12205", "authors": [{"_id": "698ea0f9cace060ff123ae3a", "name": "Dianyi Wang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae3b", "name": "Ruihang Li", "hidden": false}, {"_id": "698ea0f9cace060ff123ae3c", "name": "Feng Han", "hidden": false}, {"_id": "698ea0f9cace060ff123ae3d", "name": "Chaofan Ma", "hidden": false}, {"_id": "698ea0f9cace060ff123ae3e", "name": "Wei Song", "hidden": false}, {"_id": "698ea0f9cace060ff123ae3f", "name": "Siyuan Wang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae40", "name": "Yibin Wang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae41", "name": "Yi Xin", "hidden": false}, {"_id": "698ea0f9cace060ff123ae42", "name": "Hongjian Liu", "hidden": false}, {"_id": "698ea0f9cace060ff123ae43", "name": "Zhixiong Zhang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae44", "name": "Shengyuan Ding", "hidden": false}, {"_id": "698ea0f9cace060ff123ae45", "name": "Tianhang Wang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae46", "name": "Zhenglin Cheng", "hidden": false}, {"_id": "698ea0f9cace060ff123ae47", "name": "Tao Lin", "hidden": false}, {"_id": "698ea0f9cace060ff123ae48", "name": "Cheng Jin", "hidden": false}, {"_id": "698ea0f9cace060ff123ae49", "name": "Kaicheng Yu", "hidden": false}, {"_id": "698ea0f9cace060ff123ae4a", "name": "Jingjing Chen", "hidden": false}, {"_id": "698ea0f9cace060ff123ae4b", "name": "Wenjie Wang", "hidden": false}, {"_id": "698ea0f9cace060ff123ae4c", "name": "Zhongyu Wei", "hidden": false}, {"_id": "698ea0f9cace060ff123ae4d", "name": "Jiaqi Wang", "hidden": false}], "publishedAt": "2026-02-12T17:44:24.000Z", "submittedOnDailyAt": "2026-02-13T03:37:56.296Z", "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing", "submittedOnDailyBy": {"_id": "64b4eec4faa3181a5eab9c46", "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg", "isPro": true, "fullname": "Jiaqi Wang", "user": "myownskyW7", "type": "user"}, "summary": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.", "upvotes": 60, "discussionId": "698ea0f9cace060ff123ae4e", "projectPage": "https://deepgenteam.github.io/", "githubRepo": "https://github.com/DeepGenTeam/DeepGen", "githubRepoAddedBy": "user", "ai_summary": "A lightweight 5B unified multimodal model achieves competitive performance through hierarchical feature extraction, learnable think tokens, and progressive training strategies including alignment pre-training, joint supervised fine-tuning, and reinforcement learning with MR-GRPO.", "ai_keywords": ["unified multimodal models", "image generation", "image editing", "parameter scale", "VLM layers", "DiT representations", "Stacked Channel Bridging", "think tokens", "data-centric training strategy", "alignment pre-training", "joint supervised fine-tuning", "reinforcement learning", "MR-GRPO", "generation quality", "human preferences", "visual artifacts"], "githubStars": 36, "organization": {"_id": "683ebd0d913d82e703e77286", "name": "sii-research", "fullname": "Shanghai Innovation Institute", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6144a0c4ff1146bbd84d9865/SQAtyVRxNjp9L0CUi0tgI.png"}, "summary_zh": "<ul>\n    <li>DeepGen 1.0\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u7edf\u4e00\u6a21\u578b\uff0c\u53c2\u6570\u4ec5\u4e3a5\u4ebf\uff0c\u4f46\u529f\u80fd\u5f3a\u5927\uff0c\u80fd\u4e0e\u66f4\u5927\u6a21\u578b\u7ade\u4e89\u3002</li>\n    <li>\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u548c\u7cbe\u7ec6\u63a7\u5236\uff0c\u63d0\u51fa\u4e86\u201c\u5806\u53e0\u901a\u9053\u6865\u63a5\u201d\uff08SCB\uff09\u6846\u67b6\uff0c\u589e\u5f3a\u751f\u6210\u80fd\u529b\u3002</li>\n    <li>\u91c7\u7528\u4e86\u4e09\u9636\u6bb5\u7684\u6570\u636e\u4e2d\u5fc3\u8bad\u7ec3\u7b56\u7565\uff0c\u5305\u62ec\u5bf9\u9f50\u9884\u8bad\u7ec3\u3001\u8054\u5408\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u3002</li>\n    <li>DeepGen 1.0\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4e86\u66f4\u5927\u6a21\u578b\uff0c\u5982\u5728WISE\u4e0a\u63d0\u5347\u4e8628%\u3002</li>\n    <li>\u901a\u8fc7\u5f00\u6e90\u8bad\u7ec3\u4ee3\u7801\u3001\u6743\u91cd\u548c\u6570\u636e\u96c6\uff0c\u4fc3\u8fdb\u4e86\u7edf\u4e00\u591a\u6a21\u6001\u7814\u7a76\u7684\u666e\u53ca\u548c\u53d1\u5c55\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>DeepGen 1.0 is a new lightweight image generation and editing model with 5 billion parameters, which is much smaller than others that have over 10 billion parameters.</li>\n    <li>The model uses a technique called Stacked Channel Bridging (SCB) to improve understanding and control over generated images by combining features from different layers.</li>\n    <li>It has a three-step training process: pre-training on large datasets, joint fine-tuning on various tasks, and reinforcement learning to improve quality and alignment with human preferences.</li>\n    <li>Despite being trained on only 50 million samples, DeepGen 1.0 outperforms larger models in several benchmarks.</li>\n    <li>The creators are open-sourcing the training code, model weights, and datasets to support further research in multimodal technology.</li>\n</ul>"}, "publishedAt": "2026-02-12T12:44:24.000Z", "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing", "summary": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12205.png", "numComments": 1, "submittedBy": {"_id": "64b4eec4faa3181a5eab9c46", "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg", "fullname": "Jiaqi Wang", "name": "myownskyW7", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 25, "isUserFollowing": false}, "organization": {"_id": "683ebd0d913d82e703e77286", "name": "sii-research", "fullname": "Shanghai Innovation Institute", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6144a0c4ff1146bbd84d9865/SQAtyVRxNjp9L0CUi0tgI.png"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.08234", "authors": [{"_id": "698aba731b2dc6b37d61b0e4", "user": {"_id": "643e9ee6f6bb3c31a26e7bc4", "avatarUrl": "/avatars/acfaa7d6a23dada24c86b954c3be116a.svg", "isPro": false, "fullname": "Peng Xia", "user": "richardxp888", "type": "user"}, "name": "Peng Xia", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:18:58.896Z", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0e5", "name": "Jianwen Chen", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0e6", "name": "Hanyang Wang", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0e7", "name": "Jiaqi Liu", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0e8", "name": "Kaide Zeng", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0e9", "user": {"_id": "63234809155b0e2c44f354d6", "avatarUrl": "/avatars/60d38f8f0e12363f3f5e0388e635d7b6.svg", "isPro": false, "fullname": "Yu Wang", "user": "YuWangX", "type": "user"}, "name": "Yu Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:18:56.703Z", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0ea", "name": "Siwei Han", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0eb", "name": "Yiyang Zhou", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0ec", "name": "Xujiang Zhao", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0ed", "name": "Haifeng Chen", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0ee", "name": "Zeyu Zheng", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0ef", "name": "Cihang Xie", "hidden": false}, {"_id": "698aba731b2dc6b37d61b0f0", "name": "Huaxiu Yao", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/643e9ee6f6bb3c31a26e7bc4/L9mDRVV2qoifMcWtJ_1ib.jpeg"], "publishedAt": "2026-02-09T03:17:17.000Z", "submittedOnDailyAt": "2026-02-11T00:14:23.139Z", "title": "SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning", "submittedOnDailyBy": {"_id": "643e9ee6f6bb3c31a26e7bc4", "avatarUrl": "/avatars/acfaa7d6a23dada24c86b954c3be116a.svg", "isPro": false, "fullname": "Peng Xia", "user": "richardxp888", "type": "user"}, "summary": "Large Language Model (LLM) agents have shown stunning results in complex tasks, yet they often operate in isolation, failing to learn from past experiences. Existing memory-based methods primarily store raw trajectories, which are often redundant and noise-heavy. This prevents agents from extracting high-level, reusable behavioral patterns that are essential for generalization. In this paper, we propose SkillRL, a framework that bridges the gap between raw experience and policy improvement through automatic skill discovery and recursive evolution. Our approach introduces an experience-based distillation mechanism to build a hierarchical skill library SkillBank, an adaptive retrieval strategy for general and task-specific heuristics, and a recursive evolution mechanism that allows the skill library to co-evolve with the agent's policy during reinforcement learning. These innovations significantly reduce the token footprint while enhancing reasoning utility. Experimental results on ALFWorld, WebShop and seven search-augmented tasks demonstrate that SkillRL achieves state-of-the-art performance, outperforming strong baselines over 15.3% and maintaining robustness as task complexity increases. Code is available at this https://github.com/aiming-lab/SkillRL.", "upvotes": 56, "discussionId": "698aba731b2dc6b37d61b0f1", "githubRepo": "https://github.com/aiming-lab/SkillRL", "githubRepoAddedBy": "user", "ai_summary": "SkillRL enables LLM agents to improve through hierarchical skill discovery and recursive policy evolution, achieving superior performance on complex tasks while reducing computational overhead.", "ai_keywords": ["large language model agents", "reinforcement learning", "skill discovery", "recursive evolution", "skill library", "SkillBank", "experience-based distillation", "adaptive retrieval strategy", "policy improvement", "token footprint"], "githubStars": 140, "organization": {"_id": "669f9d1fec8789263c0e355a", "name": "UNC-ChapelHill", "fullname": "University of North Carolina at Chapel Hill", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/669f9c85bd649dba3b88e581/H5uB8_MCewnMtxEUnAvTL.png"}, "summary_zh": "<ul>\n    <li>\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7ecf\u5e38\u72ec\u7acb\u5de5\u4f5c\uff0c\u65e0\u6cd5\u4ece\u8fc7\u53bb\u7684\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u3002</li>\n    <li>\u73b0\u6709\u7684\u8bb0\u5fc6\u65b9\u6cd5\u4e3b\u8981\u5b58\u50a8\u539f\u59cb\u8f68\u8ff9\uff0c\u5bfc\u81f4\u4fe1\u606f\u5197\u4f59\u548c\u566a\u58f0\uff0c\u65e0\u6cd5\u63d0\u53d6\u9ad8\u5c42\u6b21\u7684\u53ef\u91cd\u7528\u884c\u4e3a\u6a21\u5f0f\u3002</li>\n    <li>\u672c\u6587\u63d0\u51fa\u4e86SkillRL\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u6280\u80fd\u53d1\u73b0\u548c\u9012\u5f52\u8fdb\u5316\u6765\u6539\u8fdb\u7b56\u7565\u3002</li>\n    <li>\u8be5\u65b9\u6cd5\u6784\u5efa\u4e86\u4e00\u4e2a\u6280\u80fd\u5e93\uff08SkillBank\uff09\uff0c\u91c7\u7528\u7ecf\u9a8c\u84b8\u998f\u673a\u5236\u548c\u81ea\u9002\u5e94\u68c0\u7d22\u7b56\u7565\uff0c\u63d0\u9ad8\u4e86\u5b66\u4e60\u6548\u7387\u3002</li>\n    <li>\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSkillRL\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8fc7\u5f3a\u57fa\u7ebf15.3%\uff0c\u5e76\u5728\u4efb\u52a1\u590d\u6742\u6027\u589e\u52a0\u65f6\u4fdd\u6301\u7a33\u5065\u6027\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Large Language Model (LLM) agents usually work alone and don't learn from their past actions.</li>\n    <li>Current memory methods store too much unnecessary data, making it hard for agents to find useful patterns.</li>\n    <li>The paper introduces SkillRL, a new framework that helps agents improve by discovering and evolving skills.</li>\n    <li>SkillRL includes a skill library called SkillBank, which helps agents use general and specific strategies effectively.</li>\n    <li>Tests show that SkillRL performs better than other methods by over 15.3%, even with more complex tasks.</li>\n</ul>"}, "publishedAt": "2026-02-08T22:17:17.000Z", "title": "SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning", "summary": "Large Language Model (LLM) agents have shown stunning results in complex tasks, yet they often operate in isolation, failing to learn from past experiences. Existing memory-based methods primarily store raw trajectories, which are often redundant and noise-heavy. This prevents agents from extracting high-level, reusable behavioral patterns that are essential for generalization. In this paper, we propose SkillRL, a framework that bridges the gap between raw experience and policy improvement through automatic skill discovery and recursive evolution. Our approach introduces an experience-based distillation mechanism to build a hierarchical skill library SkillBank, an adaptive retrieval strategy for general and task-specific heuristics, and a recursive evolution mechanism that allows the skill library to co-evolve with the agent's policy during reinforcement learning. These innovations significantly reduce the token footprint while enhancing reasoning utility. Experimental results on ALFWorld, WebShop and seven search-augmented tasks demonstrate that SkillRL achieves state-of-the-art performance, outperforming strong baselines over 15.3% and maintaining robustness as task complexity increases. Code is available at this https://github.com/aiming-lab/SkillRL.", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/643e9ee6f6bb3c31a26e7bc4/L9mDRVV2qoifMcWtJ_1ib.jpeg"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.08234.png", "numComments": 1, "submittedBy": {"_id": "643e9ee6f6bb3c31a26e7bc4", "avatarUrl": "/avatars/acfaa7d6a23dada24c86b954c3be116a.svg", "fullname": "Peng Xia", "name": "richardxp888", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 6, "isUserFollowing": false}, "organization": {"_id": "669f9d1fec8789263c0e355a", "name": "UNC-ChapelHill", "fullname": "University of North Carolina at Chapel Hill", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/669f9c85bd649dba3b88e581/H5uB8_MCewnMtxEUnAvTL.png"}, "isAuthorParticipating": true}],
    "month": [{"paper": {"id": "2602.05400", "authors": [{"_id": "698b396b1b2dc6b37d61b4be", "user": {"_id": "66968099c952e09a4cb29f78", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66968099c952e09a4cb29f78/n90NI2R3E9_RqCyMjDCQF.webp", "isPro": false, "fullname": "Wang", "user": "Steven-Shaobo", "type": "user"}, "name": "Shaobo Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:16:57.815Z", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4bf", "user": {"_id": "67e617d4470f96a302734e16", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/QHrYmNlTRxKR1KRS50pkf.png", "isPro": false, "fullname": "Xuan Ouyang", "user": "YoungXuan", "type": "user"}, "name": "Xuan Ouyang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:16:55.631Z", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c0", "user": {"_id": "6518a144a28f86d3e9e67c34", "avatarUrl": "/avatars/f2aed39e971cffe6c9d0b9c2f7a0df70.svg", "isPro": false, "fullname": "Tianyi Xu", "user": "tianyi0216", "type": "user"}, "name": "Tianyi Xu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:16:53.605Z", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c1", "name": "Yuzheng Hu", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c2", "name": "Jialin Liu", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c3", "name": "Guo Chen", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c4", "name": "Tianyu Zhang", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c5", "name": "Junhao Zheng", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c6", "name": "Kexin Yang", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c7", "name": "Xingzhang Ren", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c8", "name": "Dayiheng Liu", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c9", "name": "Linfeng Zhang", "hidden": false}], "publishedAt": "2026-02-05T07:34:23.000Z", "submittedOnDailyAt": "2026-02-11T02:09:03.945Z", "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration", "submittedOnDailyBy": {"_id": "67e617d4470f96a302734e16", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/QHrYmNlTRxKR1KRS50pkf.png", "isPro": false, "fullname": "Xuan Ouyang", "user": "YoungXuan", "type": "user"}, "summary": "As high-quality public text approaches exhaustion, a phenomenon known as the Data Wall, pre-training is shifting from more tokens to better tokens. However, existing methods either rely on heuristic static filters that ignore training dynamics, or use dynamic yet optimizer-agnostic criteria based on raw gradients. We propose OPUS (Optimizer-induced Projected Utility Selection), a dynamic data selection framework that defines utility in the optimizer-induced update space. OPUS scores candidates by projecting their effective updates, shaped by modern optimizers, onto a target direction derived from a stable, in-distribution proxy. To ensure scalability, we employ Ghost technique with CountSketch for computational efficiency, and Boltzmann sampling for data diversity, incurring only 4.7\\% additional compute overhead. OPUS achieves remarkable results across diverse corpora, quality tiers, optimizers, and model scales. In pre-training of GPT-2 Large/XL on FineWeb and FineWeb-Edu with 30B tokens, OPUS outperforms industrial-level baselines and even full 200B-token training. Moreover, when combined with industrial-level static filters, OPUS further improves pre-training efficiency, even with lower-quality data. Furthermore, in continued pre-training of Qwen3-8B-Base on SciencePedia, OPUS achieves superior performance using only 0.5B tokens compared to full training with 3B tokens, demonstrating significant data efficiency gains in specialized domains.", "upvotes": 279, "discussionId": "698b396b1b2dc6b37d61b4ca", "ai_summary": "OPUS is a dynamic data selection framework that improves pre-training efficiency by scoring data candidates based on optimizer-induced update projections in a stable proxy-derived target space, achieving superior performance with reduced computational overhead.", "ai_keywords": ["data selection", "optimizer-induced update space", "effective updates", "stable in-distribution proxy", "Ghost technique", "CountSketch", "Boltzmann sampling", "pre-training", "GPT-2", "Qwen3-8B-Base", "FineWeb", "FineWeb-Edu", "SciencePedia"], "organization": {"_id": "64c8b5837fe12ecd0a7e92eb", "name": "Qwen", "fullname": "Qwen", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/620760a26e3b7210c2ff1943/-s1gyJfvbE1RgO5iBeNOi.png"}, "summary_zh": "<ul>\n    <li>\u968f\u7740\u9ad8\u8d28\u91cf\u516c\u5171\u6587\u672c\u7684\u63a5\u8fd1\u67af\u7aed\uff0c\u9884\u8bad\u7ec3\u65b9\u6cd5\u6b63\u5728\u4ece\u589e\u52a0\u6570\u636e\u91cf\u8f6c\u5411\u63d0\u9ad8\u6570\u636e\u8d28\u91cf\u3002</li>\n    <li>\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u8fc7\u6ee4\u5668\u6216\u52a8\u6001\u6807\u51c6\uff0c\u4f46\u90fd\u5b58\u5728\u5c40\u9650\u6027\u3002</li>\n    <li>\u6211\u4eec\u63d0\u51fa\u4e86OPUS\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u5668\u7684\u66f4\u65b0\u7a7a\u95f4\u9009\u62e9\u6570\u636e\uff0c\u663e\u8457\u63d0\u9ad8\u6570\u636e\u9009\u62e9\u7684\u6709\u6548\u6027\u3002</li>\n    <li>OPUS\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c\u6a21\u578b\u89c4\u6a21\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u4e86\u5de5\u4e1a\u7ea7\u57fa\u7ebf\uff0c\u5e76\u4e14\u8ba1\u7b97\u5f00\u9500\u4ec5\u4e3a4.7%\u3002</li>\n    <li>\u5728\u7279\u5b9a\u9886\u57df\u7684\u9884\u8bad\u7ec3\u4e2d\uff0cOPUS\u4f7f\u7528\u66f4\u5c11\u7684\u6570\u636e\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\uff0c\u663e\u793a\u51fa\u663e\u8457\u7684\u6570\u636e\u6548\u7387\u63d0\u5347\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>As high-quality public text becomes scarce, data selection for pre-training is shifting towards using better quality tokens instead of just more tokens.</li>\n    <li>Current methods either use outdated filters that don't adapt to training changes or rely on raw gradients that aren't optimized.</li>\n    <li>OPUS is a new framework that selects data based on how effective updates are influenced by modern optimizers.</li>\n    <li>OPUS uses efficient techniques for fast computation and maintains data variety, adding only a small extra computing cost.</li>\n    <li>In tests, OPUS performed better than existing methods and even managed to achieve good results with less data in specialized areas.</li>\n</ul>"}, "publishedAt": "2026-02-05T02:34:23.000Z", "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration", "summary": "As high-quality public text approaches exhaustion, a phenomenon known as the Data Wall, pre-training is shifting from more tokens to better tokens. However, existing methods either rely on heuristic static filters that ignore training dynamics, or use dynamic yet optimizer-agnostic criteria based on raw gradients. We propose OPUS (Optimizer-induced Projected Utility Selection), a dynamic data selection framework that defines utility in the optimizer-induced update space. OPUS scores candidates by projecting their effective updates, shaped by modern optimizers, onto a target direction derived from a stable, in-distribution proxy. To ensure scalability, we employ Ghost technique with CountSketch for computational efficiency, and Boltzmann sampling for data diversity, incurring only 4.7\\% additional compute overhead. OPUS achieves remarkable results across diverse corpora, quality tiers, optimizers, and model scales. In pre-training of GPT-2 Large/XL on FineWeb and FineWeb-Edu with 30B tokens, OPUS outperforms industrial-level baselines and even full 200B-token training. Moreover, when combined with industrial-level static filters, OPUS further improves pre-training efficiency, even with lower-quality data. Furthermore, in continued pre-training of Qwen3-8B-Base on SciencePedia, OPUS achieves superior performance using only 0.5B tokens compared to full training with 3B tokens, demonstrating significant data efficiency gains in specialized domains.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.05400.png", "numComments": 2, "submittedBy": {"_id": "67e617d4470f96a302734e16", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/QHrYmNlTRxKR1KRS50pkf.png", "fullname": "Xuan Ouyang", "name": "YoungXuan", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 23, "isUserFollowing": false}, "organization": {"_id": "64c8b5837fe12ecd0a7e92eb", "name": "Qwen", "fullname": "Qwen", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/620760a26e3b7210c2ff1943/-s1gyJfvbE1RgO5iBeNOi.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.04705", "authors": [{"_id": "698424a7e34659da7e1f4e6f", "name": "Haifeng Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e70", "name": "Hua Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e71", "name": "Tian Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e72", "name": "Yu Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4e73", "name": "Jing Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e74", "name": "Dianhai Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e75", "name": "Yanjun Ma", "hidden": false}, {"_id": "698424a7e34659da7e1f4e76", "name": "Jingzhou He", "hidden": false}, {"_id": "698424a7e34659da7e1f4e77", "name": "Zhongjun He", "hidden": false}, {"_id": "698424a7e34659da7e1f4e78", "name": "Dou Hong", "hidden": false}, {"_id": "698424a7e34659da7e1f4e79", "name": "Qiwen Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7a", "name": "Shuohuan Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7b", "user": {"_id": "62cd9632342b1d5dab8df4c3", "avatarUrl": "/avatars/9080d20bb57a05a1eeb6800eba886cf9.svg", "isPro": false, "fullname": "Junyuan Shang", "user": "sjy1203", "type": "user"}, "name": "Junyuan Shang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:28.482Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7c", "user": {"_id": "67f37f78b36e82d366dedeec", "avatarUrl": "/avatars/678bb5891d5c2e80edc0799d2308a5d3.svg", "isPro": false, "fullname": "Max Zhenyu Zhang", "user": "max-zhenyu-zhang", "type": "user"}, "name": "Zhenyu Zhang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:03.972Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7d", "name": "Yuchen Ding", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7e", "name": "Jinle Zeng", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7f", "name": "Jiabin Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e80", "name": "Liang Shen", "hidden": false}, {"_id": "698424a7e34659da7e1f4e81", "name": "Ruibiao Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4e82", "name": "Weichong Yin", "hidden": false}, {"_id": "698424a7e34659da7e1f4e83", "name": "Siyu Ding", "hidden": false}, {"_id": "698424a7e34659da7e1f4e84", "name": "Dai Dai", "hidden": false}, {"_id": "698424a7e34659da7e1f4e85", "name": "Shikun Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f4e86", "name": "Siqi Bao", "hidden": false}, {"_id": "698424a7e34659da7e1f4e87", "name": "Bolei He", "hidden": false}, {"_id": "698424a7e34659da7e1f4e88", "name": "Yan Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4e89", "name": "Zhenyu Jiao", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8a", "name": "Ruiqing Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8b", "name": "Zeyu Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8c", "name": "Qingqing Dang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8d", "name": "Kaipeng Deng", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8e", "name": "Jiajun Jiang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8f", "name": "Enlei Gong", "hidden": false}, {"_id": "698424a7e34659da7e1f4e90", "name": "Guoxia Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e91", "name": "Yanlin Sha", "hidden": false}, {"_id": "698424a7e34659da7e1f4e92", "name": "Yi Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e93", "name": "Yehan Zheng", "hidden": false}, {"_id": "698424a7e34659da7e1f4e94", "name": "Weijian Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e95", "name": "Jiaxiang Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e96", "name": "Zengfeng Zeng", "hidden": false}, {"_id": "698424a7e34659da7e1f4e97", "name": "Yingqi Qu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e98", "name": "Zhongli Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4e99", "name": "Zhengkun Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9a", "name": "Xiyang Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9b", "name": "Zixiang Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9c", "name": "Xinchao Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9d", "name": "Zhengjie Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9e", "name": "Dong Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9f", "name": "Bingjin Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea0", "name": "Yue Chang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea1", "name": "Xing Yuan", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea2", "name": "Shiwei Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea3", "name": "Qiao Zhao", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea4", "name": "Xinzhe Ding", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea5", "name": "Shuangshuang Qiao", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea6", "name": "Baoshan Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea7", "name": "Bihong Tang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea8", "name": "Bin Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea9", "name": "Bingquan Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eaa", "name": "Binhan Tang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eab", "name": "Binxiong Zheng", "hidden": false}, {"_id": "698424a7e34659da7e1f4eac", "name": "Bo Cui", "hidden": false}, {"_id": "698424a7e34659da7e1f4ead", "name": "Bo Ke", "hidden": false}, {"_id": "698424a7e34659da7e1f4eae", "name": "Bo Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eaf", "name": "Bowen Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb0", "name": "Boyan Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb1", "name": "Boyang Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb2", "name": "Caiji Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb3", "name": "Can Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb4", "name": "Chang Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb5", "name": "Chao Pang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb6", "name": "Chao Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb7", "name": "Chaoyi Yuan", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb8", "name": "Chen Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb9", "name": "Cheng Cui", "hidden": false}, {"_id": "698424a7e34659da7e1f4eba", "name": "Chenlin Yin", "hidden": false}, {"_id": "698424a7e34659da7e1f4ebb", "name": "Chun Gan", "hidden": false}, {"_id": "698424a7e34659da7e1f4ebc", "name": "Chunguang Chai", "hidden": false}, {"_id": "698424a7e34659da7e1f4ebd", "name": "Chuyu Fang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ebe", "name": "Cuiyun Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4ebf", "name": "Dan Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec0", "name": "Danlei Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec1", "name": "Danxiang Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec2", "name": "Dong Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec3", "name": "Dongbo Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec4", "name": "Dongdong Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec5", "name": "Dongdong Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec6", "name": "Dongxue Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec7", "name": "Fan Ding", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec8", "name": "Fan Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec9", "name": "Fan Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4eca", "name": "Fan Mo", "hidden": false}, {"_id": "698424a7e34659da7e1f4ecb", "name": "Feisheng Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ecc", "name": "Fengwei Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ecd", "name": "Gangqiang Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ece", "name": "Gaofeng Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ecf", "name": "Gaopeng Yong", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed0", "name": "Gexiao Tian", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed1", "user": {"_id": "698419de94015f1e5eedacec", "avatarUrl": "/avatars/e80baa6f9efcd5e5d7cc9b93ac852c7b.svg", "isPro": false, "fullname": "Guan Wang", "user": "guanwcn", "type": "user"}, "name": "Guan Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:38.213Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed2", "name": "Guangchen Ni", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed3", "name": "Guangshuo Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed4", "name": "Guanzhong Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed5", "user": {"_id": "609cd5ab335f23cd2fa0f211", "avatarUrl": "/avatars/8331a7025a6aa4eabc5b6502bf8a0a63.svg", "isPro": false, "fullname": "Guihua Liu", "user": "LLLL", "type": "user"}, "name": "Guihua Liu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:31.029Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed6", "name": "Guishun Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed7", "name": "Haibin Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed8", "name": "Haijian Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed9", "name": "Haipeng Ming", "hidden": false}, {"_id": "698424a7e34659da7e1f4eda", "name": "Haisu Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4edb", "name": "Haiyang Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4edc", "name": "Haiye Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f4edd", "name": "Han Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4ede", "name": "Hangting Lou", "hidden": false}, {"_id": "698424a7e34659da7e1f4edf", "name": "Hanwen Du", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee0", "name": "Hanzhi Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee1", "name": "Hao Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee2", "name": "Hao Du", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee3", "name": "Hao Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee4", "name": "Hao Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee5", "name": "Haochen Jiang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee6", "name": "Haodong Tian", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee7", "name": "Haoshuang Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee8", "name": "Haozhe Geng", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee9", "name": "Heju Yin", "hidden": false}, {"_id": "698424a7e34659da7e1f4eea", "name": "Hong Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4eeb", "name": "Hongchen Xue", "hidden": false}, {"_id": "698424a7e34659da7e1f4eec", "name": "Hongen Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4eed", "name": "Honggeng Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eee", "name": "Hongji Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4eef", "name": "Hongwei Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef0", "name": "Hongyang Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef1", "name": "Hongyuan Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef2", "name": "Hua Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef3", "name": "Huan Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef4", "name": "Huan Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef5", "name": "Huang He", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef6", "name": "Hui Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef7", "name": "Hui Zhong", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef8", "name": "Huibin Ruan", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef9", "name": "Jiafeng Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4efa", "name": "Jiage Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4efb", "name": "Jiahao Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4efc", "name": "Jiahao Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4efd", "name": "Jiajie Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4efe", "name": "Jialin Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4eff", "name": "Jian Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f00", "name": "Jian Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f01", "name": "Jianfeng Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f02", "name": "Jianguang Jiang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f03", "name": "Jianhua Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f04", "name": "Jianye Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f05", "name": "Jiaodi Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f06", "name": "Jiarui Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f07", "name": "Jiawei Lv", "hidden": false}, {"_id": "698424a7e34659da7e1f4f08", "name": "Jiaxin Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f09", "name": "Jiaxuan Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0a", "name": "Jie Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0b", "name": "Jie Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0c", "name": "Jiefan Fang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0d", "name": "Jihan Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0e", "name": "Jihua Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0f", "name": "Jing Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f10", "name": "Jing Qian", "hidden": false}, {"_id": "698424a7e34659da7e1f4f11", "name": "Jing Yan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f12", "name": "Jingdong Du", "hidden": false}, {"_id": "698424a7e34659da7e1f4f13", "name": "Jingdong Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f14", "name": "Jingjing Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f15", "name": "Jingyong Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f16", "name": "Jinheng Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f17", "name": "Jinjin Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f18", "name": "Jinliang Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f19", "name": "Jinlin Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1a", "name": "Jinnan Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1b", "name": "Jixiang Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1c", "name": "Jiyi Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1d", "name": "Jiyuan Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1e", "name": "Jun Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1f", "name": "Jun Xia", "hidden": false}, {"_id": "698424a7e34659da7e1f4f20", "name": "Jun Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f21", "name": "Junda Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f22", "name": "Junhao Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f23", "name": "Junhong Xiang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f24", "name": "Junliang Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f25", "name": "Kai Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f26", "name": "Kailun Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f27", "name": "Kairan Su", "hidden": false}, {"_id": "698424a7e34659da7e1f4f28", "name": "Kang Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f29", "name": "Kangkang Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2a", "name": "Ke Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2b", "name": "Ke Wei", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2c", "name": "Kui Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2d", "name": "Kun Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2e", "name": "Kunbin Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2f", "name": "Lei Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4f30", "name": "Lei Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4f31", "name": "Lei Wen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f32", "name": "Linghui Meng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f33", "user": {"_id": "641e69355c348064a8251471", "avatarUrl": "/avatars/acad3877df27ff44ea3921bb43e34d53.svg", "isPro": false, "fullname": "Linhao Yu", "user": "HasuerYu", "type": "user"}, "name": "Linhao Yu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:52:47.812Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4f34", "name": "Liping Ouyang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f35", "name": "Liwen Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f36", "user": {"_id": "65cf859f88d13d8128bb8545", "avatarUrl": "/avatars/aa18b993bd90d9c8a95913050cd955a8.svg", "isPro": false, "fullname": "Longbin Ji", "user": "robingg1", "type": "user"}, "name": "Longbin Ji", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:40.295Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4f37", "name": "Longzhi Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f38", "name": "Meng Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4f39", "name": "Meng Tian", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3a", "name": "Mengfei Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3b", "name": "Mengqi Zeng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3c", "name": "Mengyu Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3d", "name": "Ming Hong", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3e", "name": "Mingcheng Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3f", "name": "Mingming Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f40", "name": "Mingxin Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f41", "name": "Mingzhu Cai", "hidden": false}, {"_id": "698424a7e34659da7e1f4f42", "name": "Naibin Gu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f43", "name": "Nemin Qiu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f44", "name": "Nian Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f45", "name": "Peng Qiu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f46", "name": "Peng Zhao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f47", "name": "Pengyu Zou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f48", "name": "Qi Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f49", "name": "Qi Xin", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4a", "name": "Qian Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4b", "name": "Qiang Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4c", "name": "Qianhui Luo", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4d", "name": "Qianwei Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4e", "name": "Qianyue He", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4f", "name": "Qifei Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f50", "name": "Qinrui Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f51", "name": "Qiwen Bao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f52", "name": "Quan Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f53", "name": "Quanxiang Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f54", "name": "Qunyi Xie", "hidden": false}, {"_id": "698424a7e34659da7e1f4f55", "name": "Rongrui Zhan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f56", "name": "Rufeng Dai", "hidden": false}, {"_id": "698424a7e34659da7e1f4f57", "name": "Rui Peng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f58", "name": "Ruian Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f59", "name": "Ruihao Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5a", "name": "Ruijie Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5b", "name": "Ruixi Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5c", "name": "Ruixuan Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5d", "name": "Runsheng Shi", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5e", "name": "Ruting Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5f", "name": "Senbo Kang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f60", "name": "Shan Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f61", "name": "Shaofei Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f62", "name": "Shaotian Gong", "hidden": false}, {"_id": "698424a7e34659da7e1f4f63", "name": "Shenwei Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f64", "name": "Shifeng Zheng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f65", "name": "Shihao Guo", "hidden": false}, {"_id": "698424a7e34659da7e1f4f66", "name": "Shilong Fan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f67", "name": "Shiqin Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f68", "name": "Shiwei Gu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f69", "name": "Shixi Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6a", "name": "Shuai Yao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6b", "name": "Shuang Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6c", "name": "Shuangqiao Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6d", "name": "Shuhao Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6e", "name": "Shuwei He", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6f", "name": "Shuwen Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f70", "user": {"_id": "62769a608483d8e9ecd9b4f8", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672799958233-62769a608483d8e9ecd9b4f8.jpeg", "isPro": false, "fullname": "Sijun He", "user": "sijunhe", "type": "user"}, "name": "Sijun He", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:33.392Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4f71", "user": {"_id": "64fada13d82fc6977d5e9c74", "avatarUrl": "/avatars/776bf1257154289e919716637770ef52.svg", "isPro": false, "fullname": "Siming Dai", "user": "DesmonDay", "type": "user"}, "name": "Siming Dai", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:52:50.302Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4f72", "name": "Siming Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f73", "name": "Siyi Long", "hidden": false}, {"_id": "698424a7e34659da7e1f4f74", "name": "Songhe Deng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f75", "name": "Suhui Dong", "hidden": false}, {"_id": "698424a7e34659da7e1f4f76", "name": "Suyin Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f77", "name": "Teng Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f78", "name": "Tianchan Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f79", "name": "Tianliang Lv", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7a", "user": {"_id": "67bbe929593452cc18877606", "avatarUrl": "/avatars/f50fd1cb35d628c26cf21ad0c95c55b1.svg", "isPro": false, "fullname": "tmyangcs", "user": "youngtimmy", "type": "user"}, "name": "Tianmeng Yang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:36.143Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7b", "name": "Tianyi Wei", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7c", "name": "Tiezhu Gao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7d", "name": "Ting Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7e", "name": "Ting Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7f", "name": "Tingdan Luo", "hidden": false}, {"_id": "698424a7e34659da7e1f4f80", "name": "Wei He", "hidden": false}, {"_id": "698424a7e34659da7e1f4f81", "name": "Wei Luan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f82", "name": "Wei Yin", "hidden": false}, {"_id": "698424a7e34659da7e1f4f83", "name": "Wei Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f84", "name": "Wei Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f85", "name": "Weibao Gong", "hidden": false}, {"_id": "698424a7e34659da7e1f4f86", "name": "Weibin Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f87", "name": "Weicheng Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f88", "name": "Weichong Dang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f89", "name": "Weiguo Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8a", "name": "Weilong Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8b", "name": "Weiqi Tan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8c", "name": "Wen Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8d", "name": "Wenbin Chang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8e", "name": "Wenjing Du", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8f", "name": "Wenlong Miao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f90", "name": "Wenpei Luo", "hidden": false}, {"_id": "698424a7e34659da7e1f4f91", "name": "Wenquan Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f92", "name": "Xi Shi", "hidden": false}, {"_id": "698424a7e34659da7e1f4f93", "name": "Xi Zhao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f94", "name": "Xiang Gao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f95", "name": "Xiangguo Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f96", "name": "Xiangrui Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f97", "name": "Xiangsen Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f98", "name": "Xiangzhe Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f99", "name": "Xianlong Luo", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9a", "name": "Xianying Ma", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9b", "name": "Xiao Tan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9c", "name": "Xiaocong Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9d", "name": "Xiaofei Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9e", "name": "Xiaofeng Peng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9f", "name": "Xiaofeng Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa0", "name": "Xiaojian Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa1", "name": "Xiaolan Yuan", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa2", "name": "Xiaopeng Cui", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa3", "name": "Xiaotian Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa4", "name": "Xiaoxiong Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa5", "name": "Xiaoxu Fei", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa6", "name": "Xiaoxuan Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa7", "user": {"_id": "664395621b88258a527cd7d1", "avatarUrl": "/avatars/8489ccebe4fd1262679ba63a5cb50bb8.svg", "isPro": false, "fullname": "Kira", "user": "Kira-wang", "type": "user"}, "name": "Xiaoyu Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:25.774Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa8", "name": "Xiaoyu Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa9", "name": "Xin Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4faa", "name": "Xin Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fab", "name": "Xinhui Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fac", "name": "Xinming Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fad", "name": "Xintong Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fae", "name": "Xinyi Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4faf", "name": "Xinyu Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb0", "name": "Xiuxian Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb1", "name": "XuanShi Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb2", "name": "Xue Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb3", "name": "Xueying Lv", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb4", "name": "Xuhong Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb5", "name": "Xulong Wei", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb6", "name": "Xuyi Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb7", "name": "Yabing Shi", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb8", "name": "Yafeng Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb9", "name": "Yamei Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4fba", "name": "Yan Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fbb", "name": "Yanfu Cheng", "hidden": false}, {"_id": "698424a7e34659da7e1f4fbc", "name": "Yang Gao", "hidden": false}, {"_id": "698424a7e34659da7e1f4fbd", "name": "Yang Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fbe", "name": "Yang Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fbf", "name": "Yang Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc0", "name": "Yang Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc1", "name": "Yanlong Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc2", "name": "Yannian Fu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc3", "name": "Yanpeng Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc4", "name": "Yanzheng Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc5", "name": "Yao Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc6", "name": "Yaozong Shen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc7", "name": "Yaqian Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc8", "name": "Yehua Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc9", "name": "Yekun Chai", "hidden": false}, {"_id": "698424a7e34659da7e1f4fca", "name": "Yesong Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fcb", "name": "Yi Song", "hidden": false}, {"_id": "698424a7e34659da7e1f4fcc", "name": "Yichen Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fcd", "name": "Yifei Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fce", "name": "Yifeng Guo", "hidden": false}, {"_id": "698424a7e34659da7e1f4fcf", "name": "Yifeng Kou", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd0", "name": "Yilong Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd1", "name": "Yilong Guo", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd2", "name": "Yiming Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd3", "name": "Ying Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd4", "name": "Ying Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd5", "name": "Yingsheng Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd6", "name": "Yingzhan Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd7", "name": "Yinqi Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd8", "name": "Yiran Xing", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd9", "name": "Yishu Lei", "hidden": false}, {"_id": "698424a7e34659da7e1f4fda", "name": "Yixiang Tu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fdb", "name": "Yiyan Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fdc", "name": "Yong Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fdd", "name": "Yonghua Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4fde", "name": "Yongqiang Ma", "hidden": false}, {"_id": "698424a7e34659da7e1f4fdf", "name": "Yongxing Dai", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe0", "name": "Yongyue Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe1", "name": "Yu Ran", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe2", "name": "Yu Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe3", "name": "Yu-Wen Michael Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe4", "name": "Yuang Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe5", "name": "Yuanle Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe6", "name": "Yuanyuan Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe7", "name": "Yubo Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe8", "name": "Yuchen Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe9", "name": "Yucheng Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fea", "name": "Yude Gao", "hidden": false}, {"_id": "698424a7e34659da7e1f4feb", "name": "Yuedong Luo", "hidden": false}, {"_id": "698424a7e34659da7e1f4fec", "name": "Yuehu Dong", "hidden": false}, {"_id": "698424a7e34659da7e1f4fed", "name": "Yufeng Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fee", "name": "Yuhui Cao", "hidden": false}, {"_id": "698424a7e34659da7e1f4fef", "name": "Yuhui Yun", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff0", "name": "Yukun Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff1", "name": "Yukun Gao", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff2", "name": "Yukun Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff3", "name": "Yumeng Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff4", "name": "Yun Fan", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff5", "name": "Yun Ma", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff6", "name": "Yunfei Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff7", "name": "Yunshen Xie", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff8", "name": "Yuping Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff9", "name": "Yuqin Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ffa", "name": "Yuqing Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ffb", "name": "Yurui Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ffc", "name": "Yuwen Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ffd", "name": "Yuxiang Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ffe", "name": "Zefeng Cai", "hidden": false}, {"_id": "698424a7e34659da7e1f4fff", "name": "Zelin Zhao", "hidden": false}, {"_id": "698424a7e34659da7e1f5000", "name": "Zelun Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f5001", "name": "Zenan Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f5002", "name": "Zezhao Dong", "hidden": false}, {"_id": "698424a7e34659da7e1f5003", "name": "Zhaowu Pan", "hidden": false}, {"_id": "698424a7e34659da7e1f5004", "name": "Zhaoyu Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f5005", "name": "Zhe Dong", "hidden": false}, {"_id": "698424a7e34659da7e1f5006", "name": "Zhe Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f5007", "name": "Zhen Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f5008", "name": "Zhengfan Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f5009", "name": "Zhengrui Wei", "hidden": false}, {"_id": "698424a7e34659da7e1f500a", "name": "Zhengsheng Ning", "hidden": false}, {"_id": "698424a7e34659da7e1f500b", "name": "Zhenxing Li", "hidden": false}, {"_id": "698424a7e34659da7e1f500c", "name": "Zhenyu Li", "hidden": false}, {"_id": "698424a7e34659da7e1f500d", "name": "Zhenyu Qian", "hidden": false}, {"_id": "698424a7e34659da7e1f500e", "name": "Zhenyun Li", "hidden": false}, {"_id": "698424a7e34659da7e1f500f", "name": "Zhi Li", "hidden": false}, {"_id": "698424a7e34659da7e1f5010", "name": "Zhichao Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f5011", "name": "Zhicheng Dong", "hidden": false}, {"_id": "698424a7e34659da7e1f5012", "name": "Zhida Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f5013", "name": "Zhifan Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f5014", "name": "Zhihao Deng", "hidden": false}, {"_id": "698424a7e34659da7e1f5015", "name": "Zhijin Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f5016", "name": "Zhiyang Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f5017", "name": "Zhonghui Zheng", "hidden": false}, {"_id": "698424a7e34659da7e1f5018", "name": "Zhuangzhuang Guo", "hidden": false}, {"_id": "698424a7e34659da7e1f5019", "name": "Zhujun Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f501a", "name": "Zhuo Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f501b", "name": "Zichang Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f501c", "name": "Zihan Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f501d", "name": "Zihao Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f501e", "name": "Zihe Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f501f", "name": "Ziheng Zhao", "hidden": false}, {"_id": "698424a7e34659da7e1f5020", "name": "Ziping Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f5021", "name": "Zixuan Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f5022", "name": "Ziyang Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f5023", "name": "Ziyi Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f5024", "name": "Ziyuan Gao", "hidden": false}], "publishedAt": "2026-02-04T16:18:15.000Z", "submittedOnDailyAt": "2026-02-05T02:34:05.150Z", "title": "ERNIE 5.0 Technical Report", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "In this report, we introduce ERNIE 5.0, a natively autoregressive foundation model desinged for unified multimodal understanding and generation across text, image, video, and audio. All modalities are trained from scratch under a unified next-group-of-tokens prediction objective, based on an ultra-sparse mixture-of-experts (MoE) architecture with modality-agnostic expert routing. To address practical challenges in large-scale deployment under diverse resource constraints, ERNIE 5.0 adopts a novel elastic training paradigm. Within a single pre-training run, the model learns a family of sub-models with varying depths, expert capacities, and routing sparsity, enabling flexible trade-offs among performance, model size, and inference latency in memory- or time-constrained scenarios. Moreover, we systematically address the challenges of scaling reinforcement learning to unified foundation models, thereby guaranteeing efficient and stable post-training under ultra-sparse MoE architectures and diverse multimodal settings. Extensive experiments demonstrate that ERNIE 5.0 achieves strong and balanced performance across multiple modalities. To the best of our knowledge, among publicly disclosed models, ERNIE 5.0 represents the first production-scale realization of a trillion-parameter unified autoregressive model that supports both multimodal understanding and generation. To facilitate further research, we present detailed visualizations of modality-agnostic expert routing in the unified model, alongside comprehensive empirical analysis of elastic training, aiming to offer profound insights to the community.", "upvotes": 198, "discussionId": "698424a7e34659da7e1f5025", "ai_summary": "ERNIE 5.0 is a production-scale trillion-parameter autoregressive model that unifies multimodal understanding and generation through sparse MoE architecture and elastic training.", "ai_keywords": ["autoregressive foundation model", "unified multimodal understanding", "unified next-group-of-tokens prediction objective", "mixture-of-experts", "modality-agnostic expert routing", "elastic training paradigm", "reinforcement learning", "sparse MoE architecture"], "summary_zh": "<ul>\n    <li>ERNIE 5.0 \u662f\u4e00\u79cd\u57fa\u7840\u6a21\u578b\uff0c\u80fd\u591f\u7edf\u4e00\u7406\u89e3\u548c\u751f\u6210\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u9891\u548c\u97f3\u9891\u3002</li>\n    <li>\u8be5\u6a21\u578b\u91c7\u7528\u8d85\u7a00\u758f\u7684\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\uff0c\u6240\u6709\u6a21\u6001\u5728\u540c\u4e00\u76ee\u6807\u4e0b\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u3002</li>\n    <li>ERNIE 5.0 \u91c7\u7528\u5f39\u6027\u8bad\u7ec3\u65b9\u5f0f\uff0c\u80fd\u591f\u5728\u9884\u8bad\u7ec3\u4e2d\u5b66\u4e60\u4e0d\u540c\u6df1\u5ea6\u548c\u5bb9\u91cf\u7684\u5b50\u6a21\u578b\uff0c\u4ee5\u9002\u5e94\u4e0d\u540c\u8d44\u6e90\u9650\u5236\u3002</li>\n    <li>\u8be5\u6a21\u578b\u5728\u591a\u4e2a\u6a21\u6001\u4e0a\u8868\u73b0\u51fa\u5f3a\u52b2\u4e14\u5747\u8861\u7684\u6027\u80fd\uff0c\u662f\u9996\u4e2a\u516c\u5f00\u7684\u4e07\u4ebf\u53c2\u6570\u7edf\u4e00\u81ea\u56de\u5f52\u6a21\u578b\u3002</li>\n    <li>\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u4e13\u5bb6\u8def\u7531\u53ef\u89c6\u5316\u548c\u5f39\u6027\u8bad\u7ec3\u7684\u5b9e\u8bc1\u5206\u6790\uff0c\u4ee5\u5e2e\u52a9\u7814\u7a76\u793e\u533a\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>ERNIE 5.0 is a new model that works with text, images, videos, and audio all at once.</li>\n    <li>It uses a unique training method that allows it to adapt to different resources and needs.</li>\n    <li>The model can create different versions of itself, balancing performance and efficiency based on available resources.</li>\n    <li>It is the first large-scale model with a trillion parameters that can understand and generate multiple types of media.</li>\n    <li>Detailed visuals and analyses are provided to help researchers understand how the model works and its training process.</li>\n</ul>"}, "publishedAt": "2026-02-04T11:18:15.000Z", "title": "ERNIE 5.0 Technical Report", "summary": "In this report, we introduce ERNIE 5.0, a natively autoregressive foundation model desinged for unified multimodal understanding and generation across text, image, video, and audio. All modalities are trained from scratch under a unified next-group-of-tokens prediction objective, based on an ultra-sparse mixture-of-experts (MoE) architecture with modality-agnostic expert routing. To address practical challenges in large-scale deployment under diverse resource constraints, ERNIE 5.0 adopts a novel elastic training paradigm. Within a single pre-training run, the model learns a family of sub-models with varying depths, expert capacities, and routing sparsity, enabling flexible trade-offs among performance, model size, and inference latency in memory- or time-constrained scenarios. Moreover, we systematically address the challenges of scaling reinforcement learning to unified foundation models, thereby guaranteeing efficient and stable post-training under ultra-sparse MoE architectures and diverse multimodal settings. Extensive experiments demonstrate that ERNIE 5.0 achieves strong and balanced performance across multiple modalities. To the best of our knowledge, among publicly disclosed models, ERNIE 5.0 represents the first production-scale realization of a trillion-parameter unified autoregressive model that supports both multimodal understanding and generation. To facilitate further research, we present detailed visualizations of modality-agnostic expert routing in the unified model, alongside comprehensive empirical analysis of elastic training, aiming to offer profound insights to the community.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.04705.png", "numComments": 2, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 228, "isUserFollowing": false}, "isAuthorParticipating": false}, {"paper": {"id": "2602.00919", "authors": [{"_id": "698186fdce18b1862809633b", "name": "I. Apanasevich", "hidden": false}, {"_id": "698186fdce18b1862809633c", "user": {"_id": "6718963e41abf87204dddaf5", "avatarUrl": "/avatars/05d4fdb330ccb52c53cb8f99f7497ab2.svg", "isPro": false, "fullname": "Mikhail Artemyev", "user": "Mixanik-43", "type": "user"}, "name": "M. Artemyev", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:34.142Z", "hidden": false}, {"_id": "698186fdce18b1862809633d", "name": "R. Babakyan", "hidden": false}, {"_id": "698186fdce18b1862809633e", "user": {"_id": "642694c721d5f027bec07c71", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642694c721d5f027bec07c71/0hZEaZ1kFxx4GEig29X_k.jpeg", "isPro": false, "fullname": "Polina Fedotova", "user": "2pd", "type": "user"}, "name": "P. Fedotova", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:41.710Z", "hidden": false}, {"_id": "698186fdce18b1862809633f", "name": "D. Grankin", "hidden": false}, {"_id": "698186fdce18b18628096340", "name": "E. Kupryashin", "hidden": false}, {"_id": "698186fdce18b18628096341", "user": {"_id": "662ace3c4f711ee4e1dcb790", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/R5dlha7Lpy5gCYFEAtr1L.jpeg", "isPro": false, "fullname": "Anastas Misailidi", "user": "kazzart", "type": "user"}, "name": "A. Misailidi", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:18.667Z", "hidden": false}, {"_id": "698186fdce18b18628096342", "user": {"_id": "66eb27551a537888d2121ddc", "avatarUrl": "/avatars/9c807b058c972c307a24d85efbfbd4ae.svg", "isPro": false, "fullname": "Daniil", "user": "Defgy", "type": "user"}, "name": "D. Nerus", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:33.667Z", "hidden": false}, {"_id": "698186fdce18b18628096343", "user": {"_id": "65e5e3df92de33440675b5d9", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65e5e3df92de33440675b5d9/UOVd40f_Htd5oMAa_L0cM.jpeg", "isPro": false, "fullname": "Alexander Nutalapati", "user": "AlexanderNutalapati", "type": "user"}, "name": "A. Nutalapati", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:20.959Z", "hidden": false}, {"_id": "698186fdce18b18628096344", "user": {"_id": "66b51b3ad4eea6ad6adfd611", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66b51b3ad4eea6ad6adfd611/SC_01wvlLjB0FFZdDVgAp.jpeg", "isPro": false, "fullname": "Gena Sidorov", "user": "haksorus", "type": "user"}, "name": "G. Sidorov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:41.584Z", "hidden": false}, {"_id": "698186fdce18b18628096345", "user": {"_id": "631ee99d2225f12fc0ef39f4", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662970571579-631ee99d2225f12fc0ef39f4.jpeg", "isPro": false, "fullname": "Ivan Efremov", "user": "4ku", "type": "user"}, "name": "I. Efremov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:36.696Z", "hidden": false}, {"_id": "698186fdce18b18628096346", "name": "M. Gerasyov", "hidden": false}, {"_id": "698186fdce18b18628096347", "name": "D. Pikurov", "hidden": false}, {"_id": "698186fdce18b18628096348", "name": "Y. Senchenko", "hidden": false}, {"_id": "698186fdce18b18628096349", "user": {"_id": "68113993ebc57966794e23d6", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Yc3GIqYZyO97lzZ9rX8OE.png", "isPro": false, "fullname": "Sergei Davidenko", "user": "Ant346", "type": "user"}, "name": "S. Davidenko", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:21.332Z", "hidden": false}, {"_id": "698186fdce18b1862809634a", "user": {"_id": "6981bbf47f758a03b9c46550", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/oTPe_MzIrDlCeRDvWWeLK.png", "isPro": false, "fullname": "Daniil Kulikov", "user": "KulikovDR", "type": "user"}, "name": "D. Kulikov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:46.458Z", "hidden": false}, {"_id": "698186fdce18b1862809634b", "name": "M. Sultankin", "hidden": false}, {"_id": "698186fdce18b1862809634c", "user": {"_id": "63518aa5a30fc3ba88ce51dd", "avatarUrl": "/avatars/2e6a8f4a3e76fcc1afe7e777d6b45e76.svg", "isPro": false, "fullname": "Kazybek A", "user": "wanjia", "type": "user"}, "name": "K. Askarbek", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:24.567Z", "hidden": false}, {"_id": "698186fdce18b1862809634d", "name": "O. Shamanin", "hidden": false}, {"_id": "698186fdce18b1862809634e", "name": "D. Statovoy", "hidden": false}, {"_id": "698186fdce18b1862809634f", "user": {"_id": "655f32a519fd101f14bf1fb0", "avatarUrl": "/avatars/adf2c494759ebe5a0d95c15631ac6312.svg", "isPro": false, "fullname": "Eduard", "user": "rjomba3000", "type": "user"}, "name": "E. Zalyaev", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:43.976Z", "hidden": false}, {"_id": "698186fdce18b18628096350", "user": {"_id": "67dd1714817478ae84b18981", "avatarUrl": "/avatars/1209da3d4c4de3f419ebea6845bb0ed6.svg", "isPro": false, "fullname": "Zorin Ilya", "user": "Zora244", "type": "user"}, "name": "I. Zorin", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:31.637Z", "hidden": false}, {"_id": "698186fdce18b18628096351", "name": "A. Letkin", "hidden": false}, {"_id": "698186fdce18b18628096352", "name": "E. Rusakov", "hidden": false}, {"_id": "698186fdce18b18628096353", "name": "A. Silchenko", "hidden": false}, {"_id": "698186fdce18b18628096354", "user": {"_id": "6981a821165e30591e1200e7", "avatarUrl": "/avatars/af72142b8ba8772926b247c31fc8e4c8.svg", "isPro": false, "fullname": "Vlad Vorobyov", "user": "GloomARK", "type": "user"}, "name": "V. Vorobyov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:18.218Z", "hidden": false}, {"_id": "698186fdce18b18628096355", "user": {"_id": "6901ce2d911da714e754422b", "avatarUrl": "/avatars/5ed8ce189ca92a04f7165751076ff446.svg", "isPro": false, "fullname": "SERGEI", "user": "sobolnikov", "type": "user"}, "name": "S. Sobolnikov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:28.887Z", "hidden": false}, {"_id": "698186fdce18b18628096356", "user": {"_id": "640e2ef88512ec51d7f34cd5", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640e2ef88512ec51d7f34cd5/Xl8UiprL-0SvOWHeoAFW1.jpeg", "isPro": false, "fullname": "Aleksey Postnikov", "user": "AlekseyPostnikov", "type": "user"}, "name": "A. Postnikov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:39.139Z", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/642694c721d5f027bec07c71/cz33CQXXE3--u2_mmgA5G.png"], "publishedAt": "2026-01-31T22:13:23.000Z", "submittedOnDailyAt": "2026-02-03T03:13:09.153Z", "title": "Green-VLA: Staged Vision-Language-Action Model for Generalist Robots", "submittedOnDailyBy": {"_id": "642694c721d5f027bec07c71", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642694c721d5f027bec07c71/0hZEaZ1kFxx4GEig29X_k.jpeg", "isPro": false, "fullname": "Polina Fedotova", "user": "2pd", "type": "user"}, "summary": "We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.", "upvotes": 173, "discussionId": "698186fece18b18628096357", "projectPage": "https://greenvla.github.io", "githubRepo": "https://github.com/greenvla/GreenVLA", "githubRepoAddedBy": "user", "ai_summary": "Green-VLA is a five-stage vision-language-action framework for real-world robot deployment that achieves generalization across different robot embodiments through multimodal training and reinforcement learning.", "ai_keywords": ["Vision-Language-Action", "multimodal grounding", "multi-embodiment pretraining", "embodiment-specific adaptation", "reinforcement-learning", "episode-progress prediction", "out-of-distribution detection", "joint-prediction-based guidance"], "githubStars": 24, "organization": {"_id": "6973998bee83f4964edef012", "name": "SberRoboticsCenter", "fullname": "Sber Robotics Center", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/642694c721d5f027bec07c71/LkuEJI3abphK4MFbq8tPf.png"}, "summary_zh": "<ul>\n    <li>\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aGreen-VLA\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728Green\u7c7b\u4eba\u673a\u5668\u4eba\u4e0a\u8fdb\u884c\u89c6\u89c9-\u8bed\u8a00-\u884c\u52a8\u7684\u5e94\u7528\u3002</li>\n    <li>Green-VLA\u5305\u542b\u4e94\u4e2a\u9636\u6bb5\u7684\u8bfe\u7a0b\uff0c\u5305\u62ec\u57fa\u7840VLM\u3001\u591a\u6a21\u6001\u57fa\u7840\u3001\u591a\u4e2a\u4f53\u73b0\u7684\u9884\u8bad\u7ec3\u7b49\u3002</li>\n    <li>\u4f7f\u7528\u4e863000\u5c0f\u65f6\u7684\u6f14\u793a\u6570\u636e\uff0c\u7ed3\u5408\u65f6\u95f4\u5bf9\u9f50\u548c\u8d28\u91cf\u8fc7\u6ee4\u3002</li>\n    <li>\u5b9e\u73b0\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u3001\u4e86\u89e3\u5177\u4f53\u4f53\u73b0\u7684\u52a8\u4f5c\u63a5\u53e3\uff0c\u53ef\u4ee5\u63a7\u5236\u4e0d\u540c\u7c7b\u578b\u7684\u673a\u5668\u4eba\u3002</li>\n    <li>\u5b9e\u9a8c\u8868\u660e\uff0cRL\u5bf9\u9f50\u63d0\u9ad8\u4e86\u6210\u529f\u7387\u3001\u9c81\u68d2\u6027\u548c\u957f\u65f6\u95f4\u6548\u7387\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u63d0\u5347\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Green-VLA is a new system for the Green robot that helps it understand and perform tasks using vision and language.</li>\n    <li>The system has five steps to improve learning, starting from basic understanding to advanced training and adaptation.</li>\n    <li>It uses a large amount of data (3,000 hours of demonstrations) to train the robot effectively.</li>\n    <li>Green-VLA can control different types of robots with a single set of instructions, making it versatile.</li>\n    <li>Tests show that this system improves the robot's success in tasks, making it more reliable and efficient.</li>\n</ul>"}, "publishedAt": "2026-01-31T17:13:23.000Z", "title": "Green-VLA: Staged Vision-Language-Action Model for Generalist Robots", "summary": "We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/642694c721d5f027bec07c71/cz33CQXXE3--u2_mmgA5G.png"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.00919.png", "numComments": 1, "submittedBy": {"_id": "642694c721d5f027bec07c71", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642694c721d5f027bec07c71/0hZEaZ1kFxx4GEig29X_k.jpeg", "fullname": "Polina Fedotova", "name": "2pd", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 3, "isUserFollowing": false}, "organization": {"_id": "6973998bee83f4964edef012", "name": "SberRoboticsCenter", "fullname": "Sber Robotics Center", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/642694c721d5f027bec07c71/LkuEJI3abphK4MFbq8tPf.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.09877", "authors": [{"_id": "698c7abdeb12ea7453916869", "user": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "isPro": false, "fullname": "Chenxu Wang", "user": "xunyoyo", "type": "user"}, "name": "Chenxu Wang", "status": "admin_assigned", "statusLastChangedAt": "2026-02-12T16:49:45.534Z", "hidden": false}, {"_id": "698c7abdeb12ea745391686a", "name": "Chaozhuo Li", "hidden": false}, {"_id": "698c7abdeb12ea745391686b", "name": "Songyang Liu", "hidden": false}, {"_id": "698c7abdeb12ea745391686c", "name": "Zejian Chen", "hidden": false}, {"_id": "698c7abdeb12ea745391686d", "name": "Jinyu Hou", "hidden": false}, {"_id": "698c7abdeb12ea745391686e", "name": "Ji Qi", "hidden": false}, {"_id": "698c7abdeb12ea745391686f", "name": "Rui Li", "hidden": false}, {"_id": "698c7abdeb12ea7453916870", "name": "Litian Zhang", "hidden": false}, {"_id": "698c7abdeb12ea7453916871", "name": "Qiwei Ye", "hidden": false}, {"_id": "698c7abdeb12ea7453916872", "name": "Zheng Liu", "hidden": false}, {"_id": "698c7abdeb12ea7453916873", "name": "Xu Chen", "hidden": false}, {"_id": "698c7abdeb12ea7453916874", "name": "Xi Zhang", "hidden": false}, {"_id": "698c7abdeb12ea7453916875", "name": "Philip S. Yu", "hidden": false}], "publishedAt": "2026-02-10T15:18:19.000Z", "submittedOnDailyAt": "2026-02-13T00:53:30.377Z", "title": "The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies", "submittedOnDailyBy": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "isPro": false, "fullname": "Chenxu Wang", "user": "xunyoyo", "type": "user"}, "summary": "The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.", "upvotes": 169, "discussionId": "698c7abdeb12ea7453916876", "ai_summary": "Multi-agent LLM systems face fundamental limitations in achieving continuous self-improvement while maintaining safety alignment due to inherent statistical blind spots in isolated evolution.", "ai_keywords": ["multi-agent systems", "large language models", "self-evolution", "safety alignment", "information-theoretic framework", "anthropic value distributions", "statistical blind spots", "self-evolving AI societies", "external oversight", "safety-preserving mechanisms"], "summary_zh": "<ul>\n    <li>\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6784\u6210\uff09\u5177\u6709\u53ef\u6269\u5c55\u7684\u96c6\u4f53\u667a\u80fd\u548c\u81ea\u6211\u8fdb\u5316\u7684\u6f5c\u529b\u3002</li>\n    <li>\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5e94\u5177\u5907\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u548c\u5b89\u5168\u5bf9\u9f50\uff0c\u4f46\u6211\u4eec\u53d1\u73b0\u8fd9\u4e24\u8005\u65e0\u6cd5\u517c\u5f97\u3002</li>\n    <li>\u6211\u4eec\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5b64\u7acb\u7684\u81ea\u6211\u8fdb\u5316\u4f1a\u5bfc\u81f4\u5b89\u5168\u5bf9\u9f50\u7684\u4e0d\u53ef\u9006\u964d\u7ea7\u3002</li>\n    <li>\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u6211\u4eec\u7684\u7406\u8bba\u9884\u6d4b\u4e00\u81f4\uff0c\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u4f1a\u968f\u7740\u65f6\u95f4\u63a8\u79fb\u800c\u964d\u4f4e\u3002</li>\n    <li>\u6211\u4eec\u5efa\u8bae\u4e86\u51e0\u79cd\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u7f13\u89e3\u5b89\u5168\u95ee\u9898\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u5916\u90e8\u76d1\u7763\u6216\u65b0\u7684\u5b89\u5168\u673a\u5236\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Multi-agent systems using large language models can enhance collective intelligence and self-improvement.</li>\n    <li>Achieving continuous self-improvement while ensuring safety is called the self-evolution trilemma, which is shown to be impossible.</li>\n    <li>Isolation during self-evolution creates safety risks due to blind spots, leading to a decline in safety alignment.</li>\n    <li>Research from a community of agents and closed systems supports the idea that safety will inevitably decrease over time.</li>\n    <li>The study suggests exploring new safety measures and external oversight to manage these risks more effectively.</li>\n</ul>"}, "publishedAt": "2026-02-10T10:18:19.000Z", "title": "The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies", "summary": "The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.09877.png", "numComments": 2, "submittedBy": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "fullname": "Chenxu Wang", "name": "xunyoyo", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "isUserFollowing": false}, "isAuthorParticipating": true}, {"paper": {"id": "2602.09856", "authors": [{"_id": "698bf5b66052d3bed9630aa7", "user": {"_id": "64107c7df52d7eb22e062956", "avatarUrl": "/avatars/7b1cee9a2b8454fedfbd4c3d1df9865c.svg", "isPro": false, "fullname": "Yuhao Zheng", "user": "yhzheng1031", "type": "user"}, "name": "Yuhao Zheng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:28.241Z", "hidden": false}, {"_id": "698bf5b66052d3bed9630aa8", "name": "Li'an Zhong", "hidden": false}, {"_id": "698bf5b66052d3bed9630aa9", "user": {"_id": "6773bcaa675a971ddf1e81dd", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/a8VUwZYXd7O_mq_zFvXMh.png", "isPro": false, "fullname": "CokeWang", "user": "CokeWang", "type": "user"}, "name": "Yi Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:30.778Z", "hidden": false}, {"_id": "698bf5b66052d3bed9630aaa", "user": {"_id": "661de9defdbc9c247f159d15", "avatarUrl": "/avatars/38e21e78327cc908201122405c48f41b.svg", "isPro": false, "fullname": "Rui Dai", "user": "DerryD", "type": "user"}, "name": "Rui Dai", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:25.982Z", "hidden": false}, {"_id": "698bf5b66052d3bed9630aab", "name": "Kaikui Liu", "hidden": false}, {"_id": "698bf5b66052d3bed9630aac", "name": "Xiangxiang Chu", "hidden": false}, {"_id": "698bf5b66052d3bed9630aad", "name": "Linyuan Lv", "hidden": false}, {"_id": "698bf5b66052d3bed9630aae", "name": "Philip Torr", "hidden": false}, {"_id": "698bf5b66052d3bed9630aaf", "user": {"_id": "64440be5af034cdfd69ca3a7", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg", "isPro": false, "fullname": "Qinghong (Kevin) Lin", "user": "KevinQHLin", "type": "user"}, "name": "Kevin Qinghong Lin", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:23.397Z", "hidden": false}], "publishedAt": "2026-02-10T14:56:19.000Z", "submittedOnDailyAt": "2026-02-11T01:02:42.385Z", "title": "Code2World: A GUI World Model via Renderable Code Generation", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.", "upvotes": 168, "discussionId": "698bf5b66052d3bed9630ab0", "projectPage": "https://amap-ml.github.io/Code2World/", "githubRepo": "https://github.com/AMAP-ML/Code2World", "githubRepoAddedBy": "user", "ai_summary": "Code2World enables autonomous GUI agents to predict next visual states through renderable code generation, achieving high visual fidelity and structural controllability while improving navigation performance.", "ai_keywords": ["vision-language coder", "GUI World model", "action-conditioned prediction", "AndroidCode", "HTML generation", "visual-feedback revision mechanism", "SFT", "Render-Aware Reinforcement Learning", "visual semantic fidelity", "action consistency", "next UI prediction", "AndroidWorld navigation"], "githubStars": 131, "organization": {"_id": "67d11771890254196d3174e5", "name": "GD-ML", "fullname": "AMAP-ML", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"}, "summary_zh": "<ul>\n    <li>\u81ea\u4e3b\u56fe\u5f62\u7528\u6237\u754c\u9762\u4ee3\u7406\u901a\u8fc7\u611f\u77e5\u754c\u9762\u548c\u6267\u884c\u52a8\u4f5c\u4e0e\u73af\u5883\u4e92\u52a8\u3002</li>\n    <li>Code2World\u662f\u4e00\u4e2a\u89c6\u89c9\u8bed\u8a00\u7f16\u7801\u5668\uff0c\u53ef\u4ee5\u751f\u6210\u53ef\u6e32\u67d3\u7684\u4ee3\u7801\u6765\u6a21\u62df\u4e0b\u4e00\u4e2a\u89c6\u89c9\u72b6\u6001\u3002</li>\n    <li>\u4e3a\u4e86\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u6211\u4eec\u6784\u5efa\u4e86AndroidCode\uff0c\u751f\u6210\u8d85\u8fc78\u4e07\u5bf9\u9ad8\u8d28\u91cf\u5c4f\u5e55-\u52a8\u4f5c\u5bf9\u3002</li>\n    <li>\u6211\u4eec\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u89c6\u89c9\u8bed\u4e49\u4e00\u81f4\u6027\u6765\u63d0\u9ad8\u4ee3\u7801\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002</li>\n    <li>Code2World\u5728\u7528\u6237\u754c\u9762\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bfc\u822a\u6210\u529f\u7387\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Code2World is a new tool that helps virtual agents predict the next visual state of user interfaces by generating code.</li>\n    <li>It improves on existing methods by creating high-quality screen-action pairs from Android GUI data, with over 80,000 examples.</li>\n    <li>The tool uses a special learning method that focuses on visual accuracy and consistent actions to enhance predictions.</li>\n    <li>Tests show that Code2World outperforms other systems like GPT-5 and Gemini-3-Pro-Image in predicting user interface changes.</li>\n    <li>Code2World also improves navigation success rates in Android applications, boosting performance significantly.</li>\n</ul>"}, "publishedAt": "2026-02-10T09:56:19.000Z", "title": "Code2World: A GUI World Model via Renderable Code Generation", "summary": "Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.09856.png", "numComments": 2, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 230, "isUserFollowing": false}, "organization": {"_id": "67d11771890254196d3174e5", "name": "GD-ML", "fullname": "AMAP-ML", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.10604", "authors": [{"_id": "698d417065c0d15a6d162026", "name": "Ailin Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162027", "name": "Ang Li", "hidden": false}, {"_id": "698d417065c0d15a6d162028", "name": "Aobo Kong", "hidden": false}, {"_id": "698d417065c0d15a6d162029", "name": "Bin Wang", "hidden": false}, {"_id": "698d417065c0d15a6d16202a", "name": "Binxing Jiao", "hidden": false}, {"_id": "698d417065c0d15a6d16202b", "name": "Bo Dong", "hidden": false}, {"_id": "698d417065c0d15a6d16202c", "name": "Bojun Wang", "hidden": false}, {"_id": "698d417065c0d15a6d16202d", "name": "Boyu Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16202e", "name": "Brian Li", "hidden": false}, {"_id": "698d417065c0d15a6d16202f", "name": "Buyun Ma", "hidden": false}, {"_id": "698d417065c0d15a6d162030", "name": "Chang Su", "hidden": false}, {"_id": "698d417065c0d15a6d162031", "name": "Changxin Miao", "hidden": false}, {"_id": "698d417065c0d15a6d162032", "name": "Changyi Wan", "hidden": false}, {"_id": "698d417065c0d15a6d162033", "name": "Chao Lou", "hidden": false}, {"_id": "698d417065c0d15a6d162034", "name": "Chen Hu", "hidden": false}, {"_id": "698d417065c0d15a6d162035", "name": "Chen Xu", "hidden": false}, {"_id": "698d417065c0d15a6d162036", "name": "Chenfeng Yu", "hidden": false}, {"_id": "698d417065c0d15a6d162037", "name": "Chengting Feng", "hidden": false}, {"_id": "698d417065c0d15a6d162038", "name": "Chengyuan Yao", "hidden": false}, {"_id": "698d417065c0d15a6d162039", "name": "Chunrui Han", "hidden": false}, {"_id": "698d417065c0d15a6d16203a", "name": "Dan Ma", "hidden": false}, {"_id": "698d417065c0d15a6d16203b", "name": "Dapeng Shi", "hidden": false}, {"_id": "698d417065c0d15a6d16203c", "name": "Daxin Jiang", "hidden": false}, {"_id": "698d417065c0d15a6d16203d", "name": "Dehua Ma", "hidden": false}, {"_id": "698d417065c0d15a6d16203e", "name": "Deshan Sun", "hidden": false}, {"_id": "698d417065c0d15a6d16203f", "name": "Di Qi", "hidden": false}, {"_id": "698d417065c0d15a6d162040", "name": "Enle Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162041", "name": "Fajie Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d162042", "name": "Fanqi Wan", "hidden": false}, {"_id": "698d417065c0d15a6d162043", "name": "Guanzhe Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162044", "name": "Gulin Yan", "hidden": false}, {"_id": "698d417065c0d15a6d162045", "name": "Guoliang Cao", "hidden": false}, {"_id": "698d417065c0d15a6d162046", "name": "Guopeng Li", "hidden": false}, {"_id": "698d417065c0d15a6d162047", "name": "Han Cheng", "hidden": false}, {"_id": "698d417065c0d15a6d162048", "name": "Hangyu Guo", "hidden": false}, {"_id": "698d417065c0d15a6d162049", "user": {"_id": "64b7874b9f5987572ca28461", "avatarUrl": "/avatars/d24ee0a6329ff93936aa7829481e2046.svg", "isPro": false, "fullname": "hanshanzhang", "user": "brain-zhang", "type": "user"}, "name": "Hanshan Zhang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:52.602Z", "hidden": false}, {"_id": "698d417065c0d15a6d16204a", "name": "Hao Nie", "hidden": false}, {"_id": "698d417065c0d15a6d16204b", "name": "Haonan Jia", "hidden": false}, {"_id": "698d417065c0d15a6d16204c", "name": "Haoran Lv", "hidden": false}, {"_id": "698d417065c0d15a6d16204d", "name": "Hebin Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d16204e", "name": "Hekun Lv", "hidden": false}, {"_id": "698d417065c0d15a6d16204f", "name": "Heng Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162050", "name": "Heung-Yeung Shum", "hidden": false}, {"_id": "698d417065c0d15a6d162051", "name": "Hongbo Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162052", "name": "Hongbo Peng", "hidden": false}, {"_id": "698d417065c0d15a6d162053", "name": "Hongyu Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d162054", "name": "Hongyuan Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162055", "name": "Houyong Chen", "hidden": false}, {"_id": "698d417065c0d15a6d162056", "name": "Huangxi Zhu", "hidden": false}, {"_id": "698d417065c0d15a6d162057", "name": "Huimin Wu", "hidden": false}, {"_id": "698d417065c0d15a6d162058", "name": "Huiyong Guo", "hidden": false}, {"_id": "698d417065c0d15a6d162059", "name": "Jia Wang", "hidden": false}, {"_id": "698d417065c0d15a6d16205a", "name": "Jian Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d16205b", "name": "Jianjian Sun", "hidden": false}, {"_id": "698d417065c0d15a6d16205c", "name": "Jiaoren Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16205d", "name": "Jiaran Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d16205e", "name": "Jiashu Lv", "hidden": false}, {"_id": "698d417065c0d15a6d16205f", "name": "Jiashuo Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162060", "name": "Jiayi Fu", "hidden": false}, {"_id": "698d417065c0d15a6d162061", "name": "Jiayu Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162062", "name": "Jie Cheng", "hidden": false}, {"_id": "698d417065c0d15a6d162063", "name": "Jie Luo", "hidden": false}, {"_id": "698d417065c0d15a6d162064", "name": "Jie Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162065", "name": "Jie Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d162066", "name": "Jieyi Hou", "hidden": false}, {"_id": "698d417065c0d15a6d162067", "name": "Jing Bai", "hidden": false}, {"_id": "698d417065c0d15a6d162068", "user": {"_id": "625026b7d2d191ac43320c5e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/625026b7d2d191ac43320c5e/2ExzHlZ-Bk8SQMyBjeY6N.jpeg", "isPro": false, "fullname": "Jingcheng Hu", "user": "reign12", "type": "user"}, "name": "Jingcheng Hu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:28:37.335Z", "hidden": false}, {"_id": "698d417065c0d15a6d162069", "name": "Jingjing Xie", "hidden": false}, {"_id": "698d417065c0d15a6d16206a", "name": "Jingwei Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16206b", "name": "Jingyang Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d16206c", "name": "Jishi Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d16206d", "name": "Junfeng Liu", "hidden": false}, {"_id": "698d417065c0d15a6d16206e", "name": "Junzhe Lin", "hidden": false}, {"_id": "698d417065c0d15a6d16206f", "name": "Ka Man Lo", "hidden": false}, {"_id": "698d417065c0d15a6d162070", "name": "Kai Liang", "hidden": false}, {"_id": "698d417065c0d15a6d162071", "name": "Kaibo Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162072", "name": "Kaijun Tan", "hidden": false}, {"_id": "698d417065c0d15a6d162073", "user": {"_id": "66668c591964b6188ee310c2", "avatarUrl": "/avatars/8a8265073dbacbb2c7139b1c8da3e055.svg", "isPro": false, "fullname": "Kaiwen Yan", "user": "linrany", "type": "user"}, "name": "Kaiwen Yan", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:58.524Z", "hidden": false}, {"_id": "698d417065c0d15a6d162074", "name": "Kaixiang Li", "hidden": false}, {"_id": "698d417065c0d15a6d162075", "name": "Kang An", "hidden": false}, {"_id": "698d417065c0d15a6d162076", "user": {"_id": "658a810665df457a55ffcd04", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/658a810665df457a55ffcd04/6Pe0mNao4mlWLIjYEoWv5.jpeg", "isPro": false, "fullname": "Linkangheng", "user": "Kangheng", "type": "user"}, "name": "Kangheng Lin", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:56.339Z", "hidden": false}, {"_id": "698d417065c0d15a6d162077", "name": "Lei Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162078", "name": "Liang Lv", "hidden": false}, {"_id": "698d417065c0d15a6d162079", "name": "Liang Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d16207a", "name": "Liangyu Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16207b", "name": "Lieyu Shi", "hidden": false}, {"_id": "698d417065c0d15a6d16207c", "name": "Liguo Tan", "hidden": false}, {"_id": "698d417065c0d15a6d16207d", "name": "Lin Lin", "hidden": false}, {"_id": "698d417065c0d15a6d16207e", "name": "Lina Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16207f", "name": "Luck Ma", "hidden": false}, {"_id": "698d417065c0d15a6d162080", "name": "Mengqiang Ren", "hidden": false}, {"_id": "698d417065c0d15a6d162081", "name": "Michael Li", "hidden": false}, {"_id": "698d417065c0d15a6d162082", "name": "Ming Li", "hidden": false}, {"_id": "698d417065c0d15a6d162083", "name": "Mingliang Li", "hidden": false}, {"_id": "698d417065c0d15a6d162084", "name": "Mingming Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d162085", "name": "Mingrui Chen", "hidden": false}, {"_id": "698d417065c0d15a6d162086", "name": "Mitt Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162087", "name": "Na Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162088", "name": "Peng Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162089", "name": "Qi Han", "hidden": false}, {"_id": "698d417065c0d15a6d16208a", "name": "Qian Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d16208b", "name": "Qinglin He", "hidden": false}, {"_id": "698d417065c0d15a6d16208c", "name": "Qinxin Du", "hidden": false}, {"_id": "698d417065c0d15a6d16208d", "name": "Qiuping Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16208e", "name": "Quan Sun", "hidden": false}, {"_id": "698d417065c0d15a6d16208f", "name": "Rongqiu Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162090", "name": "Ruihang Miao", "hidden": false}, {"_id": "698d417065c0d15a6d162091", "name": "Ruixin Han", "hidden": false}, {"_id": "698d417065c0d15a6d162092", "name": "Ruosi Wan", "hidden": false}, {"_id": "698d417065c0d15a6d162093", "name": "Ruyan Guo", "hidden": false}, {"_id": "698d417065c0d15a6d162094", "name": "Shan Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162095", "name": "Shaoliang Pang", "hidden": false}, {"_id": "698d417065c0d15a6d162096", "name": "Shaowen Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162097", "name": "Shengjie Fan", "hidden": false}, {"_id": "698d417065c0d15a6d162098", "name": "Shijie Shang", "hidden": false}, {"_id": "698d417065c0d15a6d162099", "name": "Shiliang Yang", "hidden": false}, {"_id": "698d417065c0d15a6d16209a", "name": "Shiwei Li", "hidden": false}, {"_id": "698d417065c0d15a6d16209b", "name": "Shuangshuang Tian", "hidden": false}, {"_id": "698d417065c0d15a6d16209c", "name": "Siqi Liu", "hidden": false}, {"_id": "698d417065c0d15a6d16209d", "name": "Siye Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16209e", "name": "Siyu Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16209f", "name": "Song Yuan", "hidden": false}, {"_id": "698d417065c0d15a6d1620a0", "name": "Tiancheng Cao", "hidden": false}, {"_id": "698d417065c0d15a6d1620a1", "name": "Tianchi Yue", "hidden": false}, {"_id": "698d417065c0d15a6d1620a2", "name": "Tianhao Cheng", "hidden": false}, {"_id": "698d417065c0d15a6d1620a3", "name": "Tianning Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620a4", "name": "Tingdan Luo", "hidden": false}, {"_id": "698d417065c0d15a6d1620a5", "name": "Wang You", "hidden": false}, {"_id": "698d417065c0d15a6d1620a6", "name": "Wei Ji", "hidden": false}, {"_id": "698d417065c0d15a6d1620a7", "name": "Wei Yuan", "hidden": false}, {"_id": "698d417065c0d15a6d1620a8", "name": "Wei Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620a9", "name": "Weibo Wu", "hidden": false}, {"_id": "698d417065c0d15a6d1620aa", "user": {"_id": "6657620ea496f7fcb67c3871", "avatarUrl": "/avatars/54fef1c835e6f6b478652d438a140d45.svg", "isPro": false, "fullname": "xieweihao", "user": "chalengr", "type": "user"}, "name": "Weihao Xie", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:48.216Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620ab", "name": "Wen Sun", "hidden": false}, {"_id": "698d417065c0d15a6d1620ac", "name": "Wenjin Deng", "hidden": false}, {"_id": "698d417065c0d15a6d1620ad", "user": {"_id": "650c04795510464e85b47470", "avatarUrl": "/avatars/98c194e77826b928c49659849f466dad.svg", "isPro": false, "fullname": "wen", "user": "zhengwenzhen", "type": "user"}, "name": "Wenzhen Zheng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:45.930Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620ae", "name": "Wuxun Xie", "hidden": false}, {"_id": "698d417065c0d15a6d1620af", "name": "Xiangfeng Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b0", "name": "Xiangwen Kong", "hidden": false}, {"_id": "698d417065c0d15a6d1620b1", "name": "Xiangyu Liu", "hidden": false}, {"_id": "698d417065c0d15a6d1620b2", "name": "Xiangyu Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b3", "name": "Xiaobo Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b4", "name": "Xiaojia Liu", "hidden": false}, {"_id": "698d417065c0d15a6d1620b5", "name": "Xiaolan Yuan", "hidden": false}, {"_id": "698d417065c0d15a6d1620b6", "name": "Xiaoran Jiao", "hidden": false}, {"_id": "698d417065c0d15a6d1620b7", "name": "Xiaoxiao Ren", "hidden": false}, {"_id": "698d417065c0d15a6d1620b8", "name": "Xiaoyun Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b9", "name": "Xin Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620ba", "name": "Xin Liu", "hidden": false}, {"_id": "698d417065c0d15a6d1620bb", "name": "Xin Wu", "hidden": false}, {"_id": "698d417065c0d15a6d1620bc", "name": "Xing Chen", "hidden": false}, {"_id": "698d417065c0d15a6d1620bd", "name": "Xingping Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620be", "name": "Xinran Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620bf", "name": "Xu Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620c0", "user": {"_id": "64ec5b64bfb2aa06a46ff2d6", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/Lgl55OtDWa0tzRI2ShpUe.jpeg", "isPro": false, "fullname": "xuan he", "user": "tpa115k31", "type": "user"}, "name": "Xuan He", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:36.240Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620c1", "name": "Xuanti Feng", "hidden": false}, {"_id": "698d417065c0d15a6d1620c2", "name": "Xuedan Cai", "hidden": false}, {"_id": "698d417065c0d15a6d1620c3", "name": "Xuqiang Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d1620c4", "name": "Yanbo Yu", "hidden": false}, {"_id": "698d417065c0d15a6d1620c5", "name": "Yang Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620c6", "name": "Yang Xu", "hidden": false}, {"_id": "698d417065c0d15a6d1620c7", "name": "Yanlin Lai", "hidden": false}, {"_id": "698d417065c0d15a6d1620c8", "name": "Yanming Xu", "hidden": false}, {"_id": "698d417065c0d15a6d1620c9", "name": "Yaoyu Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620ca", "name": "Yeqing Shen", "hidden": false}, {"_id": "698d417065c0d15a6d1620cb", "name": "Yibo Zhu", "hidden": false}, {"_id": "698d417065c0d15a6d1620cc", "name": "Yichen Lv", "hidden": false}, {"_id": "698d417065c0d15a6d1620cd", "name": "Yicheng Cao", "hidden": false}, {"_id": "698d417065c0d15a6d1620ce", "name": "Yifeng Gong", "hidden": false}, {"_id": "698d417065c0d15a6d1620cf", "name": "Yijing Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d0", "name": "Yikun Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d1", "name": "Yin Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620d2", "name": "Yingxiu Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620d3", "name": "Yinmin Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d4", "name": "Yitong Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d5", "name": "Yixuan Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d6", "name": "Yiyang Chen", "hidden": false}, {"_id": "698d417065c0d15a6d1620d7", "name": "Yongchi Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620d8", "name": "Yongshen Long", "hidden": false}, {"_id": "698d417065c0d15a6d1620d9", "name": "Yongyao Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620da", "name": "Yousong Guan", "hidden": false}, {"_id": "698d417065c0d15a6d1620db", "name": "Yu Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d1620dc", "name": "Yuang Peng", "hidden": false}, {"_id": "698d417065c0d15a6d1620dd", "name": "Yuanhao Ding", "hidden": false}, {"_id": "698d417065c0d15a6d1620de", "name": "Yuantao Fan", "hidden": false}, {"_id": "698d417065c0d15a6d1620df", "name": "Yuanzhen Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620e0", "name": "Yuchu Luo", "hidden": false}, {"_id": "698d417065c0d15a6d1620e1", "name": "Yudi Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620e2", "name": "Yue Peng", "hidden": false}, {"_id": "698d417065c0d15a6d1620e3", "name": "Yueqiang Lin", "hidden": false}, {"_id": "698d417065c0d15a6d1620e4", "name": "Yufan Lu", "hidden": false}, {"_id": "698d417065c0d15a6d1620e5", "name": "Yuling Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620e6", "name": "Yunzhou Ju", "hidden": false}, {"_id": "698d417065c0d15a6d1620e7", "name": "Yurong Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620e8", "name": "Yusheng Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620e9", "name": "Yuxiang Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620ea", "name": "Yuyang Chen", "hidden": false}, {"_id": "698d417065c0d15a6d1620eb", "name": "Yuzhu Cai", "hidden": false}, {"_id": "698d417065c0d15a6d1620ec", "name": "Zejia Weng", "hidden": false}, {"_id": "698d417065c0d15a6d1620ed", "name": "Zetao Hong", "hidden": false}, {"_id": "698d417065c0d15a6d1620ee", "name": "Zexi Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620ef", "name": "Zhe Xie", "hidden": false}, {"_id": "698d417065c0d15a6d1620f0", "name": "Zheng Ge", "hidden": false}, {"_id": "698d417065c0d15a6d1620f1", "name": "Zheng Gong", "hidden": false}, {"_id": "698d417065c0d15a6d1620f2", "name": "Zheng Zeng", "hidden": false}, {"_id": "698d417065c0d15a6d1620f3", "user": {"_id": "63607ace9ddc44e710e13f0f", "avatarUrl": "/avatars/b5f331549562aea4a5c8b681fd9da1ff.svg", "isPro": false, "fullname": "zy", "user": "lu-vae", "type": "user"}, "name": "Zhenyi Lu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:50.532Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620f4", "name": "Zhewei Huang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f5", "name": "Zhichao Chang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f6", "name": "Zhiguo Huang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f7", "name": "Zhiheng Hu", "hidden": false}, {"_id": "698d417065c0d15a6d1620f8", "name": "Zidong Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f9", "name": "Zili Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620fa", "name": "Ziqi Ren", "hidden": false}, {"_id": "698d417065c0d15a6d1620fb", "name": "Zixin Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620fc", "name": "Zixuan Wang", "hidden": false}], "publishedAt": "2026-02-11T07:53:51.000Z", "submittedOnDailyAt": "2026-02-12T00:26:49.880Z", "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.", "upvotes": 150, "discussionId": "698d417165c0d15a6d1620fd", "githubRepo": "https://github.com/stepfun-ai/Step-3.5-Flash", "githubRepoAddedBy": "user", "ai_summary": "Step 3.5 Flash is a sparse Mixture-of-Experts model that achieves frontier-level agentic intelligence through efficient parameter utilization and optimized attention mechanisms, demonstrating strong performance across multiple benchmarks.", "ai_keywords": ["Mixture-of-Experts", "sparse MoE", "foundation model", "active parameters", "interleaved attention", "sliding-window attention", "full attention", "Multi-Token Prediction", "reinforcement learning", "verifiable signals", "preference feedback", "off-policy training", "self-improvement", "IMO-AnswerBench", "LiveCodeBench", "tau2-Bench", "BrowseComp", "Terminal-Bench"], "githubStars": 1245, "organization": {"_id": "66e43eae9d477f566f937935", "name": "stepfun-ai", "fullname": "StepFun", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66935cee39002fc0569c2943/Qv8QPbkgoKE3wR4jTzHiy.png"}, "summary_zh": "<ul>\n    <li>Step 3.5 Flash \u662f\u4e00\u79cd\u7a00\u758f\u7684\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u65e8\u5728\u63d0\u9ad8\u667a\u80fd\u4f53\u7684\u63a8\u7406\u80fd\u529b\u548c\u6267\u884c\u6548\u7387\u3002</li>\n    <li>\u5b83\u4f7f\u7528\u4e00\u4e2a\u5305\u542b1960\u4ebf\u4e2a\u53c2\u6570\u7684\u57fa\u7840\u6a21\u578b\u548c110\u4ebf\u4e2a\u6d3b\u8dc3\u53c2\u6570\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002</li>\n    <li>\u8be5\u6a21\u578b\u901a\u8fc7\u4f18\u5316\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u6807\u8bb0\u9884\u6d4b\uff0c\u51cf\u5c11\u591a\u8f6e\u4ea4\u4e92\u7684\u5ef6\u8fdf\u548c\u6210\u672c\u3002</li>\n    <li>Step 3.5 Flash \u5728\u591a\u4e2a\u4efb\u52a1\uff08\u5982\u6570\u5b66\u3001\u7f16\u7801\u548c\u5de5\u5177\u4f7f\u7528\uff09\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u6027\u80fd\u4e0e\u524d\u6cbf\u6a21\u578b\u76f8\u5f53\u3002</li>\n    <li>\u5b83\u4e3a\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u90e8\u7f72\u590d\u6742\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u57fa\u7840\u3002 </li>\n</ul>", "summary_simple": "<ul>\n    <li>Step 3.5 Flash is a new model that combines smart decision-making with efficient computing.</li>\n    <li>It uses a large 196 billion parameter base with 11 billion active parameters for faster performance.</li>\n    <li>The model is designed to improve how agents learn and perform tasks in coding, math, and using tools.</li>\n    <li>It shows strong results on various benchmarks, performing similarly to advanced models like GPT-5.2 xHigh.</li>\n    <li>This model aims to make it easier to use intelligent agents in real-world situations.</li>\n</ul>"}, "publishedAt": "2026-02-11T02:53:51.000Z", "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters", "summary": "We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.10604.png", "numComments": 3, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 231, "isUserFollowing": false}, "organization": {"_id": "66e43eae9d477f566f937935", "name": "stepfun-ai", "fullname": "StepFun", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66935cee39002fc0569c2943/Qv8QPbkgoKE3wR4jTzHiy.png"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.02276", "authors": [{"_id": "69817e2cce18b1862809615b", "name": "Kimi Team", "hidden": false}, {"_id": "69817e2cce18b1862809615c", "name": "Tongtong Bai", "hidden": false}, {"_id": "69817e2cce18b1862809615d", "name": "Yifan Bai", "hidden": false}, {"_id": "69817e2cce18b1862809615e", "name": "Yiping Bao", "hidden": false}, {"_id": "69817e2cce18b1862809615f", "name": "S. H. Cai", "hidden": false}, {"_id": "69817e2cce18b18628096160", "name": "Yuan Cao", "hidden": false}, {"_id": "69817e2cce18b18628096161", "name": "Y. Charles", "hidden": false}, {"_id": "69817e2cce18b18628096162", "name": "H. S. Che", "hidden": false}, {"_id": "69817e2cce18b18628096163", "name": "Cheng Chen", "hidden": false}, {"_id": "69817e2cce18b18628096164", "name": "Guanduo Chen", "hidden": false}, {"_id": "69817e2cce18b18628096165", "name": "Huarong Chen", "hidden": false}, {"_id": "69817e2cce18b18628096166", "name": "Jia Chen", "hidden": false}, {"_id": "69817e2cce18b18628096167", "name": "Jiahao Chen", "hidden": false}, {"_id": "69817e2cce18b18628096168", "name": "Jianlong Chen", "hidden": false}, {"_id": "69817e2cce18b18628096169", "name": "Jun Chen", "hidden": false}, {"_id": "69817e2cce18b1862809616a", "name": "Kefan Chen", "hidden": false}, {"_id": "69817e2cce18b1862809616b", "name": "Liang Chen", "hidden": false}, {"_id": "69817e2cce18b1862809616c", "name": "Ruijue Chen", "hidden": false}, {"_id": "69817e2cce18b1862809616d", "name": "Xinhao Chen", "hidden": false}, {"_id": "69817e2cce18b1862809616e", "name": "Yanru Chen", "hidden": false}, {"_id": "69817e2cce18b1862809616f", "name": "Yanxu Chen", "hidden": false}, {"_id": "69817e2cce18b18628096170", "name": "Yicun Chen", "hidden": false}, {"_id": "69817e2cce18b18628096171", "name": "Yimin Chen", "hidden": false}, {"_id": "69817e2cce18b18628096172", "name": "Yingjiang Chen", "hidden": false}, {"_id": "69817e2cce18b18628096173", "name": "Yuankun Chen", "hidden": false}, {"_id": "69817e2cce18b18628096174", "name": "Yujie Chen", "hidden": false}, {"_id": "69817e2cce18b18628096175", "name": "Yutian Chen", "hidden": false}, {"_id": "69817e2cce18b18628096176", "name": "Zhirong Chen", "hidden": false}, {"_id": "69817e2cce18b18628096177", "name": "Ziwei Chen", "hidden": false}, {"_id": "69817e2cce18b18628096178", "name": "Dazhi Cheng", "hidden": false}, {"_id": "69817e2cce18b18628096179", "name": "Minghan Chu", "hidden": false}, {"_id": "69817e2cce18b1862809617a", "name": "Jialei Cui", "hidden": false}, {"_id": "69817e2cce18b1862809617b", "name": "Jiaqi Deng", "hidden": false}, {"_id": "69817e2cce18b1862809617c", "name": "Muxi Diao", "hidden": false}, {"_id": "69817e2cce18b1862809617d", "name": "Hao Ding", "hidden": false}, {"_id": "69817e2cce18b1862809617e", "name": "Mengfan Dong", "hidden": false}, {"_id": "69817e2cce18b1862809617f", "name": "Mengnan Dong", "hidden": false}, {"_id": "69817e2cce18b18628096180", "name": "Yuxin Dong", "hidden": false}, {"_id": "69817e2cce18b18628096181", "user": {"_id": "652965773a416e1f2173443b", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/652965773a416e1f2173443b/y9MB8YgHzbwCXAc4EI9T3.jpeg", "isPro": true, "fullname": "Yuhao Dong", "user": "THUdyh", "type": "user"}, "name": "Yuhao Dong", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:04:11.993Z", "hidden": false}, {"_id": "69817e2cce18b18628096182", "name": "Angang Du", "hidden": false}, {"_id": "69817e2cce18b18628096183", "name": "Chenzhuang Du", "hidden": false}, {"_id": "69817e2cce18b18628096184", "name": "Dikang Du", "hidden": false}, {"_id": "69817e2cce18b18628096185", "name": "Lingxiao Du", "hidden": false}, {"_id": "69817e2cce18b18628096186", "user": {"_id": "6340f31fb78ed99eab04ce33", "avatarUrl": "/avatars/2e7fcbf0233bdc0bc9a3f4603fd8bf90.svg", "isPro": false, "fullname": "Du", "user": "Yulun", "type": "user"}, "name": "Yulun Du", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:05:47.298Z", "hidden": false}, {"_id": "69817e2cce18b18628096187", "name": "Yu Fan", "hidden": false}, {"_id": "69817e2cce18b18628096188", "name": "Shengjun Fang", "hidden": false}, {"_id": "69817e2cce18b18628096189", "name": "Qiulin Feng", "hidden": false}, {"_id": "69817e2cce18b1862809618a", "name": "Yichen Feng", "hidden": false}, {"_id": "69817e2cce18b1862809618b", "name": "Garimugai Fu", "hidden": false}, {"_id": "69817e2cce18b1862809618c", "name": "Kelin Fu", "hidden": false}, {"_id": "69817e2cce18b1862809618d", "name": "Hongcheng Gao", "hidden": false}, {"_id": "69817e2cce18b1862809618e", "name": "Tong Gao", "hidden": false}, {"_id": "69817e2cce18b1862809618f", "name": "Yuyao Ge", "hidden": false}, {"_id": "69817e2cce18b18628096190", "user": {"_id": "650a5d79a0f81fbc0a9875a7", "avatarUrl": "/avatars/a76b1c932964602f2fc4a801ccad3ab5.svg", "isPro": false, "fullname": "ShangyiGeng", "user": "Reset23", "type": "user"}, "name": "Shangyi Geng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:59:10.446Z", "hidden": false}, {"_id": "69817e2cce18b18628096191", "name": "Chengyang Gong", "hidden": false}, {"_id": "69817e2cce18b18628096192", "name": "Xiaochen Gong", "hidden": false}, {"_id": "69817e2cce18b18628096193", "name": "Zhuoma Gongque", "hidden": false}, {"_id": "69817e2cce18b18628096194", "name": "Qizheng Gu", "hidden": false}, {"_id": "69817e2cce18b18628096195", "name": "Xinran Gu", "hidden": false}, {"_id": "69817e2cce18b18628096196", "name": "Yicheng Gu", "hidden": false}, {"_id": "69817e2cce18b18628096197", "name": "Longyu Guan", "hidden": false}, {"_id": "69817e2cce18b18628096198", "name": "Yuanying Guo", "hidden": false}, {"_id": "69817e2cce18b18628096199", "name": "Xiaoru Hao", "hidden": false}, {"_id": "69817e2cce18b1862809619a", "name": "Weiran He", "hidden": false}, {"_id": "69817e2cce18b1862809619b", "name": "Wenyang He", "hidden": false}, {"_id": "69817e2cce18b1862809619c", "name": "Yunjia He", "hidden": false}, {"_id": "69817e2cce18b1862809619d", "name": "Chao Hong", "hidden": false}, {"_id": "69817e2cce18b1862809619e", "name": "Hao Hu", "hidden": false}, {"_id": "69817e2cce18b1862809619f", "name": "Jiaxi Hu", "hidden": false}, {"_id": "69817e2cce18b186280961a0", "name": "Yangyang Hu", "hidden": false}, {"_id": "69817e2cce18b186280961a1", "name": "Zhenxing Hu", "hidden": false}, {"_id": "69817e2cce18b186280961a2", "name": "Ke Huang", "hidden": false}, {"_id": "69817e2cce18b186280961a3", "name": "Ruiyuan Huang", "hidden": false}, {"_id": "69817e2cce18b186280961a4", "name": "Weixiao Huang", "hidden": false}, {"_id": "69817e2cce18b186280961a5", "name": "Zhiqi Huang", "hidden": false}, {"_id": "69817e2cce18b186280961a6", "name": "Tao Jiang", "hidden": false}, {"_id": "69817e2cce18b186280961a7", "name": "Zhejun Jiang", "hidden": false}, {"_id": "69817e2cce18b186280961a8", "name": "Xinyi Jin", "hidden": false}, {"_id": "69817e2cce18b186280961a9", "name": "Yu Jing", "hidden": false}, {"_id": "69817e2cce18b186280961aa", "name": "Guokun Lai", "hidden": false}, {"_id": "69817e2cce18b186280961ab", "name": "Aidi Li", "hidden": false}, {"_id": "69817e2cce18b186280961ac", "name": "C. Li", "hidden": false}, {"_id": "69817e2cce18b186280961ad", "name": "Cheng Li", "hidden": false}, {"_id": "69817e2cce18b186280961ae", "name": "Fang Li", "hidden": false}, {"_id": "69817e2cce18b186280961af", "name": "Guanghe Li", "hidden": false}, {"_id": "69817e2cce18b186280961b0", "name": "Guanyu Li", "hidden": false}, {"_id": "69817e2cce18b186280961b1", "name": "Haitao Li", "hidden": false}, {"_id": "69817e2cce18b186280961b2", "name": "Haoyang Li", "hidden": false}, {"_id": "69817e2cce18b186280961b3", "name": "Jia Li", "hidden": false}, {"_id": "69817e2cce18b186280961b4", "name": "Jingwei Li", "hidden": false}, {"_id": "69817e2cce18b186280961b5", "name": "Junxiong Li", "hidden": false}, {"_id": "69817e2cce18b186280961b6", "name": "Lincan Li", "hidden": false}, {"_id": "69817e2cce18b186280961b7", "user": {"_id": "6576fe2b42ab083faea19841", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/c91ZKOR2E0gL8iIVkvEUa.jpeg", "isPro": false, "fullname": "Mo Li", "user": "Mor-Li", "type": "user"}, "name": "Mo Li", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:05:51.899Z", "hidden": false}, {"_id": "69817e2cce18b186280961b8", "name": "Weihong Li", "hidden": false}, {"_id": "69817e2cce18b186280961b9", "name": "Wentao Li", "hidden": false}, {"_id": "69817e2cce18b186280961ba", "name": "Xinhang Li", "hidden": false}, {"_id": "69817e2cce18b186280961bb", "name": "Xinhao Li", "hidden": false}, {"_id": "69817e2cce18b186280961bc", "name": "Yang Li", "hidden": false}, {"_id": "69817e2cce18b186280961bd", "name": "Yanhao Li", "hidden": false}, {"_id": "69817e2cce18b186280961be", "name": "Yiwei Li", "hidden": false}, {"_id": "69817e2cce18b186280961bf", "name": "Yuxiao Li", "hidden": false}, {"_id": "69817e2cce18b186280961c0", "name": "Zhaowei Li", "hidden": false}, {"_id": "69817e2cce18b186280961c1", "name": "Zheming Li", "hidden": false}, {"_id": "69817e2cce18b186280961c2", "name": "Weilong Liao", "hidden": false}, {"_id": "69817e2cce18b186280961c3", "name": "Jiawei Lin", "hidden": false}, {"_id": "69817e2cce18b186280961c4", "name": "Xiaohan Lin", "hidden": false}, {"_id": "69817e2cce18b186280961c5", "name": "Zhishan Lin", "hidden": false}, {"_id": "69817e2cce18b186280961c6", "name": "Zichao Lin", "hidden": false}, {"_id": "69817e2cce18b186280961c7", "name": "Cheng Liu", "hidden": false}, {"_id": "69817e2cce18b186280961c8", "name": "Chenyu Liu", "hidden": false}, {"_id": "69817e2cce18b186280961c9", "name": "Hongzhang Liu", "hidden": false}, {"_id": "69817e2cce18b186280961ca", "name": "Liang Liu", "hidden": false}, {"_id": "69817e2cce18b186280961cb", "name": "Shaowei Liu", "hidden": false}, {"_id": "69817e2cce18b186280961cc", "name": "Shudong Liu", "hidden": false}, {"_id": "69817e2cce18b186280961cd", "name": "Shuran Liu", "hidden": false}, {"_id": "69817e2cce18b186280961ce", "name": "Tianwei Liu", "hidden": false}, {"_id": "69817e2cce18b186280961cf", "name": "Tianyu Liu", "hidden": false}, {"_id": "69817e2cce18b186280961d0", "name": "Weizhou Liu", "hidden": false}, {"_id": "69817e2cce18b186280961d1", "name": "Xiangyan Liu", "hidden": false}, {"_id": "69817e2cce18b186280961d2", "name": "Yangyang Liu", "hidden": false}, {"_id": "69817e2cce18b186280961d3", "name": "Yanming Liu", "hidden": false}, {"_id": "69817e2cce18b186280961d4", "name": "Yibo Liu", "hidden": false}, {"_id": "69817e2cce18b186280961d5", "name": "Yuanxin Liu", "hidden": false}, {"_id": "69817e2cce18b186280961d6", "name": "Yue Liu", "hidden": false}, {"_id": "69817e2cce18b186280961d7", "name": "Zhengying Liu", "hidden": false}, {"_id": "69817e2cce18b186280961d8", "name": "Zhongnuo Liu", "hidden": false}, {"_id": "69817e2cce18b186280961d9", "name": "Enzhe Lu", "hidden": false}, {"_id": "69817e2cce18b186280961da", "name": "Haoyu Lu", "hidden": false}, {"_id": "69817e2cce18b186280961db", "name": "Zhiyuan Lu", "hidden": false}, {"_id": "69817e2cce18b186280961dc", "user": {"_id": "642da1cd99f3110ac27caca5", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642da1cd99f3110ac27caca5/C1QJY3R_ZdaeANG1y8iW7.jpeg", "isPro": false, "fullname": "junyu", "user": "luojunyu", "type": "user"}, "name": "Junyu Luo", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:59:08.357Z", "hidden": false}, {"_id": "69817e2cce18b186280961dd", "name": "Tongxu Luo", "hidden": false}, {"_id": "69817e2cce18b186280961de", "name": "Yashuo Luo", "hidden": false}, {"_id": "69817e2cce18b186280961df", "name": "Long Ma", "hidden": false}, {"_id": "69817e2cce18b186280961e0", "name": "Yingwei Ma", "hidden": false}, {"_id": "69817e2cce18b186280961e1", "name": "Shaoguang Mao", "hidden": false}, {"_id": "69817e2cce18b186280961e2", "name": "Yuan Mei", "hidden": false}, {"_id": "69817e2cce18b186280961e3", "name": "Xin Men", "hidden": false}, {"_id": "69817e2cce18b186280961e4", "name": "Fanqing Meng", "hidden": false}, {"_id": "69817e2cce18b186280961e5", "name": "Zhiyong Meng", "hidden": false}, {"_id": "69817e2cce18b186280961e6", "name": "Yibo Miao", "hidden": false}, {"_id": "69817e2cce18b186280961e7", "name": "Minqing Ni", "hidden": false}, {"_id": "69817e2cce18b186280961e8", "name": "Kun Ouyang", "hidden": false}, {"_id": "69817e2cce18b186280961e9", "name": "Siyuan Pan", "hidden": false}, {"_id": "69817e2cce18b186280961ea", "name": "Bo Pang", "hidden": false}, {"_id": "69817e2cce18b186280961eb", "name": "Yuchao Qian", "hidden": false}, {"_id": "69817e2cce18b186280961ec", "name": "Ruoyu Qin", "hidden": false}, {"_id": "69817e2cce18b186280961ed", "name": "Zeyu Qin", "hidden": false}, {"_id": "69817e2cce18b186280961ee", "name": "Jiezhong Qiu", "hidden": false}, {"_id": "69817e2cce18b186280961ef", "name": "Bowen Qu", "hidden": false}, {"_id": "69817e2cce18b186280961f0", "name": "Zeyu Shang", "hidden": false}, {"_id": "69817e2cce18b186280961f1", "name": "Youbo Shao", "hidden": false}, {"_id": "69817e2cce18b186280961f2", "name": "Tianxiao Shen", "hidden": false}, {"_id": "69817e2cce18b186280961f3", "name": "Zhennan Shen", "hidden": false}, {"_id": "69817e2cce18b186280961f4", "name": "Juanfeng Shi", "hidden": false}, {"_id": "69817e2cce18b186280961f5", "name": "Lidong Shi", "hidden": false}, {"_id": "69817e2cce18b186280961f6", "name": "Shengyuan Shi", "hidden": false}, {"_id": "69817e2cce18b186280961f7", "name": "Feifan Song", "hidden": false}, {"_id": "69817e2cce18b186280961f8", "name": "Pengwei Song", "hidden": false}, {"_id": "69817e2cce18b186280961f9", "name": "Tianhui Song", "hidden": false}, {"_id": "69817e2cce18b186280961fa", "name": "Xiaoxi Song", "hidden": false}, {"_id": "69817e2cce18b186280961fb", "name": "Hongjin Su", "hidden": false}, {"_id": "69817e2cce18b186280961fc", "name": "Jianlin Su", "hidden": false}, {"_id": "69817e2cce18b186280961fd", "name": "Zhaochen Su", "hidden": false}, {"_id": "69817e2cce18b186280961fe", "name": "Lin Sui", "hidden": false}, {"_id": "69817e2cce18b186280961ff", "name": "Jinsong Sun", "hidden": false}, {"_id": "69817e2cce18b18628096200", "name": "Junyao Sun", "hidden": false}, {"_id": "69817e2cce18b18628096201", "name": "Tongyu Sun", "hidden": false}, {"_id": "69817e2cce18b18628096202", "name": "Flood Sung", "hidden": false}, {"_id": "69817e2cce18b18628096203", "name": "Yunpeng Tai", "hidden": false}, {"_id": "69817e2cce18b18628096204", "name": "Chuning Tang", "hidden": false}, {"_id": "69817e2cce18b18628096205", "name": "Heyi Tang", "hidden": false}, {"_id": "69817e2cce18b18628096206", "name": "Xiaojuan Tang", "hidden": false}, {"_id": "69817e2cce18b18628096207", "name": "Zhengyang Tang", "hidden": false}, {"_id": "69817e2cce18b18628096208", "name": "Jiawen Tao", "hidden": false}, {"_id": "69817e2cce18b18628096209", "name": "Shiyuan Teng", "hidden": false}, {"_id": "69817e2cce18b1862809620a", "name": "Chaoran Tian", "hidden": false}, {"_id": "69817e2cce18b1862809620b", "name": "Pengfei Tian", "hidden": false}, {"_id": "69817e2cce18b1862809620c", "name": "Ao Wang", "hidden": false}, {"_id": "69817e2cce18b1862809620d", "name": "Bowen Wang", "hidden": false}, {"_id": "69817e2cce18b1862809620e", "name": "Chensi Wang", "hidden": false}, {"_id": "69817e2cce18b1862809620f", "name": "Chuang Wang", "hidden": false}, {"_id": "69817e2cce18b18628096210", "name": "Congcong Wang", "hidden": false}, {"_id": "69817e2cce18b18628096211", "name": "Dingkun Wang", "hidden": false}, {"_id": "69817e2cce18b18628096212", "name": "Dinglu Wang", "hidden": false}, {"_id": "69817e2cce18b18628096213", "name": "Dongliang Wang", "hidden": false}, {"_id": "69817e2cce18b18628096214", "name": "Feng Wang", "hidden": false}, {"_id": "69817e2cce18b18628096215", "name": "Hailong Wang", "hidden": false}, {"_id": "69817e2cce18b18628096216", "name": "Haiming Wang", "hidden": false}, {"_id": "69817e2cce18b18628096217", "name": "Hengzhi Wang", "hidden": false}, {"_id": "69817e2cce18b18628096218", "name": "Huaqing Wang", "hidden": false}, {"_id": "69817e2cce18b18628096219", "name": "Hui Wang", "hidden": false}, {"_id": "69817e2cce18b1862809621a", "name": "Jiahao Wang", "hidden": false}, {"_id": "69817e2cce18b1862809621b", "name": "Jinhong Wang", "hidden": false}, {"_id": "69817e2cce18b1862809621c", "name": "Jiuzheng Wang", "hidden": false}, {"_id": "69817e2cce18b1862809621d", "name": "Kaixin Wang", "hidden": false}, {"_id": "69817e2cce18b1862809621e", "name": "Linian Wang", "hidden": false}, {"_id": "69817e2cce18b1862809621f", "name": "Qibin Wang", "hidden": false}, {"_id": "69817e2cce18b18628096220", "name": "Shengjie Wang", "hidden": false}, {"_id": "69817e2cce18b18628096221", "name": "Shuyi Wang", "hidden": false}, {"_id": "69817e2cce18b18628096222", "name": "Si Wang", "hidden": false}, {"_id": "69817e2cce18b18628096223", "name": "Wei Wang", "hidden": false}, {"_id": "69817e2cce18b18628096224", "name": "Xiaochen Wang", "hidden": false}, {"_id": "69817e2cce18b18628096225", "name": "Xinyuan Wang", "hidden": false}, {"_id": "69817e2cce18b18628096226", "name": "Yao Wang", "hidden": false}, {"_id": "69817e2cce18b18628096227", "name": "Yejie Wang", "hidden": false}, {"_id": "69817e2cce18b18628096228", "name": "Yipu Wang", "hidden": false}, {"_id": "69817e2cce18b18628096229", "name": "Yiqin Wang", "hidden": false}, {"_id": "69817e2cce18b1862809622a", "name": "Yucheng Wang", "hidden": false}, {"_id": "69817e2cce18b1862809622b", "name": "Yuzhi Wang", "hidden": false}, {"_id": "69817e2cce18b1862809622c", "name": "Zhaoji Wang", "hidden": false}, {"_id": "69817e2cce18b1862809622d", "name": "Zhaowei Wang", "hidden": false}, {"_id": "69817e2cce18b1862809622e", "name": "Zhengtao Wang", "hidden": false}, {"_id": "69817e2cce18b1862809622f", "name": "Zhexu Wang", "hidden": false}, {"_id": "69817e2cce18b18628096230", "name": "Zihan Wang", "hidden": false}, {"_id": "69817e2cce18b18628096231", "name": "Zizhe Wang", "hidden": false}, {"_id": "69817e2cce18b18628096232", "user": {"_id": "635ddec594e5b275ca7941e8", "avatarUrl": "/avatars/28ebfaee74d31e1de020a3ae735a4c1b.svg", "isPro": false, "fullname": "Chu Wei", "user": "courage17340", "type": "user"}, "name": "Chu Wei", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:59:17.862Z", "hidden": false}, {"_id": "69817e2cce18b18628096233", "name": "Ming Wei", "hidden": false}, {"_id": "69817e2cce18b18628096234", "name": "Chuan Wen", "hidden": false}, {"_id": "69817e2cce18b18628096235", "user": {"_id": "653b8c3e97a4d71d950e2f20", "avatarUrl": "/avatars/b68880022e14556d0be58c69615db3be.svg", "isPro": false, "fullname": "Zichen Wen", "user": "zichenwen", "type": "user"}, "name": "Zichen Wen", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:09:43.363Z", "hidden": false}, {"_id": "69817e2cce18b18628096236", "name": "Chengjie Wu", "hidden": false}, {"_id": "69817e2cce18b18628096237", "user": {"_id": "63047ed2412a1b9d381b09c9", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63047ed2412a1b9d381b09c9/2Ill5G0uSMyGstrawgmIb.jpeg", "isPro": true, "fullname": "Haoning Wu, Teo", "user": "teowu", "type": "user"}, "name": "Haoning Wu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:05:49.884Z", "hidden": false}, {"_id": "69817e2cce18b18628096238", "name": "Junyan Wu", "hidden": false}, {"_id": "69817e2cce18b18628096239", "name": "Rucong Wu", "hidden": false}, {"_id": "69817e2cce18b1862809623a", "name": "Wenhao Wu", "hidden": false}, {"_id": "69817e2cce18b1862809623b", "name": "Yuefeng Wu", "hidden": false}, {"_id": "69817e2cce18b1862809623c", "name": "Yuhao Wu", "hidden": false}, {"_id": "69817e2cce18b1862809623d", "name": "Yuxin Wu", "hidden": false}, {"_id": "69817e2cce18b1862809623e", "name": "Zijian Wu", "hidden": false}, {"_id": "69817e2cce18b1862809623f", "name": "Chenjun Xiao", "hidden": false}, {"_id": "69817e2cce18b18628096240", "name": "Jin Xie", "hidden": false}, {"_id": "69817e2cce18b18628096241", "name": "Xiaotong Xie", "hidden": false}, {"_id": "69817e2cce18b18628096242", "name": "Yuchong Xie", "hidden": false}, {"_id": "69817e2cce18b18628096243", "name": "Yifei Xin", "hidden": false}, {"_id": "69817e2cce18b18628096244", "name": "Bowei Xing", "hidden": false}, {"_id": "69817e2cce18b18628096245", "name": "Boyu Xu", "hidden": false}, {"_id": "69817e2cce18b18628096246", "name": "Jianfan Xu", "hidden": false}, {"_id": "69817e2cce18b18628096247", "name": "Jing Xu", "hidden": false}, {"_id": "69817e2cce18b18628096248", "name": "Jinjing Xu", "hidden": false}, {"_id": "69817e2cce18b18628096249", "name": "L. H. Xu", "hidden": false}, {"_id": "69817e2cce18b1862809624a", "name": "Lin Xu", "hidden": false}, {"_id": "69817e2cce18b1862809624b", "name": "Suting Xu", "hidden": false}, {"_id": "69817e2cce18b1862809624c", "name": "Weixin Xu", "hidden": false}, {"_id": "69817e2cce18b1862809624d", "name": "Xinbo Xu", "hidden": false}, {"_id": "69817e2cce18b1862809624e", "name": "Xinran Xu", "hidden": false}, {"_id": "69817e2cce18b1862809624f", "name": "Yangchuan Xu", "hidden": false}, {"_id": "69817e2cce18b18628096250", "name": "Yichang Xu", "hidden": false}, {"_id": "69817e2cce18b18628096251", "name": "Yuemeng Xu", "hidden": false}, {"_id": "69817e2cce18b18628096252", "name": "Zelai Xu", "hidden": false}, {"_id": "69817e2cce18b18628096253", "name": "Ziyao Xu", "hidden": false}, {"_id": "69817e2cce18b18628096254", "name": "Junjie Yan", "hidden": false}, {"_id": "69817e2cce18b18628096255", "name": "Yuzi Yan", "hidden": false}, {"_id": "69817e2cce18b18628096256", "name": "Guangyao Yang", "hidden": false}, {"_id": "69817e2cce18b18628096257", "name": "Hao Yang", "hidden": false}, {"_id": "69817e2cce18b18628096258", "name": "Junwei Yang", "hidden": false}, {"_id": "69817e2cce18b18628096259", "name": "Kai Yang", "hidden": false}, {"_id": "69817e2cce18b1862809625a", "name": "Ningyuan Yang", "hidden": false}, {"_id": "69817e2cce18b1862809625b", "name": "Ruihan Yang", "hidden": false}, {"_id": "69817e2cce18b1862809625c", "name": "Xiaofei Yang", "hidden": false}, {"_id": "69817e2cce18b1862809625d", "name": "Xinlong Yang", "hidden": false}, {"_id": "69817e2cce18b1862809625e", "name": "Ying Yang", "hidden": false}, {"_id": "69817e2cce18b1862809625f", "name": "Yi Yang", "hidden": false}, {"_id": "69817e2cce18b18628096260", "name": "Yi Yang", "hidden": false}, {"_id": "69817e2cce18b18628096261", "name": "Zhen Yang", "hidden": false}, {"_id": "69817e2cce18b18628096262", "name": "Zhilin Yang", "hidden": false}, {"_id": "69817e2cce18b18628096263", "name": "Zonghan Yang", "hidden": false}, {"_id": "69817e2cce18b18628096264", "user": {"_id": "642bcd9be8dfcc1fe4f4f853", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642bcd9be8dfcc1fe4f4f853/M9Yqkyt66dnWWCwmBZ8l0.jpeg", "isPro": false, "fullname": "Haotian Yao", "user": "skylark-95", "type": "user"}, "name": "Haotian Yao", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:59:12.739Z", "hidden": false}, {"_id": "69817e2cce18b18628096265", "name": "Dan Ye", "hidden": false}, {"_id": "69817e2cce18b18628096266", "name": "Wenjie Ye", "hidden": false}, {"_id": "69817e2cce18b18628096267", "name": "Zhuorui Ye", "hidden": false}, {"_id": "69817e2cce18b18628096268", "name": "Bohong Yin", "hidden": false}, {"_id": "69817e2cce18b18628096269", "name": "Chengzhen Yu", "hidden": false}, {"_id": "69817e2cce18b1862809626a", "name": "Longhui Yu", "hidden": false}, {"_id": "69817e2cce18b1862809626b", "name": "Tao Yu", "hidden": false}, {"_id": "69817e2cce18b1862809626c", "name": "Tianxiang Yu", "hidden": false}, {"_id": "69817e2cce18b1862809626d", "name": "Enming Yuan", "hidden": false}, {"_id": "69817e2cce18b1862809626e", "name": "Mengjie Yuan", "hidden": false}, {"_id": "69817e2cce18b1862809626f", "name": "Xiaokun Yuan", "hidden": false}, {"_id": "69817e2cce18b18628096270", "name": "Yang Yue", "hidden": false}, {"_id": "69817e2cce18b18628096271", "name": "Weihao Zeng", "hidden": false}, {"_id": "69817e2cce18b18628096272", "name": "Dunyuan Zha", "hidden": false}, {"_id": "69817e2cce18b18628096273", "name": "Haobing Zhan", "hidden": false}, {"_id": "69817e2cce18b18628096274", "name": "Dehao Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096275", "name": "Hao Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096276", "name": "Jin Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096277", "name": "Puqi Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096278", "name": "Qiao Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096279", "name": "Rui Zhang", "hidden": false}, {"_id": "69817e2cce18b1862809627a", "name": "Xiaobin Zhang", "hidden": false}, {"_id": "69817e2cce18b1862809627b", "name": "Y. Zhang", "hidden": false}, {"_id": "69817e2cce18b1862809627c", "name": "Yadong Zhang", "hidden": false}, {"_id": "69817e2cce18b1862809627d", "name": "Yangkun Zhang", "hidden": false}, {"_id": "69817e2cce18b1862809627e", "name": "Yichi Zhang", "hidden": false}, {"_id": "69817e2cce18b1862809627f", "name": "Yizhi Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096280", "name": "Yongting Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096281", "name": "Yu Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096282", "name": "Yushun Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096283", "name": "Yutao Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096284", "name": "Yutong Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096285", "name": "Zheng Zhang", "hidden": false}, {"_id": "69817e2cce18b18628096286", "name": "Chenguang Zhao", "hidden": false}, {"_id": "69817e2cce18b18628096287", "name": "Feifan Zhao", "hidden": false}, {"_id": "69817e2cce18b18628096288", "name": "Jinxiang Zhao", "hidden": false}, {"_id": "69817e2cce18b18628096289", "name": "Shuai Zhao", "hidden": false}, {"_id": "69817e2cce18b1862809628a", "name": "Xiangyu Zhao", "hidden": false}, {"_id": "69817e2cce18b1862809628b", "name": "Yikai Zhao", "hidden": false}, {"_id": "69817e2cce18b1862809628c", "name": "Zijia Zhao", "hidden": false}, {"_id": "69817e2cce18b1862809628d", "name": "Huabin Zheng", "hidden": false}, {"_id": "69817e2cce18b1862809628e", "name": "Ruihan Zheng", "hidden": false}, {"_id": "69817e2cce18b1862809628f", "name": "Shaojie Zheng", "hidden": false}, {"_id": "69817e2cce18b18628096290", "name": "Tengyang Zheng", "hidden": false}, {"_id": "69817e2cce18b18628096291", "name": "Junfeng Zhong", "hidden": false}, {"_id": "69817e2cce18b18628096292", "user": {"_id": "62b6d20416ff90e6198301b6", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656148456743-noauth.png", "isPro": false, "fullname": "Longguang Zhong", "user": "GGLS", "type": "user"}, "name": "Longguang Zhong", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:59:14.989Z", "hidden": false}, {"_id": "69817e2cce18b18628096293", "name": "Weiming Zhong", "hidden": false}, {"_id": "69817e2cce18b18628096294", "name": "M. Zhou", "hidden": false}, {"_id": "69817e2cce18b18628096295", "name": "Runjie Zhou", "hidden": false}, {"_id": "69817e2cce18b18628096296", "name": "Xinyu Zhou", "hidden": false}, {"_id": "69817e2cce18b18628096297", "name": "Zaida Zhou", "hidden": false}, {"_id": "69817e2cce18b18628096298", "name": "Jinguo Zhu", "hidden": false}, {"_id": "69817e2cce18b18628096299", "name": "Liya Zhu", "hidden": false}, {"_id": "69817e2cce18b1862809629a", "name": "Xinhao Zhu", "hidden": false}, {"_id": "69817e2cce18b1862809629b", "name": "Yuxuan Zhu", "hidden": false}, {"_id": "69817e2cce18b1862809629c", "name": "Zhen Zhu", "hidden": false}, {"_id": "69817e2cce18b1862809629d", "name": "Jingze Zhuang", "hidden": false}, {"_id": "69817e2cce18b1862809629e", "name": "Weiyu Zhuang", "hidden": false}, {"_id": "69817e2cce18b1862809629f", "name": "Ying Zou", "hidden": false}, {"_id": "69817e2cce18b186280962a0", "name": "Xinxing Zu", "hidden": false}], "publishedAt": "2026-02-02T16:17:38.000Z", "submittedOnDailyAt": "2026-02-03T02:18:48.721Z", "title": "Kimi K2.5: Visual Agentic Intelligence", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to 4.5times over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.", "upvotes": 149, "discussionId": "69817e2cce18b186280962a1", "projectPage": "https://huggingface.co/moonshotai/Kimi-K2.5", "ai_summary": "Kimi K2.5 is an open-source multimodal agentic model that enhances text and vision processing through joint optimization techniques and introduces Agent Swarm for parallel task execution.", "ai_keywords": ["multimodal agentic model", "joint text-vision pre-training", "zero-vision SFT", "joint text-vision reinforcement learning", "Agent Swarm", "self-directed parallel agent orchestration framework", "heterogeneous sub-problems"], "organization": {"_id": "6425a114812813f8f4a9b02c", "name": "moonshotai", "fullname": "Moonshot AI", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/641c1e77c3983aa9490f8121/X1yT2rsaIbR9cdYGEVu0X.jpeg"}, "summary_zh": "<ul>\n  <li>\u6211\u4eec\u63a8\u51fa\u4e86Kimi K2.5\uff0c\u4e00\u4e2a\u5f00\u6e90\u7684\u591a\u6a21\u6001\u667a\u80fd\u6a21\u578b\uff0c\u65e8\u5728\u63d0\u5347\u901a\u7528\u667a\u80fd\u3002</li>\n  <li>K2.5\u5f3a\u8c03\u6587\u672c\u548c\u89c6\u89c9\u7684\u8054\u5408\u4f18\u5316\uff0c\u4f7f\u4e24\u79cd\u6a21\u6001\u80fd\u591f\u76f8\u4e92\u589e\u5f3a\u3002</li>\n  <li>\u8be5\u6a21\u578b\u4f7f\u7528\u4e86\u4e00\u7cfb\u5217\u6280\u672f\uff0c\u5305\u62ec\u8054\u5408\u6587\u672c-\u89c6\u89c9\u9884\u8bad\u7ec3\u548c\u5f3a\u5316\u5b66\u4e60\u3002</li>\n  <li>K2.5\u5f15\u5165\u4e86Agent Swarm\u6846\u67b6\uff0c\u53ef\u4ee5\u5c06\u590d\u6742\u4efb\u52a1\u5206\u89e3\u6210\u591a\u4e2a\u5b50\u95ee\u9898\u5e76\u540c\u65f6\u6267\u884c\u3002</li>\n  <li>Kimi K2.5\u5728\u591a\u4e2a\u9886\u57df\uff08\u5982\u7f16\u7801\u3001\u89c6\u89c9\u3001\u63a8\u7406\u7b49\uff09\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u4e14\u51cf\u5c11\u5ef6\u8fdf\u8fbe4.5\u500d\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Kimi K2.5 is an open-source model aimed at improving general intelligence that can understand both text and images.</li>\n    <li>The model uses techniques that help text and vision work together better, like joint training and reinforcement learning.</li>\n    <li>Kimi K2.5 includes a feature called Agent Swarm, which breaks down complex tasks into smaller parts that can be worked on at the same time.</li>\n    <li>Tests show Kimi K2.5 performs exceptionally well in areas like coding, vision, reasoning, and task management.</li>\n    <li>The developers have released the updated Kimi K2.5 model for other researchers and practical uses.</li>\n</ul>"}, "publishedAt": "2026-02-02T11:17:38.000Z", "title": "Kimi K2.5: Visual Agentic Intelligence", "summary": "We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to 4.5times over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.02276.png", "numComments": 1, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 227, "isUserFollowing": false}, "organization": {"_id": "6425a114812813f8f4a9b02c", "name": "moonshotai", "fullname": "Moonshot AI", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/641c1e77c3983aa9490f8121/X1yT2rsaIbR9cdYGEVu0X.jpeg"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.09082", "authors": [{"_id": "698bea506052d3bed96309cb", "name": "Veuns-Team", "hidden": false}, {"_id": "698bea506052d3bed96309cd", "name": "Changlong Gao", "hidden": false}, {"_id": "698bea506052d3bed96309ce", "user": {"_id": "60d2a2984956988b63753371", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60d2a2984956988b63753371/apXIcWbi7jnLVH37CdMTV.jpeg", "isPro": false, "fullname": "Zhangxuan Gu", "user": "zhangxgu", "type": "user"}, "name": "Zhangxuan Gu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:15:14.456Z", "hidden": false}, {"_id": "698bea506052d3bed96309cf", "name": "Yulin Liu", "hidden": false}, {"_id": "698bea506052d3bed96309d0", "name": "Xinyu Qiu", "hidden": false}, {"_id": "698bea506052d3bed96309d1", "name": "Shuheng Shen", "hidden": false}, {"_id": "698bea506052d3bed96309d2", "name": "Yue Wen", "hidden": false}, {"_id": "698bea506052d3bed96309d3", "name": "Tianyu Xia", "hidden": false}, {"_id": "698bea506052d3bed96309d4", "name": "Zhenyu Xu", "hidden": false}, {"_id": "698bea506052d3bed96309d5", "user": {"_id": "64cb238576200ec80fe988f8", "avatarUrl": "/avatars/42c48710c7881c9dfbcc075fec3cb600.svg", "isPro": false, "fullname": "zeus", "user": "zengw", "type": "user"}, "name": "Zhengwen Zeng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:24:43.235Z", "hidden": false}, {"_id": "698bea506052d3bed96309d6", "user": {"_id": "654c9dac09dd7ef524a0be1e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/654c9dac09dd7ef524a0be1e/T4glmZthS0mJydhvGZGKH.png", "isPro": false, "fullname": "beitongzhou", "user": "syorami", "type": "user"}, "name": "Beitong Zhou", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:15:11.859Z", "hidden": false}, {"_id": "698bea506052d3bed96309d7", "name": "Xingran Zhou", "hidden": false}, {"_id": "698bea506052d3bed96309d8", "name": "Weizhi Chen", "hidden": false}, {"_id": "698bea506052d3bed96309d9", "name": "Sunhao Dai", "hidden": false}, {"_id": "698bea506052d3bed96309da", "name": "Jingya Dou", "hidden": false}, {"_id": "698bea506052d3bed96309db", "name": "Yichen Gong", "hidden": false}, {"_id": "698bea506052d3bed96309dc", "name": "Yuan Guo", "hidden": false}, {"_id": "698bea506052d3bed96309dd", "name": "Zhenlin Guo", "hidden": false}, {"_id": "698bea506052d3bed96309de", "user": {"_id": "65e0763a9299e96ee674876e", "avatarUrl": "/avatars/0ea342c9f72fa3b8a8f634559d094907.svg", "isPro": false, "fullname": "fengdian", "user": "fengrudian", "type": "user"}, "name": "Feng Li", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:16:04.463Z", "hidden": false}, {"_id": "698bea506052d3bed96309df", "name": "Qian Li", "hidden": false}, {"_id": "698bea506052d3bed96309e0", "name": "Jinzhen Lin", "hidden": false}, {"_id": "698bea506052d3bed96309e1", "name": "Yuqi Zhou", "hidden": false}, {"_id": "698bea506052d3bed96309e2", "name": "Linchao Zhu", "hidden": false}, {"_id": "698bea506052d3bed96309e3", "name": "Liang Chen", "hidden": false}, {"_id": "698bea506052d3bed96309e4", "name": "Zhenyu Guo", "hidden": false}, {"_id": "698bea506052d3bed96309e5", "name": "Changhua Meng", "hidden": false}, {"_id": "698bea506052d3bed96309e6", "name": "Weiqiang Wang", "hidden": false}], "publishedAt": "2026-02-09T18:43:40.000Z", "submittedOnDailyAt": "2026-02-11T00:10:55.649Z", "title": "UI-Venus-1.5 Technical Report", "submittedOnDailyBy": {"_id": "60d2a2984956988b63753371", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60d2a2984956988b63753371/apXIcWbi7jnLVH37CdMTV.jpeg", "isPro": false, "fullname": "Zhangxuan Gu", "user": "zhangxgu", "type": "user"}, "summary": "GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging.In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications.The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios.Compared to our previous version, UI-Venus-1.5 introduces three key technical advances: (1) a comprehensive Mid-Training stage leveraging 10 billion tokens across 30+ datasets to establish foundational GUI semantics; (2) Online Reinforcement Learning with full-trajectory rollouts, aligning training objectives with long-horizon, dynamic navigation in large-scale environments; and (3) a single unified GUI Agent constructed via Model Merging, which synthesizes domain-specific models (grounding, web, and mobile) into one cohesive checkpoint. Extensive evaluations demonstrate that UI-Venus-1.5 establishes new state-of-the-art performance on benchmarks such as ScreenSpot-Pro (69.6%), VenusBench-GD (75.0%), and AndroidWorld (77.6%), significantly outperforming previous strong baselines. In addition, UI-Venus-1.5 demonstrates robust navigation capabilities across a variety of Chinese mobile apps, effectively executing user instructions in real-world scenarios. Code: https://github.com/inclusionAI/UI-Venus; Model: https://huggingface.co/collections/inclusionAI/ui-venus", "upvotes": 143, "discussionId": "698bea516052d3bed96309e7", "projectPage": "https://ui-venus.github.io/UI-Venus-1.5/", "githubRepo": "https://github.com/inclusionAI/UI-Venus/blob/UI-Venus-1.5", "githubRepoAddedBy": "user", "ai_summary": "UI-Venus-1.5 is a unified GUI agent with improved performance through mid-training stages, online reinforcement learning, and model merging techniques.", "ai_keywords": ["GUI agents", "Mid-Training stage", "Online Reinforcement Learning", "full-trajectory rollouts", "Model Merging", "dense variants", "mixture-of-experts variant"], "githubStars": 708, "organization": {"_id": "67aea5c8f086ab0f70ed97c9", "name": "inclusionAI", "fullname": "inclusionAI", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/662e1f9da266499277937d33/fyKuazRifqiaIO34xrhhm.jpeg"}, "summary_zh": "<ul>\n    <li>UI-Venus-1.5\u662f\u4e00\u79cd\u65b0\u7684\u7edf\u4e00GUI\u4ee3\u7406\uff0c\u65e8\u5728\u63d0\u5347\u6570\u5b57\u73af\u5883\u4e2d\u7684\u4ea4\u4e92\u81ea\u52a8\u5316\u3002</li>\n    <li>\u8be5\u6a21\u578b\u6709\u4e24\u79cd\u5bc6\u96c6\u578b\u53d8\u4f53\uff082B\u548c8B\uff09\u4ee5\u53ca\u4e00\u79cd\u6df7\u5408\u4e13\u5bb6\u53d8\u4f53\uff0830B-A3B\uff09\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u5e94\u7528\u573a\u666f\u3002</li>\n    <li>\u76f8\u8f83\u4e8e\u4e4b\u524d\u7684\u7248\u672c\uff0cUI-Venus-1.5\u5f15\u5165\u4e86\u4e09\u4e2a\u6280\u672f\u8fdb\u6b65\uff0c\u5305\u62ec\u5168\u9762\u7684\u4e2d\u671f\u8bad\u7ec3\u9636\u6bb5\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u3002</li>\n    <li>UI-Venus-1.5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8fbe\u5230\u65b0\u7684\u6700\u4f73\u6210\u7ee9\uff0c\u663e\u8457\u8d85\u8d8a\u4e86\u4e4b\u524d\u7684\u6a21\u578b\u3002</li>\n    <li>\u8be5\u6a21\u578b\u5728\u4e2d\u56fd\u624b\u673a\u5e94\u7528\u4e2d\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u5bfc\u822a\u80fd\u529b\uff0c\u80fd\u591f\u6709\u6548\u6267\u884c\u7528\u6237\u6307\u4ee4\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>UI-Venus-1.5 is a new GUI agent designed to automate tasks in digital environments effectively.</li>\n    <li>It includes two main models (2B and 8B) and a larger model (30B-A3B) to suit different application needs.</li>\n    <li>Key improvements include better training methods using a large amount of data, online learning for better navigation, and merging different models into one.</li>\n    <li>UI-Venus-1.5 shows top performance on several benchmarks, outperforming previous models significantly.</li>\n    <li>It can navigate and carry out tasks in various Chinese mobile apps, demonstrating strong real-world application capabilities.</li>\n</ul>"}, "publishedAt": "2026-02-09T13:43:40.000Z", "title": "UI-Venus-1.5 Technical Report", "summary": "GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging.In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications.The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios.Compared to our previous version, UI-Venus-1.5 introduces three key technical advances: (1) a comprehensive Mid-Training stage leveraging 10 billion tokens across 30+ datasets to establish foundational GUI semantics; (2) Online Reinforcement Learning with full-trajectory rollouts, aligning training objectives with long-horizon, dynamic navigation in large-scale environments; and (3) a single unified GUI Agent constructed via Model Merging, which synthesizes domain-specific models (grounding, web, and mobile) into one cohesive checkpoint. Extensive evaluations demonstrate that UI-Venus-1.5 establishes new state-of-the-art performance on benchmarks such as ScreenSpot-Pro (69.6%), VenusBench-GD (75.0%), and AndroidWorld (77.6%), significantly outperforming previous strong baselines. In addition, UI-Venus-1.5 demonstrates robust navigation capabilities across a variety of Chinese mobile apps, effectively executing user instructions in real-world scenarios. Code: https://github.com/inclusionAI/UI-Venus; Model: https://huggingface.co/collections/inclusionAI/ui-venus", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.09082.png", "numComments": 2, "submittedBy": {"_id": "60d2a2984956988b63753371", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60d2a2984956988b63753371/apXIcWbi7jnLVH37CdMTV.jpeg", "fullname": "Zhangxuan Gu", "name": "zhangxgu", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 8, "isUserFollowing": false}, "organization": {"_id": "67aea5c8f086ab0f70ed97c9", "name": "inclusionAI", "fullname": "inclusionAI", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/662e1f9da266499277937d33/fyKuazRifqiaIO34xrhhm.jpeg"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.07085", "authors": [{"_id": "698ab6f91b2dc6b37d61b031", "name": "Jun Han", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b032", "name": "Shuo Zhang", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b033", "name": "Wei Li", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b034", "user": {"_id": "64aa645404e7b379feccc490", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64aa645404e7b379feccc490/4m8qcdy2OGK8visR5Jjl5.png", "isPro": false, "fullname": "Zhi Yang", "user": "yangzhi1", "type": "user"}, "name": "Zhi Yang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-10T09:05:58.707Z", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b035", "name": "Yifan Dong", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b036", "name": "Tu Hu", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b037", "name": "Jialuo Yuan", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b038", "user": {"_id": "64084fa192033c150738e4f2", "avatarUrl": "/avatars/dfff2216eb235c635e5abe6fda3084f0.svg", "isPro": false, "fullname": "Yu_xm", "user": "Yu2020", "type": "user"}, "name": "Xiaomin Yu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-10T09:06:00.954Z", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b039", "name": "Yumo Zhu", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b03a", "name": "Fangqi Lou", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b03b", "name": "Xin Guo", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b03c", "name": "Zhaowei Liu", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b03d", "name": "Tianyi Jiang", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b03e", "name": "Ruichuan An", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b03f", "name": "Jingping Liu", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b040", "name": "Biao Wu", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b041", "name": "Rongze Chen", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b042", "name": "Kunyi Wang", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b043", "name": "Yifan Wang", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b044", "name": "Sen Hu", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b045", "name": "Xinbing Kong", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b046", "name": "Liwen Zhang", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b047", "name": "Ronghao Chen", "hidden": false}, {"_id": "698ab6f91b2dc6b37d61b048", "name": "Huacan Wang", "hidden": false}], "publishedAt": "2026-02-06T08:08:04.000Z", "submittedOnDailyAt": "2026-02-10T02:19:22.216Z", "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining", "submittedOnDailyBy": {"_id": "64aa645404e7b379feccc490", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64aa645404e7b379feccc490/4m8qcdy2OGK8visR5Jjl5.png", "isPro": false, "fullname": "Zhi Yang", "user": "yangzhi1", "type": "user"}, "summary": "Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-round search and reliable reuse of validated experience. To address these challenges, we propose QuantaAlpha, an evolutionary alpha mining framework that treats each end-to-end mining run as a trajectory and improves factors through trajectory-level mutation and crossover operations. QuantaAlpha localizes suboptimal steps in each trajectory for targeted revision and recombines complementary high-reward segments to reuse effective patterns, enabling structured exploration and refinement across mining iterations. During factor generation, QuantaAlpha enforces semantic consistency across the hypothesis, factor expression, and executable code, while constraining the complexity and redundancy of the generated factor to mitigate crowding. Extensive experiments on the China Securities Index 300 (CSI 300) demonstrate consistent gains over strong baseline models and prior agentic systems. When utilizing GPT-5.2, QuantaAlpha achieves an Information Coefficient (IC) of 0.1501, with an Annualized Rate of Return (ARR) of 27.75% and a Maximum Drawdown (MDD) of 7.98%. Moreover, factors mined on CSI 300 transfer effectively to the China Securities Index 500 (CSI 500) and the Standard & Poor's 500 Index (S&P 500), delivering 160% and 137% cumulative excess return over four years, respectively, which indicates strong robustness of QuantaAlpha under market distribution shifts.", "upvotes": 141, "discussionId": "698ab6fa1b2dc6b37d61b049", "githubRepo": "https://github.com/QuantaAlpha/QuantaAlpha", "githubRepoAddedBy": "user", "githubStars": 63, "organization": {"_id": "68b33ab6a9ed99140481cf44", "name": "QuantaAlpha", "fullname": "QuantaAlpha", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/63f7767fbd28622c9b9915e9/DRN8PvmnpKmn2MSLQ7qhF.jpeg"}, "summary_zh": "<ul>\n  <li>QuantaAlpha\u662f\u4e00\u4e2a\u8fdb\u5316\u578b\u7684alpha\u6316\u6398\u6846\u67b6\uff0c\u65e8\u5728\u5e94\u5bf9\u91d1\u878d\u5e02\u573a\u7684\u566a\u58f0\u548c\u975e\u5e73\u7a33\u6027\u3002</li>\n  <li>\u8be5\u6846\u67b6\u901a\u8fc7\u8f68\u8ff9\u7ea7\u7684\u53d8\u5f02\u548c\u4ea4\u53c9\u64cd\u4f5c\u6765\u63d0\u5347\u6316\u6398\u6548\u679c\uff0c\u5e76\u80fd\u591f\u9488\u5bf9\u6027\u5730\u4fee\u6b63\u5b50\u4f18\u5316\u6b65\u9aa4\u3002</li>\n  <li>QuantaAlpha\u786e\u4fdd\u751f\u6210\u7684\u56e0\u5b50\u5728\u5047\u8bbe\u3001\u8868\u8fbe\u548c\u53ef\u6267\u884c\u4ee3\u7801\u4e0a\u4fdd\u6301\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u964d\u4f4e\u590d\u6742\u6027\u548c\u5197\u4f59\u3002</li>\n  <li>\u5728\u4e2d\u56fd\u8bc1\u5238\u6307\u6570300\uff08CSI 300\uff09\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cQuantaAlpha\u5728\u8868\u73b0\u4e0a\u4f18\u4e8e\u5f3a\u57fa\u51c6\u6a21\u578b\u548c\u4e4b\u524d\u7684\u7cfb\u7edf\u3002</li>\n  <li>\u6316\u6398\u5f97\u5230\u7684\u56e0\u5b50\u5728CSI 500\u548c\u6807\u51c6\u666e\u5c14500\u6307\u6570\uff08S&P 500\uff09\u4e0a\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u7684\u8f6c\u79fb\u6548\u679c\uff0c\u663e\u793a\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>Financial markets are unpredictable, making it hard to test new trading strategies effectively.</li>\n    <li>QuantaAlpha is a new system for improving the process of finding profitable trading strategies, using evolutionary techniques to refine existing ideas.</li>\n    <li>It focuses on improving each strategy step by step and combines successful parts of different strategies to enhance performance.</li>\n    <li>QuantaAlpha ensures that the strategies are consistent and not overly complicated, which helps in managing risks.</li>\n    <li>Tests show that QuantaAlpha outperforms previous models and works well across different stock market indices, proving its reliability in changing market conditions.</li>\n</ul>"}, "publishedAt": "2026-02-06T03:08:04.000Z", "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining", "summary": "Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-round search and reliable reuse of validated experience. To address these challenges, we propose QuantaAlpha, an evolutionary alpha mining framework that treats each end-to-end mining run as a trajectory and improves factors through trajectory-level mutation and crossover operations. QuantaAlpha localizes suboptimal steps in each trajectory for targeted revision and recombines complementary high-reward segments to reuse effective patterns, enabling structured exploration and refinement across mining iterations. During factor generation, QuantaAlpha enforces semantic consistency across the hypothesis, factor expression, and executable code, while constraining the complexity and redundancy of the generated factor to mitigate crowding. Extensive experiments on the China Securities Index 300 (CSI 300) demonstrate consistent gains over strong baseline models and prior agentic systems. When utilizing GPT-5.2, QuantaAlpha achieves an Information Coefficient (IC) of 0.1501, with an Annualized Rate of Return (ARR) of 27.75% and a Maximum Drawdown (MDD) of 7.98%. Moreover, factors mined on CSI 300 transfer effectively to the China Securities Index 500 (CSI 500) and the Standard & Poor's 500 Index (S&P 500), delivering 160% and 137% cumulative excess return over four years, respectively, which indicates strong robustness of QuantaAlpha under market distribution shifts.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.07085.png", "numComments": 1, "submittedBy": {"_id": "64aa645404e7b379feccc490", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64aa645404e7b379feccc490/4m8qcdy2OGK8visR5Jjl5.png", "fullname": "Zhi Yang", "name": "yangzhi1", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 2, "isUserFollowing": false}, "organization": {"_id": "68b33ab6a9ed99140481cf44", "name": "QuantaAlpha", "fullname": "QuantaAlpha", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/63f7767fbd28622c9b9915e9/DRN8PvmnpKmn2MSLQ7qhF.jpeg"}, "isAuthorParticipating": true}, {"paper": {"id": "2601.16725", "authors": [{"_id": "6976d5405d41524304c13537", "name": "Meituan LongCat Team", "hidden": false}, {"_id": "6976d5405d41524304c13538", "name": "Anchun Gui", "hidden": false}, {"_id": "6976d5405d41524304c13539", "name": "Bei Li", "hidden": false}, {"_id": "6976d5405d41524304c1353a", "name": "Bingyang Tao", "hidden": false}, {"_id": "6976d5405d41524304c1353b", "name": "Bole Zhou", "hidden": false}, {"_id": "6976d5405d41524304c1353c", "name": "Borun Chen", "hidden": false}, {"_id": "6976d5405d41524304c1353e", "name": "Chao Zhang", "hidden": false}, {"_id": "69772bc15d41524304c13739", "name": "Chao Zhang", "hidden": false}, {"_id": "6976d5405d41524304c1353f", "name": "Chen Gao", "hidden": false}, {"_id": "6976d5405d41524304c13540", "name": "Chen Zhang", "hidden": false}, {"_id": "6976d5405d41524304c13541", "name": "Chengcheng Han", "hidden": false}, {"_id": "6976d5405d41524304c13542", "name": "Chenhui Yang", "hidden": false}, {"_id": "6976d5405d41524304c13543", "name": "Chuyu Zhang", "hidden": false}, {"_id": "6976d5405d41524304c13544", "name": "Cong Chen", "hidden": false}, {"_id": "6976d5405d41524304c13545", "name": "Cunguang Wang", "hidden": false}, {"_id": "6976d5405d41524304c13546", "name": "Daoru Pan", "hidden": false}, {"_id": "6976d5405d41524304c13547", "name": "Defei Bu", "hidden": false}, {"_id": "6976d5405d41524304c13548", "name": "Dengchang Zhao", "hidden": false}, {"_id": "6976d5405d41524304c13549", "name": "Di Xiu", "hidden": false}, {"_id": "6976d5405d41524304c1354a", "name": "Dishan Liu", "hidden": false}, {"_id": "6976d5405d41524304c1354b", "name": "Dongyu Ru", "hidden": false}, {"_id": "6976d5405d41524304c1354c", "name": "Dunwei Tu", "hidden": false}, {"_id": "6976d5405d41524304c1354d", "name": "Fan Wu", "hidden": false}, {"_id": "6976d5405d41524304c1354e", "name": "Fengcheng Yuan", "hidden": false}, {"_id": "6976d5405d41524304c1354f", "name": "Fengcun Li", "hidden": false}, {"_id": "6976d5405d41524304c13550", "name": "Gang Xu", "hidden": false}, {"_id": "6976d5405d41524304c13551", "name": "Guanyu Wu", "hidden": false}, {"_id": "6976d5405d41524304c13552", "name": "Guoyuan Lin", "hidden": false}, {"_id": "6976d5405d41524304c13553", "name": "Haibin Wang", "hidden": false}, {"_id": "6976d5405d41524304c13554", "name": "Hansi Yang", "hidden": false}, {"_id": "6976d5405d41524304c13555", "name": "Hao Yang", "hidden": false}, {"_id": "6976d5405d41524304c13556", "name": "Haonan Yan", "hidden": false}, {"_id": "6976d5405d41524304c13557", "name": "Haoxiang Ma", "hidden": false}, {"_id": "6976d5405d41524304c13558", "name": "Haoxing Wen", "hidden": false}, {"_id": "6976d5405d41524304c13559", "name": "Hongyan Hao", "hidden": false}, {"_id": "6976d5405d41524304c1355a", "name": "Hongyin Tang", "hidden": false}, {"_id": "6976d5405d41524304c1355b", "name": "Hongyu Zang", "hidden": false}, {"_id": "6976d5405d41524304c1355c", "name": "Hongzhi Ni", "hidden": false}, {"_id": "6976d5405d41524304c1355d", "name": "Hui Su", "hidden": false}, {"_id": "6976d5405d41524304c1355e", "name": "Jiacheng Zhang", "hidden": false}, {"_id": "6976d5405d41524304c1355f", "name": "Jiahong Zhou", "hidden": false}, {"_id": "6976d5405d41524304c13560", "name": "Jiahuan Li", "hidden": false}, {"_id": "6976d5405d41524304c13561", "name": "Jiaming Wang", "hidden": false}, {"_id": "6976d5405d41524304c13562", "name": "Jian Yang", "hidden": false}, {"_id": "6976d5405d41524304c13563", "user": {"_id": "64008a0af4ff62c2616d8858", "avatarUrl": "/avatars/b52c98857916fba5377ace8089d658b2.svg", "isPro": false, "fullname": "zhangjf", "user": "zhangjf", "type": "user"}, "name": "Jianfei Zhang", "status": "claimed_verified", "statusLastChangedAt": "2026-01-26T09:09:09.272Z", "hidden": false}, {"_id": "6976d5405d41524304c13564", "name": "Jianhao Xu", "hidden": false}, {"_id": "6976d5405d41524304c13565", "name": "Jianing Wang", "hidden": false}, {"_id": "6976d5405d41524304c13566", "name": "Jiapeng Zhu", "hidden": false}, {"_id": "6976d5405d41524304c13567", "name": "Jiaqi Sun", "hidden": false}, {"_id": "6976d5405d41524304c13568", "name": "Jiarong Shi", "hidden": false}, {"_id": "6976d5405d41524304c13569", "name": "Jiarui Zhao", "hidden": false}, {"_id": "6976d5405d41524304c1356a", "name": "Jingang Wang", "hidden": false}, {"_id": "6976d5405d41524304c1356b", "user": {"_id": "6592472fccbc1e2cc7250903", "avatarUrl": "/avatars/6f04ae66944eb2ce65c5aca7927bab10.svg", "isPro": false, "fullname": "Jinluan Yang", "user": "Jinluan", "type": "user"}, "name": "Jinluan Yang", "status": "claimed_verified", "statusLastChangedAt": "2026-01-26T08:28:47.175Z", "hidden": false}, {"_id": "6976d5405d41524304c1356c", "name": "Jinrui Ding", "hidden": false}, {"_id": "6976d5405d41524304c1356d", "name": "Jinwei Xiao", "hidden": false}, {"_id": "6976d5405d41524304c1356e", "name": "Jiyuan He", "hidden": false}, {"_id": "6976d5405d41524304c1356f", "name": "Juncan Xu", "hidden": false}, {"_id": "6976d5405d41524304c13570", "name": "Kefeng Zhang", "hidden": false}, {"_id": "6976d5405d41524304c13571", "name": "Keheng Wang", "hidden": false}, {"_id": "6976d5405d41524304c13572", "name": "Li Wei", "hidden": false}, {"_id": "6976d5405d41524304c13573", "name": "Lianhui Ma", "hidden": false}, {"_id": "6976d5405d41524304c13574", "name": "Lin Qiu", "hidden": false}, {"_id": "6976d5405d41524304c13575", "name": "Lingbing Kong", "hidden": false}, {"_id": "6976d5405d41524304c13576", "name": "Lingchuan Liu", "hidden": false}, {"_id": "6976d5405d41524304c13577", "name": "Linsen Guo", "hidden": false}, {"_id": "6976d5405d41524304c13578", "name": "Mengshen Zhu", "hidden": false}, {"_id": "6976d5405d41524304c13579", "name": "Mengxia Shen", "hidden": false}, {"_id": "6976d5405d41524304c1357a", "name": "Mingyang Zhu", "hidden": false}, {"_id": "6976d5405d41524304c1357b", "name": "Peiguang Li", "hidden": false}, {"_id": "6976d5405d41524304c1357c", "name": "Peng Pei", "hidden": false}, {"_id": "6976d5405d41524304c1357d", "name": "Pengcheng Jia", "hidden": false}, {"_id": "6976d5405d41524304c1357e", "name": "Pengtao Zhang", "hidden": false}, {"_id": "6976d5405d41524304c1357f", "name": "Peng Zhao", "hidden": false}, {"_id": "6976d5405d41524304c13580", "name": "Qi Gu", "hidden": false}, {"_id": "6976d5405d41524304c13581", "name": "Qiong Huang", "hidden": false}, {"_id": "6976d5405d41524304c13582", "name": "Qiyuan Duan", "hidden": false}, {"_id": "6976d5405d41524304c13583", "name": "Quanchi Weng", "hidden": false}, {"_id": "6976d5405d41524304c13584", "name": "Rongxiang Weng", "hidden": false}, {"_id": "6976d5405d41524304c13585", "name": "Rongzhi Zhang", "hidden": false}, {"_id": "6976d5405d41524304c13586", "name": "Rumei Li", "hidden": false}, {"_id": "6976d5405d41524304c13587", "name": "Shanglin Lei", "hidden": false}, {"_id": "6976d5405d41524304c13588", "user": {"_id": "64db5f5dd68a6ddcc7bd89e9", "avatarUrl": "/avatars/69375ec915927b855813df8a6d486837.svg", "isPro": false, "fullname": "Shengnan An", "user": "ShengnanAn", "type": "user"}, "name": "Shengnan An", "status": "claimed_verified", "statusLastChangedAt": "2026-01-26T09:09:11.410Z", "hidden": false}, {"_id": "6976d5405d41524304c13589", "name": "Shijun Dai", "hidden": false}, {"_id": "6976d5405d41524304c1358a", "name": "Shuaikang Liu", "hidden": false}, {"_id": "6976d5405d41524304c1358b", "name": "Shuang Zhou", "hidden": false}, {"_id": "6976d5405d41524304c1358c", "name": "Shuo Wang", "hidden": false}, {"_id": "6976d5405d41524304c1358d", "name": "Songyuan Zhao", "hidden": false}, {"_id": "6976d5405d41524304c1358e", "name": "Tao Liang", "hidden": false}, {"_id": "6976d5405d41524304c1358f", "name": "Tianhao Hu", "hidden": false}, {"_id": "6976d5405d41524304c13590", "name": "Tianze Chen", "hidden": false}, {"_id": "6976d5405d41524304c13591", "name": "Wei Liu", "hidden": false}, {"_id": "6976d5405d41524304c13592", "name": "Wei Shi", "hidden": false}, {"_id": "6976d5405d41524304c13593", "name": "Wei Wang", "hidden": false}, {"_id": "6976d5405d41524304c13594", "name": "Weifeng Tang", "hidden": false}, {"_id": "6976d5405d41524304c13595", "name": "Wenjie Shi", "hidden": false}, {"_id": "6976d5405d41524304c13596", "name": "Wenlong Zhu", "hidden": false}, {"_id": "6976d5405d41524304c13597", "name": "Wentao Chen", "hidden": false}, {"_id": "6976d5405d41524304c13598", "name": "Wentao Shi", "hidden": false}, {"_id": "6976d5405d41524304c13599", "name": "Xi Su", "hidden": false}, {"_id": "6976d5405d41524304c1359a", "name": "Xiangcheng Liu", "hidden": false}, {"_id": "6976d5405d41524304c1359b", "name": "Xiandi Ma", "hidden": false}, {"_id": "6976d5405d41524304c1359c", "user": {"_id": "63edb098679c2cc40abc6c2e", "avatarUrl": "/avatars/288c7229937c2c3f29fda6d17c7df2eb.svg", "isPro": false, "fullname": "Xiangyu", "user": "xixy", "type": "user"}, "name": "Xiangyu Xi", "status": "claimed_verified", "statusLastChangedAt": "2026-01-26T09:09:13.312Z", "hidden": false}, {"_id": "6976d5405d41524304c1359d", "name": "Xiangyuan Liu", "hidden": false}, {"_id": "6976d5405d41524304c1359e", "name": "Xiangzhou Huang", "hidden": false}, {"_id": "6976d5405d41524304c1359f", "name": "Xiao Liu", "hidden": false}, {"_id": "6976d5405d41524304c135a0", "name": "Xiaodong Cai", "hidden": false}, {"_id": "6976d5405d41524304c135a1", "name": "Xiaolong Chen", "hidden": false}, {"_id": "6976d5405d41524304c135a2", "name": "Xiaowei Shi", "hidden": false}, {"_id": "6976d5405d41524304c135a3", "name": "Xiaoyu Li", "hidden": false}, {"_id": "6976d5405d41524304c135a4", "name": "Xin Chen", "hidden": false}, {"_id": "6976d5405d41524304c135a5", "name": "Xingchen Liu", "hidden": false}, {"_id": "6976d5405d41524304c135a6", "name": "Xuan Huang", "hidden": false}, {"_id": "6976d5405d41524304c135a7", "name": "Xuezhi Cao", "hidden": false}, {"_id": "6976d5405d41524304c135a8", "name": "Xunliang Cai", "hidden": false}, {"_id": "6976d5405d41524304c135a9", "name": "Yan Chen", "hidden": false}, {"_id": "6976d5405d41524304c135aa", "user": {"_id": "63fc1c420aab06079200c15c", "avatarUrl": "/avatars/8e8e82a9a6552848581ca9f65011263c.svg", "isPro": false, "fullname": "yang bai", "user": "byang", "type": "user"}, "name": "Yang Bai", "status": "claimed_verified", "statusLastChangedAt": "2026-01-26T09:09:07.036Z", "hidden": false}, {"_id": "6976d5405d41524304c135ab", "name": "Yang Liu", "hidden": false}, {"_id": "6976d5405d41524304c135ac", "name": "Yang Yang", "hidden": false}, {"_id": "6976d5405d41524304c135ad", "name": "Yang Zheng", "hidden": false}, {"_id": "6976d5405d41524304c135ae", "name": "Yaoming Wang", "hidden": false}, {"_id": "6976d5405d41524304c135af", "name": "Yaoming Zhu", "hidden": false}, {"_id": "6976d5405d41524304c135b0", "name": "Yaqi Huo", "hidden": false}, {"_id": "6976d5405d41524304c135b1", "name": "Yanyu Chen", "hidden": false}, {"_id": "6976d5405d41524304c135b2", "name": "Yaorui Shi", "hidden": false}, {"_id": "6976d5405d41524304c135b3", "name": "Yerui Sun", "hidden": false}, {"_id": "6976d5405d41524304c135b4", "name": "Yi Zhang", "hidden": false}, {"_id": "6976d5405d41524304c135b5", "name": "Yihao Chen", "hidden": false}, {"_id": "6976d5405d41524304c135b6", "name": "Yi-Kai Zhang", "hidden": false}, {"_id": "6976d5405d41524304c135b7", "name": "Yifan Lu", "hidden": false}, {"_id": "6976d5405d41524304c135b8", "name": "Yifan Zhao", "hidden": false}, {"_id": "6976d5405d41524304c135b9", "name": "Yitao Zhai", "hidden": false}, {"_id": "6976d5405d41524304c135ba", "name": "Yongjing Yin", "hidden": false}, {"_id": "6976d5405d41524304c135bb", "name": "Yongwei Zhou", "hidden": false}, {"_id": "6976d5405d41524304c135bc", "name": "Youshao Xiao", "hidden": false}, {"_id": "6976d5405d41524304c135bd", "name": "Yuchuan Dai", "hidden": false}, {"_id": "6976d5405d41524304c135be", "name": "Yuchen Xie", "hidden": false}, {"_id": "6976d5405d41524304c135bf", "name": "Yuchen Yu", "hidden": false}, {"_id": "6976d5405d41524304c135c0", "name": "Yufei Zhang", "hidden": false}, {"_id": "6976d5405d41524304c135c1", "name": "Yuhuai Wei", "hidden": false}, {"_id": "6976d5405d41524304c135c2", "name": "Yulei Qian", "hidden": false}, {"_id": "6976d5405d41524304c135c3", "name": "Yunfan Liang", "hidden": false}, {"_id": "6976d5405d41524304c135c4", "name": "Yunke Zhao", "hidden": false}, {"_id": "6976d5405d41524304c135c5", "name": "Yuwei Jiang", "hidden": false}, {"_id": "6976d5405d41524304c135c6", "name": "Yuxin Bian", "hidden": false}, {"_id": "6976d5405d41524304c135c7", "name": "Yuxin Chen", "hidden": false}, {"_id": "6976d5405d41524304c135c8", "name": "Yuxin Liu", "hidden": false}, {"_id": "6976d5405d41524304c135c9", "name": "Yue Xu", "hidden": false}, {"_id": "6976d5405d41524304c135ca", "name": "Yueqing Sun", "hidden": false}, {"_id": "6976d5405d41524304c135cb", "name": "Zeyang Yu", "hidden": false}, {"_id": "6976d5405d41524304c135cc", "name": "Zhao Yang", "hidden": false}, {"_id": "6976d5405d41524304c135cd", "name": "Zhengsheng Huang", "hidden": false}, {"_id": "6976d5405d41524304c135ce", "name": "Zhengyu Chen", "hidden": false}, {"_id": "6976d5405d41524304c135cf", "name": "Zhijian Liu", "hidden": false}, {"_id": "6976d5405d41524304c135d0", "name": "Zhikang Xia", "hidden": false}, {"_id": "6976d5405d41524304c135d1", "name": "Zhimin Lin", "hidden": false}, {"_id": "6976d5405d41524304c135d2", "name": "Zhiyuan Yao", "hidden": false}, {"_id": "6976d5405d41524304c135d3", "name": "Zhuofan Chen", "hidden": false}, {"_id": "6976d5405d41524304c135d4", "name": "Zhuowen Han", "hidden": false}, {"_id": "6976d5405d41524304c135d5", "name": "Zijian Zhang", "hidden": false}, {"_id": "6976d5405d41524304c135d6", "name": "Ziran Li", "hidden": false}, {"_id": "6976d5405d41524304c135d7", "name": "Ziwen Wang", "hidden": false}, {"_id": "6976d5405d41524304c135d8", "name": "Ziyuan Zhuang", "hidden": false}], "publishedAt": "2026-01-23T13:20:09.000Z", "submittedOnDailyAt": "2026-01-26T00:15:28.340Z", "title": "LongCat-Flash-Thinking-2601 Technical Report", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.", "upvotes": 136, "discussionId": "6976d5405d41524304c135d9", "ai_summary": "A 560-billion-parameter Mixture-of-Experts reasoning model achieves state-of-the-art performance on agentic benchmarks through a unified training framework combining domain-parallel expert training with fusion, along with enhancements for real-world robustness and complex reasoning.", "ai_keywords": ["Mixture-of-Experts", "agentic reasoning", "domain-parallel expert training", "fusion", "asynchronous reinforcement learning", "DORA", "long-tailed generation", "multi-turn interactions", "real-world noise patterns", "test-time scaling", "reasoning depth", "reasoning width", "parallel thinking"], "organization": {"_id": "68b28d79a176a9beb30d2049", "name": "meituan-longcat", "fullname": "LongCat", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/68a2a29ab9d4c5698e02c747/CDCAx7X7rXDt7xjI-DoxG.png"}, "summary_zh": "<ul>\n    <li>LongCat-Flash-Thinking-2601 \u662f\u4e00\u4e2a\u62e5\u67095600\u4ebf\u53c2\u6570\u7684\u5f00\u6e90\u6df7\u5408\u4e13\u5bb6\u63a8\u7406\u6a21\u578b\uff0c\u5177\u5907\u5353\u8d8a\u7684\u63a8\u7406\u80fd\u529b\u3002</li>\n    <li>\u8be5\u6a21\u578b\u5728\u591a\u79cd\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5305\u62ec\u4ee3\u7406\u641c\u7d22\u3001\u5de5\u5177\u4f7f\u7528\u548c\u5de5\u5177\u96c6\u6210\u63a8\u7406\u3002</li>\n    <li>\u5b83\u80fd\u591f\u5f88\u597d\u5730\u5904\u7406\u590d\u6742\u7684\u5de5\u5177\u4ea4\u4e92\uff0c\u5e76\u5728\u5608\u6742\u7684\u771f\u5b9e\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002</li>\n    <li>\u901a\u8fc7\u7edf\u4e00\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u8be5\u6a21\u578b\u7ed3\u5408\u4e86\u9886\u57df\u5e76\u884c\u4e13\u5bb6\u8bad\u7ec3\u548c\u540e\u7eed\u878d\u5408\uff0c\u4f18\u5316\u4e86\u4ece\u9884\u8bad\u7ec3\u5230\u540e\u8bad\u7ec3\u7684\u5404\u4e2a\u73af\u8282\u3002</li>\n    <li>\u6a21\u578b\u5f15\u5165\u4e86\u91cd\u601d\u7ef4\u6a21\u5f0f\uff0c\u901a\u8fc7\u5e76\u884c\u601d\u7ef4\u589e\u5f3a\u63a8\u7406\u6df1\u5ea6\u548c\u5e7f\u5ea6\uff0c\u63d0\u9ad8\u4e86\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002</li>\n</ul>", "summary_simple": "<ul>\n    <li>LongCat-Flash-Thinking-2601 is a large open-source model with 560 billion parameters that excels in reasoning tasks.</li>\n    <li>It outperforms other open-source models in various tests involving decision-making and using tools effectively.</li>\n    <li>The model learns well in real-world situations, even when faced with noise and complex interactions.</li>\n    <li>A special training method combines different types of expert training to improve its performance across many environments.</li>\n    <li>It features a Heavy Thinking mode that enhances its reasoning capabilities by allowing more complex thought processes during tests.</li>\n</ul>"}, "publishedAt": "2026-01-23T08:20:09.000Z", "title": "LongCat-Flash-Thinking-2601 Technical Report", "summary": "We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2601.16725.png", "numComments": 4, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 216, "isUserFollowing": false}, "organization": {"_id": "68b28d79a176a9beb30d2049", "name": "meituan-longcat", "fullname": "LongCat", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/68a2a29ab9d4c5698e02c747/CDCAx7X7rXDt7xjI-DoxG.png"}, "isAuthorParticipating": true}]
};
window.papersLastUpdated = "Feb 15, 2026";