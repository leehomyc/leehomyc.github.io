window.trendingPapers = {
    "today": [{"paper": {"id": "2602.23152", "authors": [{"_id": "69a106faa13deaa449448917", "name": "Jingxuan Wei", "hidden": false}, {"_id": "69a106faa13deaa449448918", "user": {"_id": "640f7083208821a59b74c757", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678735253848-640f7083208821a59b74c757.jpeg", "isPro": false, "fullname": "Siyuan Li", "user": "Lupin1998", "type": "user"}, "name": "Siyuan Li", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:47.703Z", "hidden": false}, {"_id": "69a106faa13deaa449448919", "name": "Yuhang Xu", "hidden": false}, {"_id": "69a106faa13deaa44944891a", "name": "Zheng Sun", "hidden": false}, {"_id": "69a106faa13deaa44944891b", "name": "Junjie Jiang", "hidden": false}, {"_id": "69a106faa13deaa44944891c", "name": "Hexuan Jin", "hidden": false}, {"_id": "69a106faa13deaa44944891d", "name": "Caijun Jia", "hidden": false}, {"_id": "69a106faa13deaa44944891e", "name": "Honghao He", "hidden": false}, {"_id": "69a106faa13deaa44944891f", "name": "Xinglong Xu", "hidden": false}, {"_id": "69a106faa13deaa449448920", "name": "Xi bai", "hidden": false}, {"_id": "69a106faa13deaa449448921", "name": "Chang Yu", "hidden": false}, {"_id": "69a106faa13deaa449448922", "name": "Yumou Liu", "hidden": false}, {"_id": "69a106faa13deaa449448923", "name": "Junnan Zhu", "hidden": false}, {"_id": "69a106faa13deaa449448924", "user": {"_id": "64ef522242da8d2a897d62da", "avatarUrl": "/avatars/03611010d247da66696ac8976d4d3ed3.svg", "isPro": false, "fullname": "xuanhe zhou", "user": "zhouxh19", "type": "user"}, "name": "Xuanhe Zhou", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:45.120Z", "hidden": false}, {"_id": "69a106faa13deaa449448925", "name": "Jintao Chen", "hidden": false}, {"_id": "69a106faa13deaa449448926", "name": "Xiaobin Hu", "hidden": false}, {"_id": "69a106faa13deaa449448927", "name": "Shancheng Pang", "hidden": false}, {"_id": "69a106faa13deaa449448928", "name": "Bihui Yu", "hidden": false}, {"_id": "69a106faa13deaa449448929", "name": "Ran He", "hidden": false}, {"_id": "69a106faa13deaa44944892a", "name": "Zhen Lei", "hidden": false}, {"_id": "69a106faa13deaa44944892b", "name": "Stan Z. Li", "hidden": false}, {"_id": "69a106faa13deaa44944892c", "name": "Conghui He", "hidden": false}, {"_id": "69a106faa13deaa44944892d", "name": "Shuicheng Yan", "hidden": false}, {"_id": "69a106faa13deaa44944892e", "user": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "isPro": false, "fullname": "Cheng Tan", "user": "chengtan9907", "type": "user"}, "name": "Cheng Tan", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:37.726Z", "hidden": false}], "publishedAt": "2026-02-26T16:15:55.000Z", "submittedOnDailyAt": "2026-02-27T00:24:05.560Z", "title": "The Trinity of Consistency as a Defining Principle for General World Models", "submittedOnDailyBy": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "isPro": false, "fullname": "Cheng Tan", "user": "chengtan9907", "type": "user"}, "summary": "The construction of World Models capable of learning, simulating, and reasoning about objective physical laws constitutes a foundational challenge in the pursuit of Artificial General Intelligence. Recent advancements represented by video generation models like Sora have demonstrated the potential of data-driven scaling laws to approximate physical dynamics, while the emerging Unified Multimodal Model (UMM) offers a promising architectural paradigm for integrating perception, language, and reasoning. Despite these advances, the field still lacks a principled theoretical framework that defines the essential properties requisite for a General World Model. In this paper, we propose that a World Model must be grounded in the Trinity of Consistency: Modal Consistency as the semantic interface, Spatial Consistency as the geometric basis, and Temporal Consistency as the causal engine. Through this tripartite lens, we systematically review the evolution of multimodal learning, revealing a trajectory from loosely coupled specialized modules toward unified architectures that enable the synergistic emergence of internal world simulators. To complement this conceptual framework, we introduce CoW-Bench, a benchmark centered on multi-frame reasoning and generation scenarios. CoW-Bench evaluates both video generation models and UMMs under a unified evaluation protocol. Our work establishes a principled pathway toward general world models, clarifying both the limitations of current systems and the architectural requirements for future progress.", "upvotes": 159, "discussionId": "69a106faa13deaa44944892f", "projectPage": "https://openraiser.github.io/CoW-Bench/", "githubRepo": "https://github.com/openraiser/awesome-world-model-evolution", "githubRepoAddedBy": "user", "ai_summary": "World Models require three consistency principles\u2014modal, spatial, and temporal\u2014for general artificial intelligence, with a proposed benchmark evaluating multimodal learning systems.", "ai_keywords": ["World Models", "video generation models", "Unified Multimodal Model", "multimodal learning", "multi-frame reasoning", "CoW-Bench", "modal consistency", "spatial consistency", "temporal consistency"], "githubStars": 15, "organization": {"_id": "66ce9d1f5e180b9b9c8e6f31", "name": "opendatalab", "fullname": "OpenDataLab", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/639c3afa7432f2f5d16b7296/yqxxBknyeqkGnYsjoaR4M.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T11:15:55.000Z", "title": "The Trinity of Consistency as a Defining Principle for General World Models", "summary": "The construction of World Models capable of learning, simulating, and reasoning about objective physical laws constitutes a foundational challenge in the pursuit of Artificial General Intelligence. Recent advancements represented by video generation models like Sora have demonstrated the potential of data-driven scaling laws to approximate physical dynamics, while the emerging Unified Multimodal Model (UMM) offers a promising architectural paradigm for integrating perception, language, and reasoning. Despite these advances, the field still lacks a principled theoretical framework that defines the essential properties requisite for a General World Model. In this paper, we propose that a World Model must be grounded in the Trinity of Consistency: Modal Consistency as the semantic interface, Spatial Consistency as the geometric basis, and Temporal Consistency as the causal engine. Through this tripartite lens, we systematically review the evolution of multimodal learning, revealing a trajectory from loosely coupled specialized modules toward unified architectures that enable the synergistic emergence of internal world simulators. To complement this conceptual framework, we introduce CoW-Bench, a benchmark centered on multi-frame reasoning and generation scenarios. CoW-Bench evaluates both video generation models and UMMs under a unified evaluation protocol. Our work establishes a principled pathway toward general world models, clarifying both the limitations of current systems and the architectural requirements for future progress.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.23152.png", "numComments": 3, "submittedBy": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "fullname": "Cheng Tan", "name": "chengtan9907", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 3, "isUserFollowing": false}, "organization": {"_id": "66ce9d1f5e180b9b9c8e6f31", "name": "opendatalab", "fullname": "OpenDataLab", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/639c3afa7432f2f5d16b7296/yqxxBknyeqkGnYsjoaR4M.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.22859", "authors": [{"_id": "69a0ffd0a13deaa4494488fb", "user": {"_id": "66a4c04555677524a0c8047b", "avatarUrl": "/avatars/0913eadc4e33eab9ac705e1ad4df9fc9.svg", "isPro": false, "fullname": "Hongrui Jia", "user": "hongruijia", "type": "user"}, "name": "Hongrui Jia", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:41:05.608Z", "hidden": false}, {"_id": "69a0ffd0a13deaa4494488fc", "name": "Chaoya Jiang", "hidden": false}, {"_id": "69a0ffd0a13deaa4494488fd", "name": "Shikun Zhang", "hidden": false}, {"_id": "69a0ffd0a13deaa4494488fe", "name": "Wei Ye", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/61b9976efd429dff1ed3bd44/IMYdZMOvbDFl55vSivuiA.jpeg"], "publishedAt": "2026-02-26T10:53:57.000Z", "submittedOnDailyAt": "2026-02-27T04:28:11.559Z", "title": "From Blind Spots to Gains: Diagnostic-Driven Iterative Training for Large Multimodal Models", "submittedOnDailyBy": {"_id": "61b9976efd429dff1ed3bd44", "avatarUrl": "/avatars/5cdaa04e970e1e3dcfbb38ba89c0660a.svg", "isPro": false, "fullname": "jiangchaoya", "user": "jcy", "type": "user"}, "summary": "As Large Multimodal Models (LMMs) scale up and reinforcement learning (RL) methods mature, LMMs have made notable progress in complex reasoning and decision making. Yet training still relies on static data and fixed recipes, making it difficult to diagnose capability blind spots or provide dynamic, targeted reinforcement. Motivated by findings that test driven error exposure and feedback based correction outperform repetitive practice, we propose Diagnostic-driven Progressive Evolution (DPE), a spiral loop where diagnosis steers data generation and reinforcement, and each iteration re-diagnoses the updated model to drive the next round of targeted improvement. DPE has two key components. First, multiple agents annotate and quality control massive unlabeled multimodal data, using tools such as web search and image editing to produce diverse, realistic samples. Second, DPE attributes failures to specific weaknesses, dynamically adjusts the data mixture, and guides agents to generate weakness focused data for targeted reinforcement. Experiments on Qwen3-VL-8B-Instruct and Qwen2.5-VL-7B-Instruct show stable, continual gains across eleven benchmarks, indicating DPE as a scalable paradigm for continual LMM training under open task distributions. Our code, models, and data are publicly available at https://github.com/hongruijia/DPE.", "upvotes": 142, "discussionId": "69a0ffd0a13deaa4494488ff", "githubRepo": "https://github.com/hongruijia/DPE", "githubRepoAddedBy": "user", "ai_summary": "Diagnostic-driven Progressive Evolution enables continuous improvement of large multimodal models through iterative diagnosis and targeted data generation guided by identified weaknesses.", "ai_keywords": ["Large Multimodal Models", "reinforcement learning", "diagnostic-driven progressive evolution", "continual learning", "multimodal data", "quality control", "targeted reinforcement"], "githubStars": 27, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T05:53:57.000Z", "title": "From Blind Spots to Gains: Diagnostic-Driven Iterative Training for Large Multimodal Models", "summary": "As Large Multimodal Models (LMMs) scale up and reinforcement learning (RL) methods mature, LMMs have made notable progress in complex reasoning and decision making. Yet training still relies on static data and fixed recipes, making it difficult to diagnose capability blind spots or provide dynamic, targeted reinforcement. Motivated by findings that test driven error exposure and feedback based correction outperform repetitive practice, we propose Diagnostic-driven Progressive Evolution (DPE), a spiral loop where diagnosis steers data generation and reinforcement, and each iteration re-diagnoses the updated model to drive the next round of targeted improvement. DPE has two key components. First, multiple agents annotate and quality control massive unlabeled multimodal data, using tools such as web search and image editing to produce diverse, realistic samples. Second, DPE attributes failures to specific weaknesses, dynamically adjusts the data mixture, and guides agents to generate weakness focused data for targeted reinforcement. Experiments on Qwen3-VL-8B-Instruct and Qwen2.5-VL-7B-Instruct show stable, continual gains across eleven benchmarks, indicating DPE as a scalable paradigm for continual LMM training under open task distributions. Our code, models, and data are publicly available at https://github.com/hongruijia/DPE.", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/61b9976efd429dff1ed3bd44/IMYdZMOvbDFl55vSivuiA.jpeg"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.22859.png", "numComments": 2, "submittedBy": {"_id": "61b9976efd429dff1ed3bd44", "avatarUrl": "/avatars/5cdaa04e970e1e3dcfbb38ba89c0660a.svg", "fullname": "jiangchaoya", "name": "jcy", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 1, "isUserFollowing": false}, "isAuthorParticipating": false}, {"paper": {"id": "2602.22638", "authors": [{"_id": "69a13c51a13deaa449448a3f", "name": "Zhiheng Song", "hidden": false}, {"_id": "69a13c51a13deaa449448a40", "name": "Jingshuai Zhang", "hidden": false}, {"_id": "69a13c51a13deaa449448a41", "name": "Chuan Qin", "hidden": false}, {"_id": "69a13c51a13deaa449448a42", "name": "Chao Wang", "hidden": false}, {"_id": "69a13c51a13deaa449448a43", "name": "Chao Chen", "hidden": false}, {"_id": "69a13c51a13deaa449448a44", "name": "Longfei Xu", "hidden": false}, {"_id": "69a13c51a13deaa449448a45", "name": "Kaikui Liu", "hidden": false}, {"_id": "69a13c51a13deaa449448a46", "name": "Xiangxiang Chu", "hidden": false}, {"_id": "69a13c51a13deaa449448a47", "name": "Hengshu Zhu", "hidden": false}], "publishedAt": "2026-02-26T05:39:38.000Z", "submittedOnDailyAt": "2026-02-27T09:31:41.352Z", "title": "MobilityBench: A Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios", "submittedOnDailyBy": {"_id": "66d255e3947594430c723ff6", "avatarUrl": "/avatars/c56e4792332a01bf34085a75ee64916e.svg", "isPro": false, "fullname": "xiaochonglinghu", "user": "xiaochonglinghu", "type": "user"}, "summary": "Route-planning agents powered by large language models (LLMs) have emerged as a promising paradigm for supporting everyday human mobility through natural language interaction and tool-mediated decision making. However, systematic evaluation in real-world mobility settings is hindered by diverse routing demands, non-deterministic mapping services, and limited reproducibility. In this study, we introduce MobilityBench, a scalable benchmark for evaluating LLM-based route-planning agents in real-world mobility scenarios. MobilityBench is constructed from large-scale, anonymized real user queries collected from Amap and covers a broad spectrum of route-planning intents across multiple cities worldwide. To enable reproducible, end-to-end evaluation, we design a deterministic API-replay sandbox that eliminates environmental variance from live services. We further propose a multi-dimensional evaluation protocol centered on outcome validity, complemented by assessments of instruction understanding, planning, tool use, and efficiency. Using MobilityBench, we evaluate multiple LLM-based route-planning agents across diverse real-world mobility scenarios and provide an in-depth analysis of their behaviors and performance. Our findings reveal that current models perform competently on Basic information retrieval and Route Planning tasks, yet struggle considerably with Preference-Constrained Route Planning, underscoring significant room for improvement in personalized mobility applications. We publicly release the benchmark data, evaluation toolkit, and documentation at https://github.com/AMAP-ML/MobilityBench .", "upvotes": 86, "discussionId": "69a13c52a13deaa449448a48", "githubRepo": "https://github.com/AMAP-ML/MobilityBench", "githubRepoAddedBy": "user", "ai_summary": "MobileBench is a scalable benchmark for evaluating LLM-based route-planning agents in real-world scenarios, featuring anonymized user queries and a deterministic sandbox for reproducible testing.", "ai_keywords": ["route-planning agents", "large language models", "MobilityBench", "API-replay sandbox", "deterministic environment", "multi-dimensional evaluation", "outcome validity", "instruction understanding", "planning", "tool use", "efficiency", "real-world mobility scenarios"], "githubStars": 94, "organization": {"_id": "64488b334988ee01f2a8d856", "name": "alibaba-inc", "fullname": "alibaba-inc", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61ac8f8a00d01045fca0ad2f/MX4wxQVaFm1A1wqnrL2WU.jpeg"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T00:39:38.000Z", "title": "MobilityBench: A Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios", "summary": "Route-planning agents powered by large language models (LLMs) have emerged as a promising paradigm for supporting everyday human mobility through natural language interaction and tool-mediated decision making. However, systematic evaluation in real-world mobility settings is hindered by diverse routing demands, non-deterministic mapping services, and limited reproducibility. In this study, we introduce MobilityBench, a scalable benchmark for evaluating LLM-based route-planning agents in real-world mobility scenarios. MobilityBench is constructed from large-scale, anonymized real user queries collected from Amap and covers a broad spectrum of route-planning intents across multiple cities worldwide. To enable reproducible, end-to-end evaluation, we design a deterministic API-replay sandbox that eliminates environmental variance from live services. We further propose a multi-dimensional evaluation protocol centered on outcome validity, complemented by assessments of instruction understanding, planning, tool use, and efficiency. Using MobilityBench, we evaluate multiple LLM-based route-planning agents across diverse real-world mobility scenarios and provide an in-depth analysis of their behaviors and performance. Our findings reveal that current models perform competently on Basic information retrieval and Route Planning tasks, yet struggle considerably with Preference-Constrained Route Planning, underscoring significant room for improvement in personalized mobility applications. We publicly release the benchmark data, evaluation toolkit, and documentation at https://github.com/AMAP-ML/MobilityBench .", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.22638.png", "numComments": 2, "submittedBy": {"_id": "66d255e3947594430c723ff6", "avatarUrl": "/avatars/c56e4792332a01bf34085a75ee64916e.svg", "fullname": "xiaochonglinghu", "name": "xiaochonglinghu", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 8, "isUserFollowing": false}, "organization": {"_id": "64488b334988ee01f2a8d856", "name": "alibaba-inc", "fullname": "alibaba-inc", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61ac8f8a00d01045fca0ad2f/MX4wxQVaFm1A1wqnrL2WU.jpeg"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.22897", "authors": [{"_id": "69a0fda9a13deaa4494488e3", "name": "Xiaoxi Li", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e4", "user": {"_id": "63db16330cc3bc12bc0b6f8f", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63db16330cc3bc12bc0b6f8f/ld0JQIfX1SBlDVDOmw9VT.jpeg", "isPro": false, "fullname": "Wenxiang Jiao", "user": "wxjiao", "type": "user"}, "name": "Wenxiang Jiao", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:41:37.304Z", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e5", "name": "Jiarui Jin", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e6", "name": "Shijian Wang", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e7", "user": {"_id": "61cd4b833dd34ba1985e0753", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61cd4b833dd34ba1985e0753/BfHfrwotoMESpXZOHiIe4.png", "isPro": false, "fullname": "KABI", "user": "dongguanting", "type": "user"}, "name": "Guanting Dong", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:41:09.826Z", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e8", "name": "Jiajie Jin", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e9", "name": "Hao Wang", "hidden": false}, {"_id": "69a0fda9a13deaa4494488ea", "name": "Yinuo Wang", "hidden": false}, {"_id": "69a0fda9a13deaa4494488eb", "name": "Ji-Rong Wen", "hidden": false}, {"_id": "69a0fda9a13deaa4494488ec", "name": "Yuan Lu", "hidden": false}, {"_id": "69a0fda9a13deaa4494488ed", "name": "Zhicheng Dou", "hidden": false}], "publishedAt": "2026-02-26T11:35:04.000Z", "submittedOnDailyAt": "2026-02-27T00:29:04.184Z", "title": "OmniGAIA: Towards Native Omni-Modal AI Agents", "submittedOnDailyBy": {"_id": "66e03eace17fb5ff054b7686", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66e03eace17fb5ff054b7686/PpSV0Qo5lwTyxIZMp57xq.jpeg", "isPro": false, "fullname": "Xiaoxi Li", "user": "lixiaoxi45", "type": "user"}, "summary": "Human intelligence naturally intertwines omni-modal perception -- spanning vision, audio, and language -- with complex reasoning and tool usage to interact with the world. However, current multi-modal LLMs are primarily confined to bi-modal interactions (e.g., vision-language), lacking the unified cognitive capabilities required for general AI assistants. To bridge this gap, we introduce OmniGAIA, a comprehensive benchmark designed to evaluate omni-modal agents on tasks necessitating deep reasoning and multi-turn tool execution across video, audio, and image modalities. Constructed via a novel omni-modal event graph approach, OmniGAIA synthesizes complex, multi-hop queries derived from real-world data that require cross-modal reasoning and external tool integration. Furthermore, we propose OmniAtlas, a native omni-modal foundation agent under tool-integrated reasoning paradigm with active omni-modal perception. Trained on trajectories synthesized via a hindsight-guided tree exploration strategy and OmniDPO for fine-grained error correction, OmniAtlas effectively enhances the tool-use capabilities of existing open-source models. This work marks a step towards next-generation native omni-modal AI assistants for real-world scenarios.", "upvotes": 46, "discussionId": "69a0fda9a13deaa4494488ee", "githubRepo": "https://github.com/RUC-NLPIR/OmniGAIA", "githubRepoAddedBy": "user", "ai_summary": "OmniGAIA benchmark evaluates multi-modal agents on complex reasoning tasks across video, audio, and image modalities, while OmniAtlas agent improves tool-use capabilities through hindsight-guided tree exploration and OmniDPO fine-tuning.", "ai_keywords": ["multi-modal LLMs", "omni-modal perception", "cross-modal reasoning", "tool-integrated reasoning", "hindsight-guided tree exploration", "OmniDPO"], "githubStars": 34, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T06:35:04.000Z", "title": "OmniGAIA: Towards Native Omni-Modal AI Agents", "summary": "Human intelligence naturally intertwines omni-modal perception -- spanning vision, audio, and language -- with complex reasoning and tool usage to interact with the world. However, current multi-modal LLMs are primarily confined to bi-modal interactions (e.g., vision-language), lacking the unified cognitive capabilities required for general AI assistants. To bridge this gap, we introduce OmniGAIA, a comprehensive benchmark designed to evaluate omni-modal agents on tasks necessitating deep reasoning and multi-turn tool execution across video, audio, and image modalities. Constructed via a novel omni-modal event graph approach, OmniGAIA synthesizes complex, multi-hop queries derived from real-world data that require cross-modal reasoning and external tool integration. Furthermore, we propose OmniAtlas, a native omni-modal foundation agent under tool-integrated reasoning paradigm with active omni-modal perception. Trained on trajectories synthesized via a hindsight-guided tree exploration strategy and OmniDPO for fine-grained error correction, OmniAtlas effectively enhances the tool-use capabilities of existing open-source models. This work marks a step towards next-generation native omni-modal AI assistants for real-world scenarios.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.22897.png", "numComments": 2, "submittedBy": {"_id": "66e03eace17fb5ff054b7686", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66e03eace17fb5ff054b7686/PpSV0Qo5lwTyxIZMp57xq.jpeg", "fullname": "Xiaoxi Li", "name": "lixiaoxi45", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 21, "isUserFollowing": false}, "isAuthorParticipating": false}, {"paper": {"id": "2602.22766", "authors": [{"_id": "69a112ffa13deaa44944896f", "name": "You Li", "hidden": false}, {"_id": "69a112ffa13deaa449448970", "name": "Chi Chen", "hidden": false}, {"_id": "69a112ffa13deaa449448971", "name": "Yanghao Li", "hidden": false}, {"_id": "69a112ffa13deaa449448972", "name": "Fanhu Zeng", "hidden": false}, {"_id": "69a112ffa13deaa449448973", "name": "Kaiyu Huang", "hidden": false}, {"_id": "69a112ffa13deaa449448974", "name": "Jinan Xu", "hidden": false}, {"_id": "69a112ffa13deaa449448975", "name": "Maosong Sun", "hidden": false}], "publishedAt": "2026-02-26T08:56:23.000Z", "submittedOnDailyAt": "2026-02-27T01:16:22.929Z", "title": "Imagination Helps Visual Reasoning, But Not Yet in Latent Space", "submittedOnDailyBy": {"_id": "654f3e104c8874c64d43aafa", "avatarUrl": "/avatars/00de263f98a81c52cdb321fb11b16c06.svg", "isPro": false, "fullname": "You Li", "user": "Michael4933", "type": "user"}, "summary": "Latent visual reasoning aims to mimic human's imagination process by meditating through hidden states of Multimodal Large Language Models. While recognized as a promising paradigm for visual reasoning, the underlying mechanisms driving its effectiveness remain unclear. Motivated to demystify the true source of its efficacy, we investigate the validity of latent reasoning using Causal Mediation Analysis. We model the process as a causal chain: the input as the treatment, the latent tokens as the mediator, and the final answer as the outcome. Our findings uncover two critical disconnections: (a) Input-Latent Disconnect: dramatic perturbations on the input result in negligible changes to the latent tokens, suggesting that latent tokens do not effectively attend to the input sequence. (b) Latent-Answer Disconnect: perturbations on the latent tokens yield minimal impact on the final answer, indicating the limited causal effect latent tokens imposing on the outcome. Furthermore, extensive probing analysis reveals that latent tokens encode limited visual information and exhibit high similarity. Consequently, we challenge the necessity of latent reasoning and propose a straightforward alternative named CapImagine, which teaches the model to explicitly imagine using text. Experiments on vision-centric benchmarks show that CapImagine significantly outperforms complex latent-space baselines, highlighting the superior potential of visual reasoning through explicit imagination.", "upvotes": 31, "discussionId": "69a112ffa13deaa449448976", "githubRepo": "https://github.com/AI9Stars/CapImagine", "githubRepoAddedBy": "user", "ai_summary": "Research reveals that latent visual reasoning in multimodal models suffers from input-latent and latent-answer disconnects, leading to the proposal of CapImagine, a text-based approach that outperforms complex latent-space methods.", "ai_keywords": ["Multimodal Large Language Models", "causal mediation analysis", "latent tokens", "visual reasoning", "input-latent disconnect", "latent-answer disconnect", "CapImagine"], "githubStars": 10, "organization": {"_id": "628735cbc83a2d6ab8d14a66", "name": "Tsinghua", "fullname": "Tsinghua University"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T03:56:23.000Z", "title": "Imagination Helps Visual Reasoning, But Not Yet in Latent Space", "summary": "Latent visual reasoning aims to mimic human's imagination process by meditating through hidden states of Multimodal Large Language Models. While recognized as a promising paradigm for visual reasoning, the underlying mechanisms driving its effectiveness remain unclear. Motivated to demystify the true source of its efficacy, we investigate the validity of latent reasoning using Causal Mediation Analysis. We model the process as a causal chain: the input as the treatment, the latent tokens as the mediator, and the final answer as the outcome. Our findings uncover two critical disconnections: (a) Input-Latent Disconnect: dramatic perturbations on the input result in negligible changes to the latent tokens, suggesting that latent tokens do not effectively attend to the input sequence. (b) Latent-Answer Disconnect: perturbations on the latent tokens yield minimal impact on the final answer, indicating the limited causal effect latent tokens imposing on the outcome. Furthermore, extensive probing analysis reveals that latent tokens encode limited visual information and exhibit high similarity. Consequently, we challenge the necessity of latent reasoning and propose a straightforward alternative named CapImagine, which teaches the model to explicitly imagine using text. Experiments on vision-centric benchmarks show that CapImagine significantly outperforms complex latent-space baselines, highlighting the superior potential of visual reasoning through explicit imagination.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.22766.png", "numComments": 2, "submittedBy": {"_id": "654f3e104c8874c64d43aafa", "avatarUrl": "/avatars/00de263f98a81c52cdb321fb11b16c06.svg", "fullname": "You Li", "name": "Michael4933", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 2, "isUserFollowing": false}, "organization": {"_id": "628735cbc83a2d6ab8d14a66", "name": "Tsinghua", "fullname": "Tsinghua University"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.23008", "authors": [{"_id": "69a11540a13deaa449448995", "user": {"_id": "66228a37f5c285535cc9cc83", "avatarUrl": "/avatars/0982d6553a9c9001ebdca2878bcfff34.svg", "isPro": false, "fullname": "Zeyuan Liu", "user": "ZeyuanLiu", "type": "user"}, "name": "Zeyuan Liu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:23.614Z", "hidden": false}, {"_id": "69a11540a13deaa449448996", "user": {"_id": "63e48f6d9db5da2dc1f6288e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676046878664-63e48f6d9db5da2dc1f6288e.png", "isPro": false, "fullname": "JeonghyeKim", "user": "beanie00", "type": "user"}, "name": "Jeonghye Kim", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:18.705Z", "hidden": false}, {"_id": "69a11540a13deaa449448997", "user": {"_id": "66a1f912345b3106f47ce860", "avatarUrl": "/avatars/40177299c64e16703e7bfe83de0810be.svg", "isPro": false, "fullname": "Xufang Luo", "user": "daixufang", "type": "user"}, "name": "Xufang Luo", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:15.195Z", "hidden": false}, {"_id": "69a11540a13deaa449448998", "name": "Dongsheng Li", "hidden": false}, {"_id": "69a11540a13deaa449448999", "name": "Yuqing Yang", "hidden": false}], "publishedAt": "2026-02-26T13:50:57.000Z", "submittedOnDailyAt": "2026-02-27T01:31:44.571Z", "title": "Exploratory Memory-Augmented LLM Agent via Hybrid On- and Off-Policy Optimization", "submittedOnDailyBy": {"_id": "63e48f6d9db5da2dc1f6288e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676046878664-63e48f6d9db5da2dc1f6288e.png", "isPro": false, "fullname": "JeonghyeKim", "user": "beanie00", "type": "user"}, "summary": "Exploration remains the key bottleneck for large language model agents trained with reinforcement learning. While prior methods exploit pretrained knowledge, they fail in environments requiring the discovery of novel states. We propose Exploratory Memory-Augmented On- and Off-Policy Optimization (EMPO^2), a hybrid RL framework that leverages memory for exploration and combines on- and off-policy updates to make LLMs perform well with memory while also ensuring robustness without it. On ScienceWorld and WebShop, EMPO^2 achieves 128.6% and 11.3% improvements over GRPO, respectively. Moreover, in out-of-distribution tests, EMPO^2 demonstrates superior adaptability to new tasks, requiring only a few trials with memory and no parameter updates. These results highlight EMPO^2 as a promising framework for building more exploratory and generalizable LLM-based agents.", "upvotes": 26, "discussionId": "69a11540a13deaa44944899a", "ai_summary": "EMPO\u00b2 is a hybrid reinforcement learning framework that enhances exploration for large language model agents by integrating memory mechanisms with on- and off-policy updates, demonstrating improved performance and adaptability in complex environments.", "ai_keywords": ["reinforcement learning", "large language model agents", "exploration", "memory augmentation", "on-policy updates", "off-policy updates", "ScienceWorld", "WebShop"], "organization": {"_id": "5e6485f787403103f9f1055e", "name": "microsoft", "fullname": "Microsoft", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1583646260758-5e64858c87403103f9f1055d.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T08:50:57.000Z", "title": "Exploratory Memory-Augmented LLM Agent via Hybrid On- and Off-Policy Optimization", "summary": "Exploration remains the key bottleneck for large language model agents trained with reinforcement learning. While prior methods exploit pretrained knowledge, they fail in environments requiring the discovery of novel states. We propose Exploratory Memory-Augmented On- and Off-Policy Optimization (EMPO^2), a hybrid RL framework that leverages memory for exploration and combines on- and off-policy updates to make LLMs perform well with memory while also ensuring robustness without it. On ScienceWorld and WebShop, EMPO^2 achieves 128.6% and 11.3% improvements over GRPO, respectively. Moreover, in out-of-distribution tests, EMPO^2 demonstrates superior adaptability to new tasks, requiring only a few trials with memory and no parameter updates. These results highlight EMPO^2 as a promising framework for building more exploratory and generalizable LLM-based agents.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.23008.png", "numComments": 2, "submittedBy": {"_id": "63e48f6d9db5da2dc1f6288e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676046878664-63e48f6d9db5da2dc1f6288e.png", "fullname": "JeonghyeKim", "name": "beanie00", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 1, "isUserFollowing": false}, "organization": {"_id": "5e6485f787403103f9f1055e", "name": "microsoft", "fullname": "Microsoft", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1583646260758-5e64858c87403103f9f1055d.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.23258", "authors": [{"_id": "69a14dd7a13deaa449448a7e", "name": "Yutong Wang", "hidden": false}, {"_id": "69a14dd7a13deaa449448a7f", "name": "Siyuan Xiong", "hidden": false}, {"_id": "69a14dd7a13deaa449448a80", "name": "Xuebo Liu", "hidden": false}, {"_id": "69a14dd7a13deaa449448a81", "name": "Wenkang Zhou", "hidden": false}, {"_id": "69a14dd7a13deaa449448a82", "name": "Liang Ding", "hidden": false}, {"_id": "69a14dd7a13deaa449448a83", "name": "Miao Zhang", "hidden": false}, {"_id": "69a14dd7a13deaa449448a84", "name": "Min Zhang", "hidden": false}], "publishedAt": "2026-02-26T17:31:43.000Z", "submittedOnDailyAt": "2026-02-27T05:27:41.765Z", "title": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning", "submittedOnDailyBy": {"_id": "652fbf9e75f5f7a84e10cb2e", "avatarUrl": "/avatars/73e7af465dbb57826a52e49c3e72f55f.svg", "isPro": false, "fullname": "Xuebo Liu", "user": "SunbowLiu", "type": "user"}, "summary": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/AgentDropoutV2.", "upvotes": 23, "discussionId": "69a14dd7a13deaa449448a85", "githubRepo": "https://github.com/TonySY2/AgentDropoutV2", "githubRepoAddedBy": "user", "ai_summary": "AgentDropoutV2 is a test-time framework that dynamically optimizes multi-agent system information flow through error correction and pruning mechanisms without requiring retraining.", "ai_keywords": ["multi-agent systems", "test-time rectify-or-reject pruning", "retrieval-augmented rectifier", "failure-driven indicator pool", "distilled failure patterns", "error propagation", "fallback strategy", "context-aware indicators"], "githubStars": 14, "organization": {"_id": "670819b38c9c6f598f37d86f", "name": "HarbinInstituteofTechnologyHIT", "fullname": "Harbin Institute of Technology"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T12:31:43.000Z", "title": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning", "summary": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/AgentDropoutV2.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.23258.png", "numComments": 2, "submittedBy": {"_id": "652fbf9e75f5f7a84e10cb2e", "avatarUrl": "/avatars/73e7af465dbb57826a52e49c3e72f55f.svg", "fullname": "Xuebo Liu", "name": "SunbowLiu", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 1, "isUserFollowing": false}, "organization": {"_id": "670819b38c9c6f598f37d86f", "name": "HarbinInstituteofTechnologyHIT", "fullname": "Harbin Institute of Technology"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.23363", "authors": [{"_id": "69a12e58a13deaa4494489fc", "user": {"_id": "62e23c7f555a866437a53cd0", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e23c7f555a866437a53cd0/UaAsYZQXuwb4NSG5WnvdG.jpeg", "isPro": false, "fullname": "Sahal Shaji", "user": "sahalshajim", "type": "user"}, "name": "Sahal Shaji Mullappilly", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:39:40.482Z", "hidden": false}, {"_id": "69a12e58a13deaa4494489fd", "user": {"_id": "650289dbc130d99814b34dc5", "avatarUrl": "/avatars/ff0cf5add144cd79c41a255f41f34efb.svg", "isPro": false, "fullname": "K Mohammed Irfan", "user": "k-m-irfan", "type": "user"}, "name": "Mohammed Irfan Kurpath", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:39:38.185Z", "hidden": false}, {"_id": "69a12e58a13deaa4494489fe", "name": "Omair Mohamed", "hidden": false}, {"_id": "69a12e58a13deaa4494489ff", "name": "Mohamed Zidan", "hidden": false}, {"_id": "69a12e58a13deaa449448a00", "name": "Fahad Khan", "hidden": false}, {"_id": "69a12e58a13deaa449448a01", "name": "Salman Khan", "hidden": false}, {"_id": "69a12e58a13deaa449448a02", "name": "Rao Anwer", "hidden": false}, {"_id": "69a12e58a13deaa449448a03", "name": "Hisham Cholakkal", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/62e23c7f555a866437a53cd0/WddQgtwWa0OeMcmCOnun1.qt"], "publishedAt": "2026-02-26T18:59:46.000Z", "submittedOnDailyAt": "2026-02-27T05:40:54.483Z", "title": "MediX-R1: Open Ended Medical Reinforcement Learning", "submittedOnDailyBy": {"_id": "62e23c7f555a866437a53cd0", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e23c7f555a866437a53cd0/UaAsYZQXuwb4NSG5WnvdG.jpeg", "isPro": false, "fullname": "Sahal Shaji", "user": "sahalshajim", "type": "user"}, "summary": "We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group Based RL and a composite reward tailored for medical reasoning: an LLM-based accuracy reward that judges semantic correctness with a strict YES/NO decision, a medical embedding-based semantic reward to capture paraphrases and terminology variants, and lightweight format and modality rewards that enforce interpretable reasoning and modality recognition. This multi-signal design provides stable, informative feedback for open-ended outputs where traditional verifiable or MCQ-only rewards fall short. To measure progress, we propose a unified evaluation framework for both text-only and image+text tasks that uses a Reference-based LLM-as-judge in place of brittle string-overlap metrics, capturing semantic correctness, reasoning, and contextual alignment. Despite using only sim51K instruction examples, MediX-R1 achieves excellent results across standard medical LLM (text-only) and VLM (image + text) benchmarks, outperforming strong open-source baselines and delivering particularly large gains on open-ended clinical tasks. Our results demonstrate that open-ended RL with comprehensive reward signals and LLM-based evaluation is a practical path toward reliable medical reasoning in multimodal models. Our trained models, curated datasets and source code are available at https://medix.cvmbzuai.com", "upvotes": 14, "discussionId": "69a12e58a13deaa449448a04", "projectPage": "https://medix.cvmbzuai.com/", "githubRepo": "https://github.com/mbzuai-oryx/MediX-R1", "githubRepoAddedBy": "user", "ai_summary": "MediX-R1 presents an open-ended reinforcement learning framework for medical multimodal large language models that uses diverse reward signals and LLM-based evaluation to improve clinical reasoning beyond multiple-choice formats.", "ai_keywords": ["Reinforcement Learning", "vision-language backbone", "Group Based RL", "LLM-based accuracy reward", "medical embedding-based semantic reward", "lightweight format reward", "lightweight modality reward", "Reference-based LLM-as-judge", "medical reasoning", "multimodal large language models"], "githubStars": 13, "organization": {"_id": "61fb9e24dc607a42af5f193f", "name": "MBZUAI", "fullname": "Mohamed Bin Zayed University of Artificial Intelligence", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1643879908583-603ab5664a944b99e81476e8.jpeg"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T13:59:46.000Z", "title": "MediX-R1: Open Ended Medical Reinforcement Learning", "summary": "We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group Based RL and a composite reward tailored for medical reasoning: an LLM-based accuracy reward that judges semantic correctness with a strict YES/NO decision, a medical embedding-based semantic reward to capture paraphrases and terminology variants, and lightweight format and modality rewards that enforce interpretable reasoning and modality recognition. This multi-signal design provides stable, informative feedback for open-ended outputs where traditional verifiable or MCQ-only rewards fall short. To measure progress, we propose a unified evaluation framework for both text-only and image+text tasks that uses a Reference-based LLM-as-judge in place of brittle string-overlap metrics, capturing semantic correctness, reasoning, and contextual alignment. Despite using only sim51K instruction examples, MediX-R1 achieves excellent results across standard medical LLM (text-only) and VLM (image + text) benchmarks, outperforming strong open-source baselines and delivering particularly large gains on open-ended clinical tasks. Our results demonstrate that open-ended RL with comprehensive reward signals and LLM-based evaluation is a practical path toward reliable medical reasoning in multimodal models. Our trained models, curated datasets and source code are available at https://medix.cvmbzuai.com", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/62e23c7f555a866437a53cd0/WddQgtwWa0OeMcmCOnun1.qt"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.23363.png", "numComments": 1, "submittedBy": {"_id": "62e23c7f555a866437a53cd0", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e23c7f555a866437a53cd0/UaAsYZQXuwb4NSG5WnvdG.jpeg", "fullname": "Sahal Shaji", "name": "sahalshajim", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 3, "isUserFollowing": false}, "organization": {"_id": "61fb9e24dc607a42af5f193f", "name": "MBZUAI", "fullname": "Mohamed Bin Zayed University of Artificial Intelligence", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1643879908583-603ab5664a944b99e81476e8.jpeg"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.22675", "authors": [{"_id": "69a14feba13deaa449448a87", "name": "Qianben Chen", "hidden": false}, {"_id": "69a14feba13deaa449448a88", "name": "Tianrui Qin", "hidden": false}, {"_id": "69a14feba13deaa449448a89", "name": "King Zhu", "hidden": false}, {"_id": "69a14feba13deaa449448a8a", "name": "Qiexiang Wang", "hidden": false}, {"_id": "69a14feba13deaa449448a8b", "name": "Chengjun Yu", "hidden": false}, {"_id": "69a14feba13deaa449448a8c", "name": "Shu Xu", "hidden": false}, {"_id": "69a14feba13deaa449448a8d", "name": "Jiaqi Wu", "hidden": false}, {"_id": "69a14feba13deaa449448a8e", "name": "Jiayu Zhang", "hidden": false}, {"_id": "69a14feba13deaa449448a8f", "name": "Xinpeng Liu", "hidden": false}, {"_id": "69a14feba13deaa449448a90", "name": "Xin Gui", "hidden": false}, {"_id": "69a14feba13deaa449448a91", "name": "Jingyi Cao", "hidden": false}, {"_id": "69a14feba13deaa449448a92", "name": "Piaohong Wang", "hidden": false}, {"_id": "69a14feba13deaa449448a93", "user": {"_id": "657c1f7e688f1a0f7ecfe264", "avatarUrl": "/avatars/265afcb7b0eeddbcf66ec4cdd4920dd3.svg", "isPro": false, "fullname": "Dingfeng Shi", "user": "hugteste", "type": "user"}, "name": "Dingfeng Shi", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:39:18.806Z", "hidden": false}, {"_id": "69a14feba13deaa449448a94", "name": "He Zhu", "hidden": false}, {"_id": "69a14feba13deaa449448a95", "name": "Tiannan Wang", "hidden": false}, {"_id": "69a14feba13deaa449448a96", "name": "Yuqing Wang", "hidden": false}, {"_id": "69a14feba13deaa449448a97", "name": "Maojia Song", "hidden": false}, {"_id": "69a14feba13deaa449448a98", "name": "Tianyu Zheng", "hidden": false}, {"_id": "69a14feba13deaa449448a99", "name": "Ge Zhang", "hidden": false}, {"_id": "69a14feba13deaa449448a9a", "name": "Jian Yang", "hidden": false}, {"_id": "69a14feba13deaa449448a9b", "name": "Jiaheng Liu", "hidden": false}, {"_id": "69a14feba13deaa449448a9c", "user": {"_id": "6417d9ea8f689506e7148417", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6417d9ea8f689506e7148417/bAYcruWNw4WvmuQcGgcwC.jpeg", "isPro": false, "fullname": "minghao", "user": "Liam-Liu", "type": "user"}, "name": "Minghao Liu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:39:21.379Z", "hidden": false}, {"_id": "69a14feba13deaa449448a9d", "name": "Yuchen Eleanor Jiang", "hidden": false}, {"_id": "69a14feba13deaa449448a9e", "name": "Wangchunshu Zhou", "hidden": false}], "publishedAt": "2026-02-26T06:46:41.000Z", "submittedOnDailyAt": "2026-02-27T05:37:12.477Z", "title": "Search More, Think Less: Rethinking Long-Horizon Agentic Search for Efficiency and Generalization", "submittedOnDailyBy": {"_id": "64be3a8b86e7fb5b8a7ec8a9", "avatarUrl": "/avatars/58280c82f643a5a8073623eff33fefb2.svg", "isPro": false, "fullname": "Chen", "user": "Qianben", "type": "user"}, "summary": "Recent deep research agents primarily improve performance by scaling reasoning depth, but this leads to high inference cost and latency in search-intensive scenarios. Moreover, generalization across heterogeneous research settings remains challenging. In this work, we propose Search More, Think Less (SMTL), a framework for long-horizon agentic search that targets both efficiency and generalization. SMTL replaces sequential reasoning with parallel evidence acquisition, enabling efficient context management under constrained context budgets. To support generalization across task types, we further introduce a unified data synthesis pipeline that constructs search tasks spanning both deterministic question answering and open-ended research scenarios with task appropriate evaluation metrics. We train an end-to-end agent using supervised fine-tuning and reinforcement learning, achieving strong and often state of the art performance across benchmarks including BrowseComp (48.6\\%), GAIA (75.7\\%), Xbench (82.0\\%), and DeepResearch Bench (45.9\\%). Compared to Mirothinker-v1.0, SMTL with maximum 100 interaction steps reduces the average number of reasoning steps on BrowseComp by 70.7\\%, while improving accuracy.", "upvotes": 14, "discussionId": "69a14feba13deaa449448a9f", "githubRepo": "https://github.com/OPPO-PersonalAI/SMTL", "githubRepoAddedBy": "user", "ai_summary": "A deep learning framework called SMTL improves efficient long-horizon agentic search by replacing sequential reasoning with parallel evidence acquisition, achieving state-of-the-art performance across multiple research benchmarks while reducing reasoning steps by 70.7%.", "ai_keywords": ["deep research agents", "reasoning depth", "inference cost", "search-intensive scenarios", "generalization", "agentic search", "parallel evidence acquisition", "context management", "supervised fine-tuning", "reinforcement learning", "BrowseComp", "GAIA", "Xbench", "DeepResearch Bench"], "githubStars": 0, "organization": {"_id": "67177eecd0fad5b4ccc09461", "name": "OPPOer", "fullname": "OPPO", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66e24afddce93c7249b418c0/gQ-XFJehEyAH12zhbeR8Z.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T01:46:41.000Z", "title": "Search More, Think Less: Rethinking Long-Horizon Agentic Search for Efficiency and Generalization", "summary": "Recent deep research agents primarily improve performance by scaling reasoning depth, but this leads to high inference cost and latency in search-intensive scenarios. Moreover, generalization across heterogeneous research settings remains challenging. In this work, we propose Search More, Think Less (SMTL), a framework for long-horizon agentic search that targets both efficiency and generalization. SMTL replaces sequential reasoning with parallel evidence acquisition, enabling efficient context management under constrained context budgets. To support generalization across task types, we further introduce a unified data synthesis pipeline that constructs search tasks spanning both deterministic question answering and open-ended research scenarios with task appropriate evaluation metrics. We train an end-to-end agent using supervised fine-tuning and reinforcement learning, achieving strong and often state of the art performance across benchmarks including BrowseComp (48.6\\%), GAIA (75.7\\%), Xbench (82.0\\%), and DeepResearch Bench (45.9\\%). Compared to Mirothinker-v1.0, SMTL with maximum 100 interaction steps reduces the average number of reasoning steps on BrowseComp by 70.7\\%, while improving accuracy.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.22675.png", "numComments": 2, "submittedBy": {"_id": "64be3a8b86e7fb5b8a7ec8a9", "avatarUrl": "/avatars/58280c82f643a5a8073623eff33fefb2.svg", "fullname": "Chen", "name": "Qianben", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 5, "isUserFollowing": false}, "organization": {"_id": "67177eecd0fad5b4ccc09461", "name": "OPPOer", "fullname": "OPPO", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66e24afddce93c7249b418c0/gQ-XFJehEyAH12zhbeR8Z.png"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.23361", "authors": [{"_id": "69a11a51a13deaa4494489bb", "user": {"_id": "692da82ab884a1ba56270557", "avatarUrl": "/avatars/e98409da85032ad2092b77f9fceee784.svg", "isPro": false, "fullname": "Sven Elflein", "user": "sven-el", "type": "user"}, "name": "Sven Elflein", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:00.776Z", "hidden": false}, {"_id": "69a11a51a13deaa4494489bc", "name": "Ruilong Li", "hidden": false}, {"_id": "69a11a51a13deaa4494489bd", "name": "S\u00e9rgio Agostinho", "hidden": false}, {"_id": "69a11a51a13deaa4494489be", "name": "Zan Gojcic", "hidden": false}, {"_id": "69a11a51a13deaa4494489bf", "name": "Laura Leal-Taix\u00e9", "hidden": false}, {"_id": "69a11a51a13deaa4494489c0", "name": "Qunjie Zhou", "hidden": false}, {"_id": "69a11a51a13deaa4494489c1", "name": "Aljosa Osep", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/692da82ab884a1ba56270557/MfAsycfptzzlmO0_Y7TYp.gif"], "publishedAt": "2026-02-26T18:59:33.000Z", "submittedOnDailyAt": "2026-02-27T16:09:16.796Z", "title": "VGG-T^3: Offline Feed-Forward 3D Reconstruction at Scale", "submittedOnDailyBy": {"_id": "692da82ab884a1ba56270557", "avatarUrl": "/avatars/e98409da85032ad2092b77f9fceee784.svg", "isPro": false, "fullname": "Sven Elflein", "user": "sven-el", "type": "user"}, "summary": "We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t. the number of input images. Our approach is built on the key insight that this bottleneck stems from the varying-length Key-Value (KV) space representation of scene geometry, which we distill into a fixed-size Multi-Layer Perceptron (MLP) via test-time training. VGG-T^3 (Visual Geometry Grounded Test Time Training) scales linearly w.r.t. the number of input views, similar to online models, and reconstructs a 1k image collection in just 54 seconds, achieving a 11.6times speed-up over baselines that rely on softmax attention. Since our method retains global scene aggregation capability, our point map reconstruction error outperforming other linear-time methods by large margins. Finally, we demonstrate visual localization capabilities of our model by querying the scene representation with unseen images.", "upvotes": 11, "discussionId": "69a11a51a13deaa4494489c2", "projectPage": "https://research.nvidia.com/labs/dvl/projects/vgg-ttt/", "ai_summary": "VGG-T\u00b3 addresses scalability issues in 3D reconstruction by transforming variable-length key-value representations into fixed-size MLPs through test-time training, enabling linear scaling with input views and achieving significant speedup over traditional softmax attention methods.", "ai_keywords": ["3D reconstruction", "feed-forward methods", "computational requirements", "memory requirements", "Key-Value space representation", "scene geometry", "Multi-Layer Perceptron", "test-time training", "Visual Geometry Grounded Test Time Training", "softmax attention", "point map reconstruction", "visual localization"], "organization": {"_id": "60262b67268c201cdc8b7d43", "name": "nvidia", "fullname": "NVIDIA", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T13:59:33.000Z", "title": "VGG-T^3: Offline Feed-Forward 3D Reconstruction at Scale", "summary": "We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t. the number of input images. Our approach is built on the key insight that this bottleneck stems from the varying-length Key-Value (KV) space representation of scene geometry, which we distill into a fixed-size Multi-Layer Perceptron (MLP) via test-time training. VGG-T^3 (Visual Geometry Grounded Test Time Training) scales linearly w.r.t. the number of input views, similar to online models, and reconstructs a 1k image collection in just 54 seconds, achieving a 11.6times speed-up over baselines that rely on softmax attention. Since our method retains global scene aggregation capability, our point map reconstruction error outperforming other linear-time methods by large margins. Finally, we demonstrate visual localization capabilities of our model by querying the scene representation with unseen images.", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/692da82ab884a1ba56270557/MfAsycfptzzlmO0_Y7TYp.gif"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.23361.png", "numComments": 1, "submittedBy": {"_id": "692da82ab884a1ba56270557", "avatarUrl": "/avatars/e98409da85032ad2092b77f9fceee784.svg", "fullname": "Sven Elflein", "name": "sven-el", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "isUserFollowing": false}, "organization": {"_id": "60262b67268c201cdc8b7d43", "name": "nvidia", "fullname": "NVIDIA", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"}, "isAuthorParticipating": true}],
    "week": [{"paper": {"id": "2602.20159", "authors": [{"_id": "699d1e7a4e37ec6dfa1bc5b7", "user": {"_id": "67f87529318a17cc80365190", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/p1YkznAT-op1Cg-vBoFw7.png", "isPro": false, "fullname": "Maijunxian Wang", "user": "Mark7121983123", "type": "user"}, "name": "Maijunxian Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:19.409Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5b8", "user": {"_id": "65b74305e602b6c2c9125480", "avatarUrl": "/avatars/d36909e0f245bfeb632a4afc9d3fceca.svg", "isPro": false, "fullname": "wang ruisi", "user": "wruisi", "type": "user"}, "name": "Ruisi Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:01.779Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5b9", "name": "Juyi Lin", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ba", "name": "Ran Ji", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5bb", "name": "Thadd\u00e4us Wiedemer", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5bc", "name": "Qingying Gao", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5bd", "name": "Dezhi Luo", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5be", "name": "Yaoyao Qian", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5bf", "name": "Lianyu Huang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c0", "name": "Zelong Hong", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c1", "name": "Jiahui Ge", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c2", "name": "Qianli Ma", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c3", "name": "Hang He", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c4", "user": {"_id": "659d2dff20cf0b934bbee513", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/659d2dff20cf0b934bbee513/9e9R852Zr2R82h64eUUQl.jpeg", "isPro": false, "fullname": "Yifan Zhou", "user": "yingmanji", "type": "user"}, "name": "Yifan Zhou", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:04.030Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c5", "name": "Lingzi Guo", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c6", "name": "Lantao Mei", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c7", "name": "Jiachen Li", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c8", "user": {"_id": "6532c3018bde2fae19578587", "avatarUrl": "/avatars/7231538f3d682a1e7b80e15ea91b2a97.svg", "isPro": false, "fullname": "Hanwen Xing", "user": "Hudx111", "type": "user"}, "name": "Hanwen Xing", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:09.132Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c9", "name": "Tianqi Zhao", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ca", "name": "Fengyuan Yu", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5cb", "name": "Weihang Xiao", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5cc", "name": "Yizheng Jiao", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5cd", "name": "Jianheng Hou", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ce", "name": "Danyang Zhang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5cf", "user": {"_id": "65d854e5d8134b93774b4080", "avatarUrl": "/avatars/0ff1db8c13095f420a856212d64f88ca.svg", "isPro": false, "fullname": "Pengcheng Xu", "user": "explcre", "type": "user"}, "name": "Pengcheng Xu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:21.447Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d0", "name": "Boyang Zhong", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d1", "name": "Zehong Zhao", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d2", "name": "Gaoyun Fang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d3", "name": "John Kitaoka", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d4", "name": "Yile Xu", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d5", "name": "Hua Xu", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d6", "name": "Kenton Blacutt", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d7", "name": "Tin Nguyen", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d8", "name": "Siyuan Song", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d9", "name": "Haoran Sun", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5da", "name": "Shaoyue Wen", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5db", "name": "Linyang He", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5dc", "name": "Runming Wang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5dd", "name": "Yanzhi Wang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5de", "name": "Mengyue Yang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5df", "name": "Ziqiao Ma", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e0", "name": "Rapha\u00ebl Milli\u00e8re", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e1", "name": "Freda Shi", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e2", "name": "Nuno Vasconcelos", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e3", "name": "Daniel Khashabi", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e4", "name": "Alan Yuille", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e5", "name": "Yilun Du", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e6", "name": "Ziming Liu", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e7", "name": "Bo Li", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e8", "name": "Dahua Lin", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e9", "name": "Ziwei Liu", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ea", "name": "Vikash Kumar", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5eb", "name": "Yijiang Li", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ec", "user": {"_id": "6626a471430a124253f197c8", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6626a471430a124253f197c8/uVEk5nnW-bS6-no0rQ7Wh.png", "isPro": false, "fullname": "yl-1993", "user": "yl-1993", "type": "user"}, "name": "Lei Yang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:17.400Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ed", "user": {"_id": "652d06833b5997ed71ce5c46", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/xZTXEcnEogEmBm_ledJQr.jpeg", "isPro": false, "fullname": "Zhongang Cai", "user": "caizhongang", "type": "user"}, "name": "Zhongang Cai", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:06.679Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ee", "user": {"_id": "6793f65033629a5fa8ae47b5", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/h11aIy3Yuw0kLCil5yeOt.png", "isPro": false, "fullname": "Hokin Deng", "user": "Hokin", "type": "user"}, "name": "Hokin Deng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:49:58.948Z", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/6039478ab3ecf716b1a5fd4d/IjK1EcVGF8x-SG3ymPI6T.mp4"], "publishedAt": "2026-02-23T18:59:41.000Z", "submittedOnDailyAt": "2026-02-24T01:14:31.428Z", "title": "A Very Big Video Reasoning Suite", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored. Video reasoning grounds intelligence in spatiotemporally consistent visual environments that go beyond what text can naturally capture, enabling intuitive reasoning over spatiotemporal structure such as continuity, interaction, and causality. However, systematically studying video reasoning and its scaling behavior is hindered by the lack of large-scale training data. To address this gap, we introduce the Very Big Video Reasoning (VBVR) Dataset, an unprecedentedly large-scale resource spanning 200 curated reasoning tasks following a principled taxonomy and over one million video clips, approximately three orders of magnitude larger than existing datasets. We further present VBVR-Bench, a verifiable evaluation framework that moves beyond model-based judging by incorporating rule-based, human-aligned scorers, enabling reproducible and interpretable diagnosis of video reasoning capabilities. Leveraging the VBVR suite, we conduct one of the first large-scale scaling studies of video reasoning and observe early signs of emergent generalization to unseen reasoning tasks. Together, VBVR lays a foundation for the next stage of research in generalizable video reasoning. The data, benchmark toolkit, and models are publicly available at https://video-reason.com/ .", "upvotes": 302, "discussionId": "699d1e7b4e37ec6dfa1bc5ef", "projectPage": "https://video-reason.com/", "ai_summary": "A large-scale video reasoning dataset and benchmark are introduced to study video intelligence capabilities beyond visual quality, enabling systematic analysis of spatiotemporal reasoning and generalization across diverse tasks.", "ai_keywords": ["video reasoning", "spatiotemporal consistency", "emergent generalization", "video reasoning benchmark", "video reasoning dataset"], "organization": {"_id": "6986a6f58d72821326efbfbb", "name": "Video-Reason", "fullname": "Video-Reason", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6793f65033629a5fa8ae47b5/7JFt2ReogqVi_udM_OHWG.jpeg"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-23T13:59:41.000Z", "title": "A Very Big Video Reasoning Suite", "summary": "Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored. Video reasoning grounds intelligence in spatiotemporally consistent visual environments that go beyond what text can naturally capture, enabling intuitive reasoning over spatiotemporal structure such as continuity, interaction, and causality. However, systematically studying video reasoning and its scaling behavior is hindered by the lack of large-scale training data. To address this gap, we introduce the Very Big Video Reasoning (VBVR) Dataset, an unprecedentedly large-scale resource spanning 200 curated reasoning tasks following a principled taxonomy and over one million video clips, approximately three orders of magnitude larger than existing datasets. We further present VBVR-Bench, a verifiable evaluation framework that moves beyond model-based judging by incorporating rule-based, human-aligned scorers, enabling reproducible and interpretable diagnosis of video reasoning capabilities. Leveraging the VBVR suite, we conduct one of the first large-scale scaling studies of video reasoning and observe early signs of emergent generalization to unseen reasoning tasks. Together, VBVR lays a foundation for the next stage of research in generalizable video reasoning. The data, benchmark toolkit, and models are publicly available at https://video-reason.com/ .", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/6039478ab3ecf716b1a5fd4d/IjK1EcVGF8x-SG3ymPI6T.mp4"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.20159.png", "numComments": 0, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 238, "isUserFollowing": false}, "organization": {"_id": "6986a6f58d72821326efbfbb", "name": "Video-Reason", "fullname": "Video-Reason", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6793f65033629a5fa8ae47b5/7JFt2ReogqVi_udM_OHWG.jpeg"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.23152", "authors": [{"_id": "69a106faa13deaa449448917", "name": "Jingxuan Wei", "hidden": false}, {"_id": "69a106faa13deaa449448918", "user": {"_id": "640f7083208821a59b74c757", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678735253848-640f7083208821a59b74c757.jpeg", "isPro": false, "fullname": "Siyuan Li", "user": "Lupin1998", "type": "user"}, "name": "Siyuan Li", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:47.703Z", "hidden": false}, {"_id": "69a106faa13deaa449448919", "name": "Yuhang Xu", "hidden": false}, {"_id": "69a106faa13deaa44944891a", "name": "Zheng Sun", "hidden": false}, {"_id": "69a106faa13deaa44944891b", "name": "Junjie Jiang", "hidden": false}, {"_id": "69a106faa13deaa44944891c", "name": "Hexuan Jin", "hidden": false}, {"_id": "69a106faa13deaa44944891d", "name": "Caijun Jia", "hidden": false}, {"_id": "69a106faa13deaa44944891e", "name": "Honghao He", "hidden": false}, {"_id": "69a106faa13deaa44944891f", "name": "Xinglong Xu", "hidden": false}, {"_id": "69a106faa13deaa449448920", "name": "Xi bai", "hidden": false}, {"_id": "69a106faa13deaa449448921", "name": "Chang Yu", "hidden": false}, {"_id": "69a106faa13deaa449448922", "name": "Yumou Liu", "hidden": false}, {"_id": "69a106faa13deaa449448923", "name": "Junnan Zhu", "hidden": false}, {"_id": "69a106faa13deaa449448924", "user": {"_id": "64ef522242da8d2a897d62da", "avatarUrl": "/avatars/03611010d247da66696ac8976d4d3ed3.svg", "isPro": false, "fullname": "xuanhe zhou", "user": "zhouxh19", "type": "user"}, "name": "Xuanhe Zhou", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:45.120Z", "hidden": false}, {"_id": "69a106faa13deaa449448925", "name": "Jintao Chen", "hidden": false}, {"_id": "69a106faa13deaa449448926", "name": "Xiaobin Hu", "hidden": false}, {"_id": "69a106faa13deaa449448927", "name": "Shancheng Pang", "hidden": false}, {"_id": "69a106faa13deaa449448928", "name": "Bihui Yu", "hidden": false}, {"_id": "69a106faa13deaa449448929", "name": "Ran He", "hidden": false}, {"_id": "69a106faa13deaa44944892a", "name": "Zhen Lei", "hidden": false}, {"_id": "69a106faa13deaa44944892b", "name": "Stan Z. Li", "hidden": false}, {"_id": "69a106faa13deaa44944892c", "name": "Conghui He", "hidden": false}, {"_id": "69a106faa13deaa44944892d", "name": "Shuicheng Yan", "hidden": false}, {"_id": "69a106faa13deaa44944892e", "user": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "isPro": false, "fullname": "Cheng Tan", "user": "chengtan9907", "type": "user"}, "name": "Cheng Tan", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:37.726Z", "hidden": false}], "publishedAt": "2026-02-26T16:15:55.000Z", "submittedOnDailyAt": "2026-02-27T00:24:05.560Z", "title": "The Trinity of Consistency as a Defining Principle for General World Models", "submittedOnDailyBy": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "isPro": false, "fullname": "Cheng Tan", "user": "chengtan9907", "type": "user"}, "summary": "The construction of World Models capable of learning, simulating, and reasoning about objective physical laws constitutes a foundational challenge in the pursuit of Artificial General Intelligence. Recent advancements represented by video generation models like Sora have demonstrated the potential of data-driven scaling laws to approximate physical dynamics, while the emerging Unified Multimodal Model (UMM) offers a promising architectural paradigm for integrating perception, language, and reasoning. Despite these advances, the field still lacks a principled theoretical framework that defines the essential properties requisite for a General World Model. In this paper, we propose that a World Model must be grounded in the Trinity of Consistency: Modal Consistency as the semantic interface, Spatial Consistency as the geometric basis, and Temporal Consistency as the causal engine. Through this tripartite lens, we systematically review the evolution of multimodal learning, revealing a trajectory from loosely coupled specialized modules toward unified architectures that enable the synergistic emergence of internal world simulators. To complement this conceptual framework, we introduce CoW-Bench, a benchmark centered on multi-frame reasoning and generation scenarios. CoW-Bench evaluates both video generation models and UMMs under a unified evaluation protocol. Our work establishes a principled pathway toward general world models, clarifying both the limitations of current systems and the architectural requirements for future progress.", "upvotes": 159, "discussionId": "69a106faa13deaa44944892f", "projectPage": "https://openraiser.github.io/CoW-Bench/", "githubRepo": "https://github.com/openraiser/awesome-world-model-evolution", "githubRepoAddedBy": "user", "ai_summary": "World Models require three consistency principles\u2014modal, spatial, and temporal\u2014for general artificial intelligence, with a proposed benchmark evaluating multimodal learning systems.", "ai_keywords": ["World Models", "video generation models", "Unified Multimodal Model", "multimodal learning", "multi-frame reasoning", "CoW-Bench", "modal consistency", "spatial consistency", "temporal consistency"], "githubStars": 15, "organization": {"_id": "66ce9d1f5e180b9b9c8e6f31", "name": "opendatalab", "fullname": "OpenDataLab", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/639c3afa7432f2f5d16b7296/yqxxBknyeqkGnYsjoaR4M.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T11:15:55.000Z", "title": "The Trinity of Consistency as a Defining Principle for General World Models", "summary": "The construction of World Models capable of learning, simulating, and reasoning about objective physical laws constitutes a foundational challenge in the pursuit of Artificial General Intelligence. Recent advancements represented by video generation models like Sora have demonstrated the potential of data-driven scaling laws to approximate physical dynamics, while the emerging Unified Multimodal Model (UMM) offers a promising architectural paradigm for integrating perception, language, and reasoning. Despite these advances, the field still lacks a principled theoretical framework that defines the essential properties requisite for a General World Model. In this paper, we propose that a World Model must be grounded in the Trinity of Consistency: Modal Consistency as the semantic interface, Spatial Consistency as the geometric basis, and Temporal Consistency as the causal engine. Through this tripartite lens, we systematically review the evolution of multimodal learning, revealing a trajectory from loosely coupled specialized modules toward unified architectures that enable the synergistic emergence of internal world simulators. To complement this conceptual framework, we introduce CoW-Bench, a benchmark centered on multi-frame reasoning and generation scenarios. CoW-Bench evaluates both video generation models and UMMs under a unified evaluation protocol. Our work establishes a principled pathway toward general world models, clarifying both the limitations of current systems and the architectural requirements for future progress.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.23152.png", "numComments": 3, "submittedBy": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "fullname": "Cheng Tan", "name": "chengtan9907", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 3, "isUserFollowing": false}, "organization": {"_id": "66ce9d1f5e180b9b9c8e6f31", "name": "opendatalab", "fullname": "OpenDataLab", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/639c3afa7432f2f5d16b7296/yqxxBknyeqkGnYsjoaR4M.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.22859", "authors": [{"_id": "69a0ffd0a13deaa4494488fb", "user": {"_id": "66a4c04555677524a0c8047b", "avatarUrl": "/avatars/0913eadc4e33eab9ac705e1ad4df9fc9.svg", "isPro": false, "fullname": "Hongrui Jia", "user": "hongruijia", "type": "user"}, "name": "Hongrui Jia", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:41:05.608Z", "hidden": false}, {"_id": "69a0ffd0a13deaa4494488fc", "name": "Chaoya Jiang", "hidden": false}, {"_id": "69a0ffd0a13deaa4494488fd", "name": "Shikun Zhang", "hidden": false}, {"_id": "69a0ffd0a13deaa4494488fe", "name": "Wei Ye", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/61b9976efd429dff1ed3bd44/IMYdZMOvbDFl55vSivuiA.jpeg"], "publishedAt": "2026-02-26T10:53:57.000Z", "submittedOnDailyAt": "2026-02-27T04:28:11.559Z", "title": "From Blind Spots to Gains: Diagnostic-Driven Iterative Training for Large Multimodal Models", "submittedOnDailyBy": {"_id": "61b9976efd429dff1ed3bd44", "avatarUrl": "/avatars/5cdaa04e970e1e3dcfbb38ba89c0660a.svg", "isPro": false, "fullname": "jiangchaoya", "user": "jcy", "type": "user"}, "summary": "As Large Multimodal Models (LMMs) scale up and reinforcement learning (RL) methods mature, LMMs have made notable progress in complex reasoning and decision making. Yet training still relies on static data and fixed recipes, making it difficult to diagnose capability blind spots or provide dynamic, targeted reinforcement. Motivated by findings that test driven error exposure and feedback based correction outperform repetitive practice, we propose Diagnostic-driven Progressive Evolution (DPE), a spiral loop where diagnosis steers data generation and reinforcement, and each iteration re-diagnoses the updated model to drive the next round of targeted improvement. DPE has two key components. First, multiple agents annotate and quality control massive unlabeled multimodal data, using tools such as web search and image editing to produce diverse, realistic samples. Second, DPE attributes failures to specific weaknesses, dynamically adjusts the data mixture, and guides agents to generate weakness focused data for targeted reinforcement. Experiments on Qwen3-VL-8B-Instruct and Qwen2.5-VL-7B-Instruct show stable, continual gains across eleven benchmarks, indicating DPE as a scalable paradigm for continual LMM training under open task distributions. Our code, models, and data are publicly available at https://github.com/hongruijia/DPE.", "upvotes": 142, "discussionId": "69a0ffd0a13deaa4494488ff", "githubRepo": "https://github.com/hongruijia/DPE", "githubRepoAddedBy": "user", "ai_summary": "Diagnostic-driven Progressive Evolution enables continuous improvement of large multimodal models through iterative diagnosis and targeted data generation guided by identified weaknesses.", "ai_keywords": ["Large Multimodal Models", "reinforcement learning", "diagnostic-driven progressive evolution", "continual learning", "multimodal data", "quality control", "targeted reinforcement"], "githubStars": 27, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T05:53:57.000Z", "title": "From Blind Spots to Gains: Diagnostic-Driven Iterative Training for Large Multimodal Models", "summary": "As Large Multimodal Models (LMMs) scale up and reinforcement learning (RL) methods mature, LMMs have made notable progress in complex reasoning and decision making. Yet training still relies on static data and fixed recipes, making it difficult to diagnose capability blind spots or provide dynamic, targeted reinforcement. Motivated by findings that test driven error exposure and feedback based correction outperform repetitive practice, we propose Diagnostic-driven Progressive Evolution (DPE), a spiral loop where diagnosis steers data generation and reinforcement, and each iteration re-diagnoses the updated model to drive the next round of targeted improvement. DPE has two key components. First, multiple agents annotate and quality control massive unlabeled multimodal data, using tools such as web search and image editing to produce diverse, realistic samples. Second, DPE attributes failures to specific weaknesses, dynamically adjusts the data mixture, and guides agents to generate weakness focused data for targeted reinforcement. Experiments on Qwen3-VL-8B-Instruct and Qwen2.5-VL-7B-Instruct show stable, continual gains across eleven benchmarks, indicating DPE as a scalable paradigm for continual LMM training under open task distributions. Our code, models, and data are publicly available at https://github.com/hongruijia/DPE.", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/61b9976efd429dff1ed3bd44/IMYdZMOvbDFl55vSivuiA.jpeg"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.22859.png", "numComments": 2, "submittedBy": {"_id": "61b9976efd429dff1ed3bd44", "avatarUrl": "/avatars/5cdaa04e970e1e3dcfbb38ba89c0660a.svg", "fullname": "jiangchaoya", "name": "jcy", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 1, "isUserFollowing": false}, "isAuthorParticipating": false}, {"paper": {"id": "2602.22638", "authors": [{"_id": "69a13c51a13deaa449448a3f", "name": "Zhiheng Song", "hidden": false}, {"_id": "69a13c51a13deaa449448a40", "name": "Jingshuai Zhang", "hidden": false}, {"_id": "69a13c51a13deaa449448a41", "name": "Chuan Qin", "hidden": false}, {"_id": "69a13c51a13deaa449448a42", "name": "Chao Wang", "hidden": false}, {"_id": "69a13c51a13deaa449448a43", "name": "Chao Chen", "hidden": false}, {"_id": "69a13c51a13deaa449448a44", "name": "Longfei Xu", "hidden": false}, {"_id": "69a13c51a13deaa449448a45", "name": "Kaikui Liu", "hidden": false}, {"_id": "69a13c51a13deaa449448a46", "name": "Xiangxiang Chu", "hidden": false}, {"_id": "69a13c51a13deaa449448a47", "name": "Hengshu Zhu", "hidden": false}], "publishedAt": "2026-02-26T05:39:38.000Z", "submittedOnDailyAt": "2026-02-27T09:31:41.352Z", "title": "MobilityBench: A Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios", "submittedOnDailyBy": {"_id": "66d255e3947594430c723ff6", "avatarUrl": "/avatars/c56e4792332a01bf34085a75ee64916e.svg", "isPro": false, "fullname": "xiaochonglinghu", "user": "xiaochonglinghu", "type": "user"}, "summary": "Route-planning agents powered by large language models (LLMs) have emerged as a promising paradigm for supporting everyday human mobility through natural language interaction and tool-mediated decision making. However, systematic evaluation in real-world mobility settings is hindered by diverse routing demands, non-deterministic mapping services, and limited reproducibility. In this study, we introduce MobilityBench, a scalable benchmark for evaluating LLM-based route-planning agents in real-world mobility scenarios. MobilityBench is constructed from large-scale, anonymized real user queries collected from Amap and covers a broad spectrum of route-planning intents across multiple cities worldwide. To enable reproducible, end-to-end evaluation, we design a deterministic API-replay sandbox that eliminates environmental variance from live services. We further propose a multi-dimensional evaluation protocol centered on outcome validity, complemented by assessments of instruction understanding, planning, tool use, and efficiency. Using MobilityBench, we evaluate multiple LLM-based route-planning agents across diverse real-world mobility scenarios and provide an in-depth analysis of their behaviors and performance. Our findings reveal that current models perform competently on Basic information retrieval and Route Planning tasks, yet struggle considerably with Preference-Constrained Route Planning, underscoring significant room for improvement in personalized mobility applications. We publicly release the benchmark data, evaluation toolkit, and documentation at https://github.com/AMAP-ML/MobilityBench .", "upvotes": 86, "discussionId": "69a13c52a13deaa449448a48", "githubRepo": "https://github.com/AMAP-ML/MobilityBench", "githubRepoAddedBy": "user", "ai_summary": "MobileBench is a scalable benchmark for evaluating LLM-based route-planning agents in real-world scenarios, featuring anonymized user queries and a deterministic sandbox for reproducible testing.", "ai_keywords": ["route-planning agents", "large language models", "MobilityBench", "API-replay sandbox", "deterministic environment", "multi-dimensional evaluation", "outcome validity", "instruction understanding", "planning", "tool use", "efficiency", "real-world mobility scenarios"], "githubStars": 94, "organization": {"_id": "64488b334988ee01f2a8d856", "name": "alibaba-inc", "fullname": "alibaba-inc", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61ac8f8a00d01045fca0ad2f/MX4wxQVaFm1A1wqnrL2WU.jpeg"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T00:39:38.000Z", "title": "MobilityBench: A Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios", "summary": "Route-planning agents powered by large language models (LLMs) have emerged as a promising paradigm for supporting everyday human mobility through natural language interaction and tool-mediated decision making. However, systematic evaluation in real-world mobility settings is hindered by diverse routing demands, non-deterministic mapping services, and limited reproducibility. In this study, we introduce MobilityBench, a scalable benchmark for evaluating LLM-based route-planning agents in real-world mobility scenarios. MobilityBench is constructed from large-scale, anonymized real user queries collected from Amap and covers a broad spectrum of route-planning intents across multiple cities worldwide. To enable reproducible, end-to-end evaluation, we design a deterministic API-replay sandbox that eliminates environmental variance from live services. We further propose a multi-dimensional evaluation protocol centered on outcome validity, complemented by assessments of instruction understanding, planning, tool use, and efficiency. Using MobilityBench, we evaluate multiple LLM-based route-planning agents across diverse real-world mobility scenarios and provide an in-depth analysis of their behaviors and performance. Our findings reveal that current models perform competently on Basic information retrieval and Route Planning tasks, yet struggle considerably with Preference-Constrained Route Planning, underscoring significant room for improvement in personalized mobility applications. We publicly release the benchmark data, evaluation toolkit, and documentation at https://github.com/AMAP-ML/MobilityBench .", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.22638.png", "numComments": 2, "submittedBy": {"_id": "66d255e3947594430c723ff6", "avatarUrl": "/avatars/c56e4792332a01bf34085a75ee64916e.svg", "fullname": "xiaochonglinghu", "name": "xiaochonglinghu", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 8, "isUserFollowing": false}, "organization": {"_id": "64488b334988ee01f2a8d856", "name": "alibaba-inc", "fullname": "alibaba-inc", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61ac8f8a00d01045fca0ad2f/MX4wxQVaFm1A1wqnrL2WU.jpeg"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.21193", "authors": [{"_id": "699e72b4dfbcf0b800aecb63", "name": "Renjie Pi", "hidden": false}, {"_id": "699e72b4dfbcf0b800aecb64", "name": "Grace Lam", "hidden": false}, {"_id": "699e72b4dfbcf0b800aecb65", "name": "Mohammad Shoeybi", "hidden": false}, {"_id": "699e72b4dfbcf0b800aecb66", "name": "Pooya Jannaty", "hidden": false}, {"_id": "699e72b4dfbcf0b800aecb67", "name": "Bryan Catanzaro", "hidden": false}, {"_id": "699e72b4dfbcf0b800aecb68", "name": "Wei Ping", "hidden": false}], "publishedAt": "2026-02-24T18:51:04.000Z", "submittedOnDailyAt": "2026-02-25T01:39:40.130Z", "title": "On Data Engineering for Scaling LLM Terminal Capabilities", "submittedOnDailyBy": {"_id": "63f45b8d520c14618930d175", "avatarUrl": "/avatars/42b3aaf50748a25e4a596fc57ab1306d.svg", "isPro": false, "fullname": "renjie", "user": "renjiepi", "type": "user"}, "summary": "Despite rapid recent progress in the terminal capabilities of large language models, the training data strategies behind state-of-the-art terminal agents remain largely undisclosed. We address this gap through a systematic study of data engineering practices for terminal agents, making two key contributions: (1) Terminal-Task-Gen, a lightweight synthetic task generation pipeline that supports seed-based and skill-based task construction, and (2) a comprehensive analysis of data and training strategies, including filtering, curriculum learning, long context training, and scaling behavior. Our pipeline yields Terminal-Corpus, a large-scale open-source dataset for terminal tasks. Using this dataset, we train Nemotron-Terminal, a family of models initialized from Qwen3(8B, 14B, 32B) that achieve substantial gains on Terminal-Bench 2.0: Nemotron-Terminal-8B improves from 2.5% to 13.0% Nemotron-Terminal-14B improves from 4.0% to 20.2%, and Nemotron-Terminal-32B improves from 3.4% to 27.4%, matching the performance of significantly larger models. To accelerate research in this domain, we open-source our model checkpoints and most of our synthetic datasets at https://huggingface.co/collections/nvidia/nemotron-terminal.", "upvotes": 60, "discussionId": "699e72b5dfbcf0b800aecb69", "projectPage": "https://huggingface.co/collections/nvidia/nemotron-terminal", "ai_summary": "Researchers developed a synthetic task generation pipeline and analyzed data strategies to improve terminal agent performance, creating a large-scale dataset and models that outperform larger counterparts on benchmark tests.", "ai_keywords": ["large language models", "terminal agents", "data engineering practices", "synthetic task generation", "Terminal-Task-Gen", "Terminal-Corpus", "Nemotron-Terminal", "Terminal-Bench 2.0", "curriculum learning", "long context training", "scaling behavior"], "organization": {"_id": "60262b67268c201cdc8b7d43", "name": "nvidia", "fullname": "NVIDIA", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-24T13:51:04.000Z", "title": "On Data Engineering for Scaling LLM Terminal Capabilities", "summary": "Despite rapid recent progress in the terminal capabilities of large language models, the training data strategies behind state-of-the-art terminal agents remain largely undisclosed. We address this gap through a systematic study of data engineering practices for terminal agents, making two key contributions: (1) Terminal-Task-Gen, a lightweight synthetic task generation pipeline that supports seed-based and skill-based task construction, and (2) a comprehensive analysis of data and training strategies, including filtering, curriculum learning, long context training, and scaling behavior. Our pipeline yields Terminal-Corpus, a large-scale open-source dataset for terminal tasks. Using this dataset, we train Nemotron-Terminal, a family of models initialized from Qwen3(8B, 14B, 32B) that achieve substantial gains on Terminal-Bench 2.0: Nemotron-Terminal-8B improves from 2.5% to 13.0% Nemotron-Terminal-14B improves from 4.0% to 20.2%, and Nemotron-Terminal-32B improves from 3.4% to 27.4%, matching the performance of significantly larger models. To accelerate research in this domain, we open-source our model checkpoints and most of our synthetic datasets at https://huggingface.co/collections/nvidia/nemotron-terminal.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.21193.png", "numComments": 2, "submittedBy": {"_id": "63f45b8d520c14618930d175", "avatarUrl": "/avatars/42b3aaf50748a25e4a596fc57ab1306d.svg", "fullname": "renjie", "name": "renjiepi", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 11, "isUserFollowing": false}, "organization": {"_id": "60262b67268c201cdc8b7d43", "name": "nvidia", "fullname": "NVIDIA", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.22897", "authors": [{"_id": "69a0fda9a13deaa4494488e3", "name": "Xiaoxi Li", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e4", "user": {"_id": "63db16330cc3bc12bc0b6f8f", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63db16330cc3bc12bc0b6f8f/ld0JQIfX1SBlDVDOmw9VT.jpeg", "isPro": false, "fullname": "Wenxiang Jiao", "user": "wxjiao", "type": "user"}, "name": "Wenxiang Jiao", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:41:37.304Z", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e5", "name": "Jiarui Jin", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e6", "name": "Shijian Wang", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e7", "user": {"_id": "61cd4b833dd34ba1985e0753", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61cd4b833dd34ba1985e0753/BfHfrwotoMESpXZOHiIe4.png", "isPro": false, "fullname": "KABI", "user": "dongguanting", "type": "user"}, "name": "Guanting Dong", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:41:09.826Z", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e8", "name": "Jiajie Jin", "hidden": false}, {"_id": "69a0fda9a13deaa4494488e9", "name": "Hao Wang", "hidden": false}, {"_id": "69a0fda9a13deaa4494488ea", "name": "Yinuo Wang", "hidden": false}, {"_id": "69a0fda9a13deaa4494488eb", "name": "Ji-Rong Wen", "hidden": false}, {"_id": "69a0fda9a13deaa4494488ec", "name": "Yuan Lu", "hidden": false}, {"_id": "69a0fda9a13deaa4494488ed", "name": "Zhicheng Dou", "hidden": false}], "publishedAt": "2026-02-26T11:35:04.000Z", "submittedOnDailyAt": "2026-02-27T00:29:04.184Z", "title": "OmniGAIA: Towards Native Omni-Modal AI Agents", "submittedOnDailyBy": {"_id": "66e03eace17fb5ff054b7686", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66e03eace17fb5ff054b7686/PpSV0Qo5lwTyxIZMp57xq.jpeg", "isPro": false, "fullname": "Xiaoxi Li", "user": "lixiaoxi45", "type": "user"}, "summary": "Human intelligence naturally intertwines omni-modal perception -- spanning vision, audio, and language -- with complex reasoning and tool usage to interact with the world. However, current multi-modal LLMs are primarily confined to bi-modal interactions (e.g., vision-language), lacking the unified cognitive capabilities required for general AI assistants. To bridge this gap, we introduce OmniGAIA, a comprehensive benchmark designed to evaluate omni-modal agents on tasks necessitating deep reasoning and multi-turn tool execution across video, audio, and image modalities. Constructed via a novel omni-modal event graph approach, OmniGAIA synthesizes complex, multi-hop queries derived from real-world data that require cross-modal reasoning and external tool integration. Furthermore, we propose OmniAtlas, a native omni-modal foundation agent under tool-integrated reasoning paradigm with active omni-modal perception. Trained on trajectories synthesized via a hindsight-guided tree exploration strategy and OmniDPO for fine-grained error correction, OmniAtlas effectively enhances the tool-use capabilities of existing open-source models. This work marks a step towards next-generation native omni-modal AI assistants for real-world scenarios.", "upvotes": 46, "discussionId": "69a0fda9a13deaa4494488ee", "githubRepo": "https://github.com/RUC-NLPIR/OmniGAIA", "githubRepoAddedBy": "user", "ai_summary": "OmniGAIA benchmark evaluates multi-modal agents on complex reasoning tasks across video, audio, and image modalities, while OmniAtlas agent improves tool-use capabilities through hindsight-guided tree exploration and OmniDPO fine-tuning.", "ai_keywords": ["multi-modal LLMs", "omni-modal perception", "cross-modal reasoning", "tool-integrated reasoning", "hindsight-guided tree exploration", "OmniDPO"], "githubStars": 34, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T06:35:04.000Z", "title": "OmniGAIA: Towards Native Omni-Modal AI Agents", "summary": "Human intelligence naturally intertwines omni-modal perception -- spanning vision, audio, and language -- with complex reasoning and tool usage to interact with the world. However, current multi-modal LLMs are primarily confined to bi-modal interactions (e.g., vision-language), lacking the unified cognitive capabilities required for general AI assistants. To bridge this gap, we introduce OmniGAIA, a comprehensive benchmark designed to evaluate omni-modal agents on tasks necessitating deep reasoning and multi-turn tool execution across video, audio, and image modalities. Constructed via a novel omni-modal event graph approach, OmniGAIA synthesizes complex, multi-hop queries derived from real-world data that require cross-modal reasoning and external tool integration. Furthermore, we propose OmniAtlas, a native omni-modal foundation agent under tool-integrated reasoning paradigm with active omni-modal perception. Trained on trajectories synthesized via a hindsight-guided tree exploration strategy and OmniDPO for fine-grained error correction, OmniAtlas effectively enhances the tool-use capabilities of existing open-source models. This work marks a step towards next-generation native omni-modal AI assistants for real-world scenarios.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.22897.png", "numComments": 2, "submittedBy": {"_id": "66e03eace17fb5ff054b7686", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66e03eace17fb5ff054b7686/PpSV0Qo5lwTyxIZMp57xq.jpeg", "fullname": "Xiaoxi Li", "name": "lixiaoxi45", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 21, "isUserFollowing": false}, "isAuthorParticipating": false}, {"paper": {"id": "2602.22766", "authors": [{"_id": "69a112ffa13deaa44944896f", "name": "You Li", "hidden": false}, {"_id": "69a112ffa13deaa449448970", "name": "Chi Chen", "hidden": false}, {"_id": "69a112ffa13deaa449448971", "name": "Yanghao Li", "hidden": false}, {"_id": "69a112ffa13deaa449448972", "name": "Fanhu Zeng", "hidden": false}, {"_id": "69a112ffa13deaa449448973", "name": "Kaiyu Huang", "hidden": false}, {"_id": "69a112ffa13deaa449448974", "name": "Jinan Xu", "hidden": false}, {"_id": "69a112ffa13deaa449448975", "name": "Maosong Sun", "hidden": false}], "publishedAt": "2026-02-26T08:56:23.000Z", "submittedOnDailyAt": "2026-02-27T01:16:22.929Z", "title": "Imagination Helps Visual Reasoning, But Not Yet in Latent Space", "submittedOnDailyBy": {"_id": "654f3e104c8874c64d43aafa", "avatarUrl": "/avatars/00de263f98a81c52cdb321fb11b16c06.svg", "isPro": false, "fullname": "You Li", "user": "Michael4933", "type": "user"}, "summary": "Latent visual reasoning aims to mimic human's imagination process by meditating through hidden states of Multimodal Large Language Models. While recognized as a promising paradigm for visual reasoning, the underlying mechanisms driving its effectiveness remain unclear. Motivated to demystify the true source of its efficacy, we investigate the validity of latent reasoning using Causal Mediation Analysis. We model the process as a causal chain: the input as the treatment, the latent tokens as the mediator, and the final answer as the outcome. Our findings uncover two critical disconnections: (a) Input-Latent Disconnect: dramatic perturbations on the input result in negligible changes to the latent tokens, suggesting that latent tokens do not effectively attend to the input sequence. (b) Latent-Answer Disconnect: perturbations on the latent tokens yield minimal impact on the final answer, indicating the limited causal effect latent tokens imposing on the outcome. Furthermore, extensive probing analysis reveals that latent tokens encode limited visual information and exhibit high similarity. Consequently, we challenge the necessity of latent reasoning and propose a straightforward alternative named CapImagine, which teaches the model to explicitly imagine using text. Experiments on vision-centric benchmarks show that CapImagine significantly outperforms complex latent-space baselines, highlighting the superior potential of visual reasoning through explicit imagination.", "upvotes": 31, "discussionId": "69a112ffa13deaa449448976", "githubRepo": "https://github.com/AI9Stars/CapImagine", "githubRepoAddedBy": "user", "ai_summary": "Research reveals that latent visual reasoning in multimodal models suffers from input-latent and latent-answer disconnects, leading to the proposal of CapImagine, a text-based approach that outperforms complex latent-space methods.", "ai_keywords": ["Multimodal Large Language Models", "causal mediation analysis", "latent tokens", "visual reasoning", "input-latent disconnect", "latent-answer disconnect", "CapImagine"], "githubStars": 10, "organization": {"_id": "628735cbc83a2d6ab8d14a66", "name": "Tsinghua", "fullname": "Tsinghua University"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T03:56:23.000Z", "title": "Imagination Helps Visual Reasoning, But Not Yet in Latent Space", "summary": "Latent visual reasoning aims to mimic human's imagination process by meditating through hidden states of Multimodal Large Language Models. While recognized as a promising paradigm for visual reasoning, the underlying mechanisms driving its effectiveness remain unclear. Motivated to demystify the true source of its efficacy, we investigate the validity of latent reasoning using Causal Mediation Analysis. We model the process as a causal chain: the input as the treatment, the latent tokens as the mediator, and the final answer as the outcome. Our findings uncover two critical disconnections: (a) Input-Latent Disconnect: dramatic perturbations on the input result in negligible changes to the latent tokens, suggesting that latent tokens do not effectively attend to the input sequence. (b) Latent-Answer Disconnect: perturbations on the latent tokens yield minimal impact on the final answer, indicating the limited causal effect latent tokens imposing on the outcome. Furthermore, extensive probing analysis reveals that latent tokens encode limited visual information and exhibit high similarity. Consequently, we challenge the necessity of latent reasoning and propose a straightforward alternative named CapImagine, which teaches the model to explicitly imagine using text. Experiments on vision-centric benchmarks show that CapImagine significantly outperforms complex latent-space baselines, highlighting the superior potential of visual reasoning through explicit imagination.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.22766.png", "numComments": 2, "submittedBy": {"_id": "654f3e104c8874c64d43aafa", "avatarUrl": "/avatars/00de263f98a81c52cdb321fb11b16c06.svg", "fullname": "You Li", "name": "Michael4933", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 2, "isUserFollowing": false}, "organization": {"_id": "628735cbc83a2d6ab8d14a66", "name": "Tsinghua", "fullname": "Tsinghua University"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.19672", "authors": [{"_id": "699d407c4e37ec6dfa1bc6a7", "user": {"_id": "651651f5d93a51ceda3021c3", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651651f5d93a51ceda3021c3/FE2uGpTKBRWMKTDBv1H-g.png", "isPro": false, "fullname": "Jiayu (Mila) Wang", "user": "MilaWang", "type": "user"}, "name": "Jiayu Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:49:47.846Z", "hidden": false}, {"_id": "699d407c4e37ec6dfa1bc6a8", "name": "Yifei Ming", "hidden": false}, {"_id": "699d407c4e37ec6dfa1bc6a9", "name": "Zixuan Ke", "hidden": false}, {"_id": "699d407c4e37ec6dfa1bc6aa", "name": "Shafiq Joty", "hidden": false}, {"_id": "699d407c4e37ec6dfa1bc6ab", "name": "Aws Albarghouthi", "hidden": false}, {"_id": "699d407c4e37ec6dfa1bc6ac", "name": "Frederic Sala", "hidden": false}], "publishedAt": "2026-02-23T10:17:25.000Z", "submittedOnDailyAt": "2026-02-24T03:44:00.879Z", "title": "SkillOrchestra: Learning to Route Agents via Skill Transfer", "submittedOnDailyBy": {"_id": "651651f5d93a51ceda3021c3", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651651f5d93a51ceda3021c3/FE2uGpTKBRWMKTDBv1H-g.png", "isPro": false, "fullname": "Jiayu (Mila) Wang", "user": "MilaWang", "type": "user"}, "summary": "Compound AI systems promise capabilities beyond those of individual models, yet their success depends critically on effective orchestration. Existing routing approaches face two limitations: (1) input-level routers make coarse query-level decisions that ignore evolving task requirements; (2) RL-trained orchestrators are expensive to adapt and often suffer from routing collapse, repeatedly invoking one strong but costly option in multi-turn scenarios. We introduce SkillOrchestra, a framework for skill-aware orchestration. Instead of directly learning a routing policy end-to-end, SkillOrchestra learns fine-grained skills from execution experience and models agent-specific competence and cost under those skills. At deployment, the orchestrator infers the skill demands of the current interaction and selects agents that best satisfy them under an explicit performance-cost trade-off. Extensive experiments across ten benchmarks demonstrate that SkillOrchestra outperforms SoTA RL-based orchestrators by up to 22.5% with 700x and 300x learning cost reduction compared to Router-R1 and ToolOrchestra, respectively. These results show that explicit skill modeling enables scalable, interpretable, and sample-efficient orchestration, offering a principled alternative to data-intensive RL-based approaches. The code is available at: https://github.com/jiayuww/SkillOrchestra.", "upvotes": 30, "discussionId": "699d407c4e37ec6dfa1bc6ad", "ai_summary": "SkillOrchestra presents a skill-aware orchestration framework that improves compound AI system performance through fine-grained skill modeling and efficient agent selection, achieving superior results with significantly reduced learning costs compared to reinforcement learning-based methods.", "ai_keywords": ["compound AI systems", "orchestration", "routing policy", "reinforcement learning", "skill modeling", "agent-specific competence", "performance-cost trade-off", "multi-turn scenarios", "routing collapse", "end-to-end learning"], "organization": {"_id": "61d090ec03bc10eb8e1c2970", "name": "uw-madison", "fullname": "University of Wisconsin - Madison", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/68e396f2b5bb631e9b2fac9a/IYmUaLUc_rDVNC6F7-k8M.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-23T05:17:25.000Z", "title": "SkillOrchestra: Learning to Route Agents via Skill Transfer", "summary": "Compound AI systems promise capabilities beyond those of individual models, yet their success depends critically on effective orchestration. Existing routing approaches face two limitations: (1) input-level routers make coarse query-level decisions that ignore evolving task requirements; (2) RL-trained orchestrators are expensive to adapt and often suffer from routing collapse, repeatedly invoking one strong but costly option in multi-turn scenarios. We introduce SkillOrchestra, a framework for skill-aware orchestration. Instead of directly learning a routing policy end-to-end, SkillOrchestra learns fine-grained skills from execution experience and models agent-specific competence and cost under those skills. At deployment, the orchestrator infers the skill demands of the current interaction and selects agents that best satisfy them under an explicit performance-cost trade-off. Extensive experiments across ten benchmarks demonstrate that SkillOrchestra outperforms SoTA RL-based orchestrators by up to 22.5% with 700x and 300x learning cost reduction compared to Router-R1 and ToolOrchestra, respectively. These results show that explicit skill modeling enables scalable, interpretable, and sample-efficient orchestration, offering a principled alternative to data-intensive RL-based approaches. The code is available at: https://github.com/jiayuww/SkillOrchestra.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.19672.png", "numComments": 1, "submittedBy": {"_id": "651651f5d93a51ceda3021c3", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651651f5d93a51ceda3021c3/FE2uGpTKBRWMKTDBv1H-g.png", "fullname": "Jiayu (Mila) Wang", "name": "MilaWang", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 1, "isUserFollowing": false}, "organization": {"_id": "61d090ec03bc10eb8e1c2970", "name": "uw-madison", "fullname": "University of Wisconsin - Madison", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/68e396f2b5bb631e9b2fac9a/IYmUaLUc_rDVNC6F7-k8M.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.23008", "authors": [{"_id": "69a11540a13deaa449448995", "user": {"_id": "66228a37f5c285535cc9cc83", "avatarUrl": "/avatars/0982d6553a9c9001ebdca2878bcfff34.svg", "isPro": false, "fullname": "Zeyuan Liu", "user": "ZeyuanLiu", "type": "user"}, "name": "Zeyuan Liu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:23.614Z", "hidden": false}, {"_id": "69a11540a13deaa449448996", "user": {"_id": "63e48f6d9db5da2dc1f6288e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676046878664-63e48f6d9db5da2dc1f6288e.png", "isPro": false, "fullname": "JeonghyeKim", "user": "beanie00", "type": "user"}, "name": "Jeonghye Kim", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:18.705Z", "hidden": false}, {"_id": "69a11540a13deaa449448997", "user": {"_id": "66a1f912345b3106f47ce860", "avatarUrl": "/avatars/40177299c64e16703e7bfe83de0810be.svg", "isPro": false, "fullname": "Xufang Luo", "user": "daixufang", "type": "user"}, "name": "Xufang Luo", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:15.195Z", "hidden": false}, {"_id": "69a11540a13deaa449448998", "name": "Dongsheng Li", "hidden": false}, {"_id": "69a11540a13deaa449448999", "name": "Yuqing Yang", "hidden": false}], "publishedAt": "2026-02-26T13:50:57.000Z", "submittedOnDailyAt": "2026-02-27T01:31:44.571Z", "title": "Exploratory Memory-Augmented LLM Agent via Hybrid On- and Off-Policy Optimization", "submittedOnDailyBy": {"_id": "63e48f6d9db5da2dc1f6288e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676046878664-63e48f6d9db5da2dc1f6288e.png", "isPro": false, "fullname": "JeonghyeKim", "user": "beanie00", "type": "user"}, "summary": "Exploration remains the key bottleneck for large language model agents trained with reinforcement learning. While prior methods exploit pretrained knowledge, they fail in environments requiring the discovery of novel states. We propose Exploratory Memory-Augmented On- and Off-Policy Optimization (EMPO^2), a hybrid RL framework that leverages memory for exploration and combines on- and off-policy updates to make LLMs perform well with memory while also ensuring robustness without it. On ScienceWorld and WebShop, EMPO^2 achieves 128.6% and 11.3% improvements over GRPO, respectively. Moreover, in out-of-distribution tests, EMPO^2 demonstrates superior adaptability to new tasks, requiring only a few trials with memory and no parameter updates. These results highlight EMPO^2 as a promising framework for building more exploratory and generalizable LLM-based agents.", "upvotes": 26, "discussionId": "69a11540a13deaa44944899a", "ai_summary": "EMPO\u00b2 is a hybrid reinforcement learning framework that enhances exploration for large language model agents by integrating memory mechanisms with on- and off-policy updates, demonstrating improved performance and adaptability in complex environments.", "ai_keywords": ["reinforcement learning", "large language model agents", "exploration", "memory augmentation", "on-policy updates", "off-policy updates", "ScienceWorld", "WebShop"], "organization": {"_id": "5e6485f787403103f9f1055e", "name": "microsoft", "fullname": "Microsoft", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1583646260758-5e64858c87403103f9f1055d.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T08:50:57.000Z", "title": "Exploratory Memory-Augmented LLM Agent via Hybrid On- and Off-Policy Optimization", "summary": "Exploration remains the key bottleneck for large language model agents trained with reinforcement learning. While prior methods exploit pretrained knowledge, they fail in environments requiring the discovery of novel states. We propose Exploratory Memory-Augmented On- and Off-Policy Optimization (EMPO^2), a hybrid RL framework that leverages memory for exploration and combines on- and off-policy updates to make LLMs perform well with memory while also ensuring robustness without it. On ScienceWorld and WebShop, EMPO^2 achieves 128.6% and 11.3% improvements over GRPO, respectively. Moreover, in out-of-distribution tests, EMPO^2 demonstrates superior adaptability to new tasks, requiring only a few trials with memory and no parameter updates. These results highlight EMPO^2 as a promising framework for building more exploratory and generalizable LLM-based agents.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.23008.png", "numComments": 2, "submittedBy": {"_id": "63e48f6d9db5da2dc1f6288e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676046878664-63e48f6d9db5da2dc1f6288e.png", "fullname": "JeonghyeKim", "name": "beanie00", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 1, "isUserFollowing": false}, "organization": {"_id": "5e6485f787403103f9f1055e", "name": "microsoft", "fullname": "Microsoft", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1583646260758-5e64858c87403103f9f1055d.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.23258", "authors": [{"_id": "69a14dd7a13deaa449448a7e", "name": "Yutong Wang", "hidden": false}, {"_id": "69a14dd7a13deaa449448a7f", "name": "Siyuan Xiong", "hidden": false}, {"_id": "69a14dd7a13deaa449448a80", "name": "Xuebo Liu", "hidden": false}, {"_id": "69a14dd7a13deaa449448a81", "name": "Wenkang Zhou", "hidden": false}, {"_id": "69a14dd7a13deaa449448a82", "name": "Liang Ding", "hidden": false}, {"_id": "69a14dd7a13deaa449448a83", "name": "Miao Zhang", "hidden": false}, {"_id": "69a14dd7a13deaa449448a84", "name": "Min Zhang", "hidden": false}], "publishedAt": "2026-02-26T17:31:43.000Z", "submittedOnDailyAt": "2026-02-27T05:27:41.765Z", "title": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning", "submittedOnDailyBy": {"_id": "652fbf9e75f5f7a84e10cb2e", "avatarUrl": "/avatars/73e7af465dbb57826a52e49c3e72f55f.svg", "isPro": false, "fullname": "Xuebo Liu", "user": "SunbowLiu", "type": "user"}, "summary": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/AgentDropoutV2.", "upvotes": 23, "discussionId": "69a14dd7a13deaa449448a85", "githubRepo": "https://github.com/TonySY2/AgentDropoutV2", "githubRepoAddedBy": "user", "ai_summary": "AgentDropoutV2 is a test-time framework that dynamically optimizes multi-agent system information flow through error correction and pruning mechanisms without requiring retraining.", "ai_keywords": ["multi-agent systems", "test-time rectify-or-reject pruning", "retrieval-augmented rectifier", "failure-driven indicator pool", "distilled failure patterns", "error propagation", "fallback strategy", "context-aware indicators"], "githubStars": 14, "organization": {"_id": "670819b38c9c6f598f37d86f", "name": "HarbinInstituteofTechnologyHIT", "fullname": "Harbin Institute of Technology"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T12:31:43.000Z", "title": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning", "summary": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/AgentDropoutV2.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.23258.png", "numComments": 2, "submittedBy": {"_id": "652fbf9e75f5f7a84e10cb2e", "avatarUrl": "/avatars/73e7af465dbb57826a52e49c3e72f55f.svg", "fullname": "Xuebo Liu", "name": "SunbowLiu", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 1, "isUserFollowing": false}, "organization": {"_id": "670819b38c9c6f598f37d86f", "name": "HarbinInstituteofTechnologyHIT", "fullname": "Harbin Institute of Technology"}, "isAuthorParticipating": false}],
    "month": [{"paper": {"id": "2602.20159", "authors": [{"_id": "699d1e7a4e37ec6dfa1bc5b7", "user": {"_id": "67f87529318a17cc80365190", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/p1YkznAT-op1Cg-vBoFw7.png", "isPro": false, "fullname": "Maijunxian Wang", "user": "Mark7121983123", "type": "user"}, "name": "Maijunxian Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:19.409Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5b8", "user": {"_id": "65b74305e602b6c2c9125480", "avatarUrl": "/avatars/d36909e0f245bfeb632a4afc9d3fceca.svg", "isPro": false, "fullname": "wang ruisi", "user": "wruisi", "type": "user"}, "name": "Ruisi Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:01.779Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5b9", "name": "Juyi Lin", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ba", "name": "Ran Ji", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5bb", "name": "Thadd\u00e4us Wiedemer", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5bc", "name": "Qingying Gao", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5bd", "name": "Dezhi Luo", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5be", "name": "Yaoyao Qian", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5bf", "name": "Lianyu Huang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c0", "name": "Zelong Hong", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c1", "name": "Jiahui Ge", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c2", "name": "Qianli Ma", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c3", "name": "Hang He", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c4", "user": {"_id": "659d2dff20cf0b934bbee513", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/659d2dff20cf0b934bbee513/9e9R852Zr2R82h64eUUQl.jpeg", "isPro": false, "fullname": "Yifan Zhou", "user": "yingmanji", "type": "user"}, "name": "Yifan Zhou", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:04.030Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c5", "name": "Lingzi Guo", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c6", "name": "Lantao Mei", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c7", "name": "Jiachen Li", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c8", "user": {"_id": "6532c3018bde2fae19578587", "avatarUrl": "/avatars/7231538f3d682a1e7b80e15ea91b2a97.svg", "isPro": false, "fullname": "Hanwen Xing", "user": "Hudx111", "type": "user"}, "name": "Hanwen Xing", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:09.132Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5c9", "name": "Tianqi Zhao", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ca", "name": "Fengyuan Yu", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5cb", "name": "Weihang Xiao", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5cc", "name": "Yizheng Jiao", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5cd", "name": "Jianheng Hou", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ce", "name": "Danyang Zhang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5cf", "user": {"_id": "65d854e5d8134b93774b4080", "avatarUrl": "/avatars/0ff1db8c13095f420a856212d64f88ca.svg", "isPro": false, "fullname": "Pengcheng Xu", "user": "explcre", "type": "user"}, "name": "Pengcheng Xu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:21.447Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d0", "name": "Boyang Zhong", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d1", "name": "Zehong Zhao", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d2", "name": "Gaoyun Fang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d3", "name": "John Kitaoka", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d4", "name": "Yile Xu", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d5", "name": "Hua Xu", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d6", "name": "Kenton Blacutt", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d7", "name": "Tin Nguyen", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d8", "name": "Siyuan Song", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5d9", "name": "Haoran Sun", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5da", "name": "Shaoyue Wen", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5db", "name": "Linyang He", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5dc", "name": "Runming Wang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5dd", "name": "Yanzhi Wang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5de", "name": "Mengyue Yang", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5df", "name": "Ziqiao Ma", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e0", "name": "Rapha\u00ebl Milli\u00e8re", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e1", "name": "Freda Shi", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e2", "name": "Nuno Vasconcelos", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e3", "name": "Daniel Khashabi", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e4", "name": "Alan Yuille", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e5", "name": "Yilun Du", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e6", "name": "Ziming Liu", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e7", "name": "Bo Li", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e8", "name": "Dahua Lin", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5e9", "name": "Ziwei Liu", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ea", "name": "Vikash Kumar", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5eb", "name": "Yijiang Li", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ec", "user": {"_id": "6626a471430a124253f197c8", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6626a471430a124253f197c8/uVEk5nnW-bS6-no0rQ7Wh.png", "isPro": false, "fullname": "yl-1993", "user": "yl-1993", "type": "user"}, "name": "Lei Yang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:17.400Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ed", "user": {"_id": "652d06833b5997ed71ce5c46", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/xZTXEcnEogEmBm_ledJQr.jpeg", "isPro": false, "fullname": "Zhongang Cai", "user": "caizhongang", "type": "user"}, "name": "Zhongang Cai", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:50:06.679Z", "hidden": false}, {"_id": "699d1e7a4e37ec6dfa1bc5ee", "user": {"_id": "6793f65033629a5fa8ae47b5", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/h11aIy3Yuw0kLCil5yeOt.png", "isPro": false, "fullname": "Hokin Deng", "user": "Hokin", "type": "user"}, "name": "Hokin Deng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-24T09:49:58.948Z", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/6039478ab3ecf716b1a5fd4d/IjK1EcVGF8x-SG3ymPI6T.mp4"], "publishedAt": "2026-02-23T18:59:41.000Z", "submittedOnDailyAt": "2026-02-24T01:14:31.428Z", "title": "A Very Big Video Reasoning Suite", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored. Video reasoning grounds intelligence in spatiotemporally consistent visual environments that go beyond what text can naturally capture, enabling intuitive reasoning over spatiotemporal structure such as continuity, interaction, and causality. However, systematically studying video reasoning and its scaling behavior is hindered by the lack of large-scale training data. To address this gap, we introduce the Very Big Video Reasoning (VBVR) Dataset, an unprecedentedly large-scale resource spanning 200 curated reasoning tasks following a principled taxonomy and over one million video clips, approximately three orders of magnitude larger than existing datasets. We further present VBVR-Bench, a verifiable evaluation framework that moves beyond model-based judging by incorporating rule-based, human-aligned scorers, enabling reproducible and interpretable diagnosis of video reasoning capabilities. Leveraging the VBVR suite, we conduct one of the first large-scale scaling studies of video reasoning and observe early signs of emergent generalization to unseen reasoning tasks. Together, VBVR lays a foundation for the next stage of research in generalizable video reasoning. The data, benchmark toolkit, and models are publicly available at https://video-reason.com/ .", "upvotes": 302, "discussionId": "699d1e7b4e37ec6dfa1bc5ef", "projectPage": "https://video-reason.com/", "ai_summary": "A large-scale video reasoning dataset and benchmark are introduced to study video intelligence capabilities beyond visual quality, enabling systematic analysis of spatiotemporal reasoning and generalization across diverse tasks.", "ai_keywords": ["video reasoning", "spatiotemporal consistency", "emergent generalization", "video reasoning benchmark", "video reasoning dataset"], "organization": {"_id": "6986a6f58d72821326efbfbb", "name": "Video-Reason", "fullname": "Video-Reason", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6793f65033629a5fa8ae47b5/7JFt2ReogqVi_udM_OHWG.jpeg"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-23T13:59:41.000Z", "title": "A Very Big Video Reasoning Suite", "summary": "Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored. Video reasoning grounds intelligence in spatiotemporally consistent visual environments that go beyond what text can naturally capture, enabling intuitive reasoning over spatiotemporal structure such as continuity, interaction, and causality. However, systematically studying video reasoning and its scaling behavior is hindered by the lack of large-scale training data. To address this gap, we introduce the Very Big Video Reasoning (VBVR) Dataset, an unprecedentedly large-scale resource spanning 200 curated reasoning tasks following a principled taxonomy and over one million video clips, approximately three orders of magnitude larger than existing datasets. We further present VBVR-Bench, a verifiable evaluation framework that moves beyond model-based judging by incorporating rule-based, human-aligned scorers, enabling reproducible and interpretable diagnosis of video reasoning capabilities. Leveraging the VBVR suite, we conduct one of the first large-scale scaling studies of video reasoning and observe early signs of emergent generalization to unseen reasoning tasks. Together, VBVR lays a foundation for the next stage of research in generalizable video reasoning. The data, benchmark toolkit, and models are publicly available at https://video-reason.com/ .", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/6039478ab3ecf716b1a5fd4d/IjK1EcVGF8x-SG3ymPI6T.mp4"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.20159.png", "numComments": 0, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 238, "isUserFollowing": false}, "organization": {"_id": "6986a6f58d72821326efbfbb", "name": "Video-Reason", "fullname": "Video-Reason", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6793f65033629a5fa8ae47b5/7JFt2ReogqVi_udM_OHWG.jpeg"}, "isAuthorParticipating": false}, {"paper": {"id": "2602.05400", "authors": [{"_id": "698b396b1b2dc6b37d61b4be", "user": {"_id": "66968099c952e09a4cb29f78", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66968099c952e09a4cb29f78/n90NI2R3E9_RqCyMjDCQF.webp", "isPro": false, "fullname": "Wang", "user": "Steven-Shaobo", "type": "user"}, "name": "Shaobo Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:16:57.815Z", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4bf", "user": {"_id": "67e617d4470f96a302734e16", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/QHrYmNlTRxKR1KRS50pkf.png", "isPro": false, "fullname": "Xuan Ouyang", "user": "YoungXuan", "type": "user"}, "name": "Xuan Ouyang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:16:55.631Z", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c0", "user": {"_id": "6518a144a28f86d3e9e67c34", "avatarUrl": "/avatars/f2aed39e971cffe6c9d0b9c2f7a0df70.svg", "isPro": false, "fullname": "Tianyi Xu", "user": "tianyi0216", "type": "user"}, "name": "Tianyi Xu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:16:53.605Z", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c1", "name": "Yuzheng Hu", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c2", "name": "Jialin Liu", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c3", "name": "Guo Chen", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c4", "name": "Tianyu Zhang", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c5", "name": "Junhao Zheng", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c6", "name": "Kexin Yang", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c7", "name": "Xingzhang Ren", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c8", "name": "Dayiheng Liu", "hidden": false}, {"_id": "698b396b1b2dc6b37d61b4c9", "name": "Linfeng Zhang", "hidden": false}], "publishedAt": "2026-02-05T07:34:23.000Z", "submittedOnDailyAt": "2026-02-11T02:09:03.945Z", "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration", "submittedOnDailyBy": {"_id": "67e617d4470f96a302734e16", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/QHrYmNlTRxKR1KRS50pkf.png", "isPro": false, "fullname": "Xuan Ouyang", "user": "YoungXuan", "type": "user"}, "summary": "As high-quality public text approaches exhaustion, a phenomenon known as the Data Wall, pre-training is shifting from more tokens to better tokens. However, existing methods either rely on heuristic static filters that ignore training dynamics, or use dynamic yet optimizer-agnostic criteria based on raw gradients. We propose OPUS (Optimizer-induced Projected Utility Selection), a dynamic data selection framework that defines utility in the optimizer-induced update space. OPUS scores candidates by projecting their effective updates, shaped by modern optimizers, onto a target direction derived from a stable, in-distribution proxy. To ensure scalability, we employ Ghost technique with CountSketch for computational efficiency, and Boltzmann sampling for data diversity, incurring only 4.7\\% additional compute overhead. OPUS achieves remarkable results across diverse corpora, quality tiers, optimizers, and model scales. In pre-training of GPT-2 Large/XL on FineWeb and FineWeb-Edu with 30B tokens, OPUS outperforms industrial-level baselines and even full 200B-token training. Moreover, when combined with industrial-level static filters, OPUS further improves pre-training efficiency, even with lower-quality data. Furthermore, in continued pre-training of Qwen3-8B-Base on SciencePedia, OPUS achieves superior performance using only 0.5B tokens compared to full training with 3B tokens, demonstrating significant data efficiency gains in specialized domains.", "upvotes": 279, "discussionId": "698b396b1b2dc6b37d61b4ca", "ai_summary": "OPUS is a dynamic data selection framework that improves pre-training efficiency by scoring data candidates based on optimizer-induced update projections in a stable proxy-derived target space, achieving superior performance with reduced computational overhead.", "ai_keywords": ["data selection", "optimizer-induced update space", "effective updates", "stable in-distribution proxy", "Ghost technique", "CountSketch", "Boltzmann sampling", "pre-training", "GPT-2", "Qwen3-8B-Base", "FineWeb", "FineWeb-Edu", "SciencePedia"], "organization": {"_id": "64c8b5837fe12ecd0a7e92eb", "name": "Qwen", "fullname": "Qwen", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/620760a26e3b7210c2ff1943/-s1gyJfvbE1RgO5iBeNOi.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-05T02:34:23.000Z", "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration", "summary": "As high-quality public text approaches exhaustion, a phenomenon known as the Data Wall, pre-training is shifting from more tokens to better tokens. However, existing methods either rely on heuristic static filters that ignore training dynamics, or use dynamic yet optimizer-agnostic criteria based on raw gradients. We propose OPUS (Optimizer-induced Projected Utility Selection), a dynamic data selection framework that defines utility in the optimizer-induced update space. OPUS scores candidates by projecting their effective updates, shaped by modern optimizers, onto a target direction derived from a stable, in-distribution proxy. To ensure scalability, we employ Ghost technique with CountSketch for computational efficiency, and Boltzmann sampling for data diversity, incurring only 4.7\\% additional compute overhead. OPUS achieves remarkable results across diverse corpora, quality tiers, optimizers, and model scales. In pre-training of GPT-2 Large/XL on FineWeb and FineWeb-Edu with 30B tokens, OPUS outperforms industrial-level baselines and even full 200B-token training. Moreover, when combined with industrial-level static filters, OPUS further improves pre-training efficiency, even with lower-quality data. Furthermore, in continued pre-training of Qwen3-8B-Base on SciencePedia, OPUS achieves superior performance using only 0.5B tokens compared to full training with 3B tokens, demonstrating significant data efficiency gains in specialized domains.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.05400.png", "numComments": 2, "submittedBy": {"_id": "67e617d4470f96a302734e16", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/QHrYmNlTRxKR1KRS50pkf.png", "fullname": "Xuan Ouyang", "name": "YoungXuan", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 23, "isUserFollowing": false}, "organization": {"_id": "64c8b5837fe12ecd0a7e92eb", "name": "Qwen", "fullname": "Qwen", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/620760a26e3b7210c2ff1943/-s1gyJfvbE1RgO5iBeNOi.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.10388", "authors": [{"_id": "698d3bd265c0d15a6d16200e", "user": {"_id": "6951c555b519522f565dfd0c", "avatarUrl": "/avatars/9028d619483f359639ae7bfe4769da45.svg", "isPro": false, "fullname": "ZhongzhiLi", "user": "Zhongzhi1228", "type": "user"}, "name": "Zhongzhi Li", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:57:05.580Z", "hidden": false}, {"_id": "698d3bd265c0d15a6d16200f", "name": "Xuansheng Wu", "hidden": false}, {"_id": "698d3bd265c0d15a6d162010", "name": "Yijiang Li", "hidden": false}, {"_id": "698d3bd265c0d15a6d162011", "name": "Lijie Hu", "hidden": false}, {"_id": "698d3bd265c0d15a6d162012", "name": "Ninghao Liu", "hidden": false}], "publishedAt": "2026-02-11T00:23:13.000Z", "submittedOnDailyAt": "2026-02-16T02:31:34.708Z", "title": "Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs", "submittedOnDailyBy": {"_id": "6951c555b519522f565dfd0c", "avatarUrl": "/avatars/9028d619483f359639ae7bfe4769da45.svg", "isPro": false, "fullname": "ZhongzhiLi", "user": "Zhongzhi1228", "type": "user"}, "summary": "The diversity of post-training data is critical for effective downstream performance in large language models (LLMs). Many existing approaches to constructing post-training data quantify diversity using text-based metrics that capture linguistic variation, but such metrics provide only weak signals for the task-relevant features that determine downstream performance. In this work, we introduce Feature Activation Coverage (FAC) which measures data diversity in an interpretable feature space. Building upon this metric, we further propose a diversity-driven data synthesis framework, named FAC Synthesis, that first uses a sparse autoencoder to identify missing features from a seed dataset, and then generates synthetic samples that explicitly reflect these features. Experiments show that our approach consistently improves both data diversity and downstream performance on various tasks, including instruction following, toxicity detection, reward modeling, and behavior steering. Interestingly, we identify a shared, interpretable feature space across model families (i.e., LLaMA, Mistral, and Qwen), enabling cross-model knowledge transfer. Our work provides a solid and practical methodology for exploring data-centric optimization of LLMs.", "upvotes": 200, "discussionId": "698d3bd265c0d15a6d162013", "projectPage": "https://website-sigma-three-35.vercel.app/", "githubRepo": "https://github.com/Zhongzhi660/FAC-Synthesis", "githubRepoAddedBy": "user", "ai_summary": "Feature Activation Coverage measures data diversity in an interpretable feature space and enables diversity-driven data synthesis that improves downstream performance across multiple language model architectures.", "ai_keywords": ["Feature Activation Coverage", "sparse autoencoder", "data diversity", "downstream performance", "instruction following", "toxicity detection", "reward modeling", "behavior steering", "cross-model knowledge transfer", "data-centric optimization"], "githubStars": 52, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-10T19:23:13.000Z", "title": "Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs", "summary": "The diversity of post-training data is critical for effective downstream performance in large language models (LLMs). Many existing approaches to constructing post-training data quantify diversity using text-based metrics that capture linguistic variation, but such metrics provide only weak signals for the task-relevant features that determine downstream performance. In this work, we introduce Feature Activation Coverage (FAC) which measures data diversity in an interpretable feature space. Building upon this metric, we further propose a diversity-driven data synthesis framework, named FAC Synthesis, that first uses a sparse autoencoder to identify missing features from a seed dataset, and then generates synthetic samples that explicitly reflect these features. Experiments show that our approach consistently improves both data diversity and downstream performance on various tasks, including instruction following, toxicity detection, reward modeling, and behavior steering. Interestingly, we identify a shared, interpretable feature space across model families (i.e., LLaMA, Mistral, and Qwen), enabling cross-model knowledge transfer. Our work provides a solid and practical methodology for exploring data-centric optimization of LLMs.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.10388.png", "numComments": 2, "submittedBy": {"_id": "6951c555b519522f565dfd0c", "avatarUrl": "/avatars/9028d619483f359639ae7bfe4769da45.svg", "fullname": "ZhongzhiLi", "name": "Zhongzhi1228", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "isUserFollowing": false}, "isAuthorParticipating": true}, {"paper": {"id": "2602.04705", "authors": [{"_id": "698424a7e34659da7e1f4e6f", "name": "Haifeng Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e70", "name": "Hua Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e71", "name": "Tian Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e72", "name": "Yu Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4e73", "name": "Jing Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e74", "name": "Dianhai Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e75", "name": "Yanjun Ma", "hidden": false}, {"_id": "698424a7e34659da7e1f4e76", "name": "Jingzhou He", "hidden": false}, {"_id": "698424a7e34659da7e1f4e77", "name": "Zhongjun He", "hidden": false}, {"_id": "698424a7e34659da7e1f4e78", "name": "Dou Hong", "hidden": false}, {"_id": "698424a7e34659da7e1f4e79", "name": "Qiwen Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7a", "name": "Shuohuan Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7b", "user": {"_id": "62cd9632342b1d5dab8df4c3", "avatarUrl": "/avatars/9080d20bb57a05a1eeb6800eba886cf9.svg", "isPro": false, "fullname": "Junyuan Shang", "user": "sjy1203", "type": "user"}, "name": "Junyuan Shang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:28.482Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7c", "user": {"_id": "67f37f78b36e82d366dedeec", "avatarUrl": "/avatars/678bb5891d5c2e80edc0799d2308a5d3.svg", "isPro": false, "fullname": "Max Zhenyu Zhang", "user": "max-zhenyu-zhang", "type": "user"}, "name": "Zhenyu Zhang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:03.972Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7d", "name": "Yuchen Ding", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7e", "name": "Jinle Zeng", "hidden": false}, {"_id": "698424a7e34659da7e1f4e7f", "name": "Jiabin Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e80", "name": "Liang Shen", "hidden": false}, {"_id": "698424a7e34659da7e1f4e81", "name": "Ruibiao Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4e82", "name": "Weichong Yin", "hidden": false}, {"_id": "698424a7e34659da7e1f4e83", "name": "Siyu Ding", "hidden": false}, {"_id": "698424a7e34659da7e1f4e84", "name": "Dai Dai", "hidden": false}, {"_id": "698424a7e34659da7e1f4e85", "name": "Shikun Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f4e86", "name": "Siqi Bao", "hidden": false}, {"_id": "698424a7e34659da7e1f4e87", "name": "Bolei He", "hidden": false}, {"_id": "698424a7e34659da7e1f4e88", "name": "Yan Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4e89", "name": "Zhenyu Jiao", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8a", "name": "Ruiqing Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8b", "name": "Zeyu Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8c", "name": "Qingqing Dang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8d", "name": "Kaipeng Deng", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8e", "name": "Jiajun Jiang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e8f", "name": "Enlei Gong", "hidden": false}, {"_id": "698424a7e34659da7e1f4e90", "name": "Guoxia Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e91", "name": "Yanlin Sha", "hidden": false}, {"_id": "698424a7e34659da7e1f4e92", "name": "Yi Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e93", "name": "Yehan Zheng", "hidden": false}, {"_id": "698424a7e34659da7e1f4e94", "name": "Weijian Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e95", "name": "Jiaxiang Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e96", "name": "Zengfeng Zeng", "hidden": false}, {"_id": "698424a7e34659da7e1f4e97", "name": "Yingqi Qu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e98", "name": "Zhongli Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4e99", "name": "Zhengkun Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9a", "name": "Xiyang Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9b", "name": "Zixiang Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9c", "name": "Xinchao Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9d", "name": "Zhengjie Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9e", "name": "Dong Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4e9f", "name": "Bingjin Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea0", "name": "Yue Chang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea1", "name": "Xing Yuan", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea2", "name": "Shiwei Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea3", "name": "Qiao Zhao", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea4", "name": "Xinzhe Ding", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea5", "name": "Shuangshuang Qiao", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea6", "name": "Baoshan Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea7", "name": "Bihong Tang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea8", "name": "Bin Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ea9", "name": "Bingquan Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eaa", "name": "Binhan Tang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eab", "name": "Binxiong Zheng", "hidden": false}, {"_id": "698424a7e34659da7e1f4eac", "name": "Bo Cui", "hidden": false}, {"_id": "698424a7e34659da7e1f4ead", "name": "Bo Ke", "hidden": false}, {"_id": "698424a7e34659da7e1f4eae", "name": "Bo Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eaf", "name": "Bowen Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb0", "name": "Boyan Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb1", "name": "Boyang Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb2", "name": "Caiji Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb3", "name": "Can Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb4", "name": "Chang Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb5", "name": "Chao Pang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb6", "name": "Chao Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb7", "name": "Chaoyi Yuan", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb8", "name": "Chen Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4eb9", "name": "Cheng Cui", "hidden": false}, {"_id": "698424a7e34659da7e1f4eba", "name": "Chenlin Yin", "hidden": false}, {"_id": "698424a7e34659da7e1f4ebb", "name": "Chun Gan", "hidden": false}, {"_id": "698424a7e34659da7e1f4ebc", "name": "Chunguang Chai", "hidden": false}, {"_id": "698424a7e34659da7e1f4ebd", "name": "Chuyu Fang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ebe", "name": "Cuiyun Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4ebf", "name": "Dan Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec0", "name": "Danlei Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec1", "name": "Danxiang Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec2", "name": "Dong Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec3", "name": "Dongbo Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec4", "name": "Dongdong Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec5", "name": "Dongdong Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec6", "name": "Dongxue Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec7", "name": "Fan Ding", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec8", "name": "Fan Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ec9", "name": "Fan Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4eca", "name": "Fan Mo", "hidden": false}, {"_id": "698424a7e34659da7e1f4ecb", "name": "Feisheng Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ecc", "name": "Fengwei Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ecd", "name": "Gangqiang Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ece", "name": "Gaofeng Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ecf", "name": "Gaopeng Yong", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed0", "name": "Gexiao Tian", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed1", "user": {"_id": "698419de94015f1e5eedacec", "avatarUrl": "/avatars/e80baa6f9efcd5e5d7cc9b93ac852c7b.svg", "isPro": false, "fullname": "Guan Wang", "user": "guanwcn", "type": "user"}, "name": "Guan Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:38.213Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed2", "name": "Guangchen Ni", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed3", "name": "Guangshuo Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed4", "name": "Guanzhong Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed5", "user": {"_id": "609cd5ab335f23cd2fa0f211", "avatarUrl": "/avatars/8331a7025a6aa4eabc5b6502bf8a0a63.svg", "isPro": false, "fullname": "Guihua Liu", "user": "LLLL", "type": "user"}, "name": "Guihua Liu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:31.029Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed6", "name": "Guishun Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed7", "name": "Haibin Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed8", "name": "Haijian Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ed9", "name": "Haipeng Ming", "hidden": false}, {"_id": "698424a7e34659da7e1f4eda", "name": "Haisu Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4edb", "name": "Haiyang Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4edc", "name": "Haiye Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f4edd", "name": "Han Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4ede", "name": "Hangting Lou", "hidden": false}, {"_id": "698424a7e34659da7e1f4edf", "name": "Hanwen Du", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee0", "name": "Hanzhi Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee1", "name": "Hao Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee2", "name": "Hao Du", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee3", "name": "Hao Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee4", "name": "Hao Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee5", "name": "Haochen Jiang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee6", "name": "Haodong Tian", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee7", "name": "Haoshuang Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee8", "name": "Haozhe Geng", "hidden": false}, {"_id": "698424a7e34659da7e1f4ee9", "name": "Heju Yin", "hidden": false}, {"_id": "698424a7e34659da7e1f4eea", "name": "Hong Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4eeb", "name": "Hongchen Xue", "hidden": false}, {"_id": "698424a7e34659da7e1f4eec", "name": "Hongen Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4eed", "name": "Honggeng Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4eee", "name": "Hongji Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4eef", "name": "Hongwei Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef0", "name": "Hongyang Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef1", "name": "Hongyuan Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef2", "name": "Hua Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef3", "name": "Huan Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef4", "name": "Huan Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef5", "name": "Huang He", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef6", "name": "Hui Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef7", "name": "Hui Zhong", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef8", "name": "Huibin Ruan", "hidden": false}, {"_id": "698424a7e34659da7e1f4ef9", "name": "Jiafeng Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4efa", "name": "Jiage Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4efb", "name": "Jiahao Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4efc", "name": "Jiahao Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4efd", "name": "Jiajie Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4efe", "name": "Jialin Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4eff", "name": "Jian Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f00", "name": "Jian Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f01", "name": "Jianfeng Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f02", "name": "Jianguang Jiang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f03", "name": "Jianhua Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f04", "name": "Jianye Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f05", "name": "Jiaodi Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f06", "name": "Jiarui Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f07", "name": "Jiawei Lv", "hidden": false}, {"_id": "698424a7e34659da7e1f4f08", "name": "Jiaxin Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f09", "name": "Jiaxuan Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0a", "name": "Jie Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0b", "name": "Jie Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0c", "name": "Jiefan Fang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0d", "name": "Jihan Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0e", "name": "Jihua Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f0f", "name": "Jing Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f10", "name": "Jing Qian", "hidden": false}, {"_id": "698424a7e34659da7e1f4f11", "name": "Jing Yan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f12", "name": "Jingdong Du", "hidden": false}, {"_id": "698424a7e34659da7e1f4f13", "name": "Jingdong Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f14", "name": "Jingjing Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f15", "name": "Jingyong Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f16", "name": "Jinheng Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f17", "name": "Jinjin Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f18", "name": "Jinliang Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f19", "name": "Jinlin Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1a", "name": "Jinnan Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1b", "name": "Jixiang Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1c", "name": "Jiyi Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1d", "name": "Jiyuan Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1e", "name": "Jun Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f1f", "name": "Jun Xia", "hidden": false}, {"_id": "698424a7e34659da7e1f4f20", "name": "Jun Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f21", "name": "Junda Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f22", "name": "Junhao Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f23", "name": "Junhong Xiang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f24", "name": "Junliang Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f25", "name": "Kai Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f26", "name": "Kailun Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f27", "name": "Kairan Su", "hidden": false}, {"_id": "698424a7e34659da7e1f4f28", "name": "Kang Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f29", "name": "Kangkang Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2a", "name": "Ke Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2b", "name": "Ke Wei", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2c", "name": "Kui Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2d", "name": "Kun Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2e", "name": "Kunbin Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f2f", "name": "Lei Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4f30", "name": "Lei Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4f31", "name": "Lei Wen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f32", "name": "Linghui Meng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f33", "user": {"_id": "641e69355c348064a8251471", "avatarUrl": "/avatars/acad3877df27ff44ea3921bb43e34d53.svg", "isPro": false, "fullname": "Linhao Yu", "user": "HasuerYu", "type": "user"}, "name": "Linhao Yu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:52:47.812Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4f34", "name": "Liping Ouyang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f35", "name": "Liwen Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f36", "user": {"_id": "65cf859f88d13d8128bb8545", "avatarUrl": "/avatars/aa18b993bd90d9c8a95913050cd955a8.svg", "isPro": false, "fullname": "Longbin Ji", "user": "robingg1", "type": "user"}, "name": "Longbin Ji", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:40.295Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4f37", "name": "Longzhi Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f38", "name": "Meng Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4f39", "name": "Meng Tian", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3a", "name": "Mengfei Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3b", "name": "Mengqi Zeng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3c", "name": "Mengyu Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3d", "name": "Ming Hong", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3e", "name": "Mingcheng Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f3f", "name": "Mingming Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f40", "name": "Mingxin Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4f41", "name": "Mingzhu Cai", "hidden": false}, {"_id": "698424a7e34659da7e1f4f42", "name": "Naibin Gu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f43", "name": "Nemin Qiu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f44", "name": "Nian Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f45", "name": "Peng Qiu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f46", "name": "Peng Zhao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f47", "name": "Pengyu Zou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f48", "name": "Qi Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f49", "name": "Qi Xin", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4a", "name": "Qian Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4b", "name": "Qiang Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4c", "name": "Qianhui Luo", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4d", "name": "Qianwei Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4e", "name": "Qianyue He", "hidden": false}, {"_id": "698424a7e34659da7e1f4f4f", "name": "Qifei Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f50", "name": "Qinrui Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f51", "name": "Qiwen Bao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f52", "name": "Quan Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f53", "name": "Quanxiang Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f54", "name": "Qunyi Xie", "hidden": false}, {"_id": "698424a7e34659da7e1f4f55", "name": "Rongrui Zhan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f56", "name": "Rufeng Dai", "hidden": false}, {"_id": "698424a7e34659da7e1f4f57", "name": "Rui Peng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f58", "name": "Ruian Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f59", "name": "Ruihao Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5a", "name": "Ruijie Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5b", "name": "Ruixi Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5c", "name": "Ruixuan Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5d", "name": "Runsheng Shi", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5e", "name": "Ruting Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f5f", "name": "Senbo Kang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f60", "name": "Shan Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f61", "name": "Shaofei Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f62", "name": "Shaotian Gong", "hidden": false}, {"_id": "698424a7e34659da7e1f4f63", "name": "Shenwei Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f64", "name": "Shifeng Zheng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f65", "name": "Shihao Guo", "hidden": false}, {"_id": "698424a7e34659da7e1f4f66", "name": "Shilong Fan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f67", "name": "Shiqin Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f68", "name": "Shiwei Gu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f69", "name": "Shixi Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6a", "name": "Shuai Yao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6b", "name": "Shuang Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6c", "name": "Shuangqiao Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6d", "name": "Shuhao Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6e", "name": "Shuwei He", "hidden": false}, {"_id": "698424a7e34659da7e1f4f6f", "name": "Shuwen Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f70", "user": {"_id": "62769a608483d8e9ecd9b4f8", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672799958233-62769a608483d8e9ecd9b4f8.jpeg", "isPro": false, "fullname": "Sijun He", "user": "sijunhe", "type": "user"}, "name": "Sijun He", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:33.392Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4f71", "user": {"_id": "64fada13d82fc6977d5e9c74", "avatarUrl": "/avatars/776bf1257154289e919716637770ef52.svg", "isPro": false, "fullname": "Siming Dai", "user": "DesmonDay", "type": "user"}, "name": "Siming Dai", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:52:50.302Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4f72", "name": "Siming Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f73", "name": "Siyi Long", "hidden": false}, {"_id": "698424a7e34659da7e1f4f74", "name": "Songhe Deng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f75", "name": "Suhui Dong", "hidden": false}, {"_id": "698424a7e34659da7e1f4f76", "name": "Suyin Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f77", "name": "Teng Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f78", "name": "Tianchan Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f79", "name": "Tianliang Lv", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7a", "user": {"_id": "67bbe929593452cc18877606", "avatarUrl": "/avatars/f50fd1cb35d628c26cf21ad0c95c55b1.svg", "isPro": false, "fullname": "tmyangcs", "user": "youngtimmy", "type": "user"}, "name": "Tianmeng Yang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:36.143Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7b", "name": "Tianyi Wei", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7c", "name": "Tiezhu Gao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7d", "name": "Ting Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7e", "name": "Ting Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f7f", "name": "Tingdan Luo", "hidden": false}, {"_id": "698424a7e34659da7e1f4f80", "name": "Wei He", "hidden": false}, {"_id": "698424a7e34659da7e1f4f81", "name": "Wei Luan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f82", "name": "Wei Yin", "hidden": false}, {"_id": "698424a7e34659da7e1f4f83", "name": "Wei Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f84", "name": "Wei Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4f85", "name": "Weibao Gong", "hidden": false}, {"_id": "698424a7e34659da7e1f4f86", "name": "Weibin Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4f87", "name": "Weicheng Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f88", "name": "Weichong Dang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f89", "name": "Weiguo Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8a", "name": "Weilong Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8b", "name": "Weiqi Tan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8c", "name": "Wen Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8d", "name": "Wenbin Chang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8e", "name": "Wenjing Du", "hidden": false}, {"_id": "698424a7e34659da7e1f4f8f", "name": "Wenlong Miao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f90", "name": "Wenpei Luo", "hidden": false}, {"_id": "698424a7e34659da7e1f4f91", "name": "Wenquan Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f92", "name": "Xi Shi", "hidden": false}, {"_id": "698424a7e34659da7e1f4f93", "name": "Xi Zhao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f94", "name": "Xiang Gao", "hidden": false}, {"_id": "698424a7e34659da7e1f4f95", "name": "Xiangguo Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f96", "name": "Xiangrui Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4f97", "name": "Xiangsen Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f98", "name": "Xiangzhe Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f99", "name": "Xianlong Luo", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9a", "name": "Xianying Ma", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9b", "name": "Xiao Tan", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9c", "name": "Xiaocong Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9d", "name": "Xiaofei Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9e", "name": "Xiaofeng Peng", "hidden": false}, {"_id": "698424a7e34659da7e1f4f9f", "name": "Xiaofeng Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa0", "name": "Xiaojian Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa1", "name": "Xiaolan Yuan", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa2", "name": "Xiaopeng Cui", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa3", "name": "Xiaotian Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa4", "name": "Xiaoxiong Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa5", "name": "Xiaoxu Fei", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa6", "name": "Xiaoxuan Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa7", "user": {"_id": "664395621b88258a527cd7d1", "avatarUrl": "/avatars/8489ccebe4fd1262679ba63a5cb50bb8.svg", "isPro": false, "fullname": "Kira", "user": "Kira-wang", "type": "user"}, "name": "Xiaoyu Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-05T10:53:25.774Z", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa8", "name": "Xiaoyu Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fa9", "name": "Xin Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4faa", "name": "Xin Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fab", "name": "Xinhui Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fac", "name": "Xinming Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fad", "name": "Xintong Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fae", "name": "Xinyi Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4faf", "name": "Xinyu Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb0", "name": "Xiuxian Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb1", "name": "XuanShi Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb2", "name": "Xue Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb3", "name": "Xueying Lv", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb4", "name": "Xuhong Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb5", "name": "Xulong Wei", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb6", "name": "Xuyi Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb7", "name": "Yabing Shi", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb8", "name": "Yafeng Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fb9", "name": "Yamei Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4fba", "name": "Yan Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fbb", "name": "Yanfu Cheng", "hidden": false}, {"_id": "698424a7e34659da7e1f4fbc", "name": "Yang Gao", "hidden": false}, {"_id": "698424a7e34659da7e1f4fbd", "name": "Yang Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fbe", "name": "Yang Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fbf", "name": "Yang Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc0", "name": "Yang Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc1", "name": "Yanlong Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc2", "name": "Yannian Fu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc3", "name": "Yanpeng Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc4", "name": "Yanzheng Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc5", "name": "Yao Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc6", "name": "Yaozong Shen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc7", "name": "Yaqian Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc8", "name": "Yehua Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fc9", "name": "Yekun Chai", "hidden": false}, {"_id": "698424a7e34659da7e1f4fca", "name": "Yesong Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fcb", "name": "Yi Song", "hidden": false}, {"_id": "698424a7e34659da7e1f4fcc", "name": "Yichen Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fcd", "name": "Yifei Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fce", "name": "Yifeng Guo", "hidden": false}, {"_id": "698424a7e34659da7e1f4fcf", "name": "Yifeng Kou", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd0", "name": "Yilong Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd1", "name": "Yilong Guo", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd2", "name": "Yiming Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd3", "name": "Ying Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd4", "name": "Ying Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd5", "name": "Yingsheng Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd6", "name": "Yingzhan Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd7", "name": "Yinqi Yang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd8", "name": "Yiran Xing", "hidden": false}, {"_id": "698424a7e34659da7e1f4fd9", "name": "Yishu Lei", "hidden": false}, {"_id": "698424a7e34659da7e1f4fda", "name": "Yixiang Tu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fdb", "name": "Yiyan Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4fdc", "name": "Yong Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fdd", "name": "Yonghua Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4fde", "name": "Yongqiang Ma", "hidden": false}, {"_id": "698424a7e34659da7e1f4fdf", "name": "Yongxing Dai", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe0", "name": "Yongyue Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe1", "name": "Yu Ran", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe2", "name": "Yu Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe3", "name": "Yu-Wen Michael Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe4", "name": "Yuang Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe5", "name": "Yuanle Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe6", "name": "Yuanyuan Zhou", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe7", "name": "Yubo Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe8", "name": "Yuchen Han", "hidden": false}, {"_id": "698424a7e34659da7e1f4fe9", "name": "Yucheng Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4fea", "name": "Yude Gao", "hidden": false}, {"_id": "698424a7e34659da7e1f4feb", "name": "Yuedong Luo", "hidden": false}, {"_id": "698424a7e34659da7e1f4fec", "name": "Yuehu Dong", "hidden": false}, {"_id": "698424a7e34659da7e1f4fed", "name": "Yufeng Hu", "hidden": false}, {"_id": "698424a7e34659da7e1f4fee", "name": "Yuhui Cao", "hidden": false}, {"_id": "698424a7e34659da7e1f4fef", "name": "Yuhui Yun", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff0", "name": "Yukun Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff1", "name": "Yukun Gao", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff2", "name": "Yukun Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff3", "name": "Yumeng Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff4", "name": "Yun Fan", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff5", "name": "Yun Ma", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff6", "name": "Yunfei Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff7", "name": "Yunshen Xie", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff8", "name": "Yuping Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ff9", "name": "Yuqin Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ffa", "name": "Yuqing Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ffb", "name": "Yurui Li", "hidden": false}, {"_id": "698424a7e34659da7e1f4ffc", "name": "Yuwen Wang", "hidden": false}, {"_id": "698424a7e34659da7e1f4ffd", "name": "Yuxiang Lu", "hidden": false}, {"_id": "698424a7e34659da7e1f4ffe", "name": "Zefeng Cai", "hidden": false}, {"_id": "698424a7e34659da7e1f4fff", "name": "Zelin Zhao", "hidden": false}, {"_id": "698424a7e34659da7e1f5000", "name": "Zelun Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f5001", "name": "Zenan Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f5002", "name": "Zezhao Dong", "hidden": false}, {"_id": "698424a7e34659da7e1f5003", "name": "Zhaowu Pan", "hidden": false}, {"_id": "698424a7e34659da7e1f5004", "name": "Zhaoyu Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f5005", "name": "Zhe Dong", "hidden": false}, {"_id": "698424a7e34659da7e1f5006", "name": "Zhe Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f5007", "name": "Zhen Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f5008", "name": "Zhengfan Wu", "hidden": false}, {"_id": "698424a7e34659da7e1f5009", "name": "Zhengrui Wei", "hidden": false}, {"_id": "698424a7e34659da7e1f500a", "name": "Zhengsheng Ning", "hidden": false}, {"_id": "698424a7e34659da7e1f500b", "name": "Zhenxing Li", "hidden": false}, {"_id": "698424a7e34659da7e1f500c", "name": "Zhenyu Li", "hidden": false}, {"_id": "698424a7e34659da7e1f500d", "name": "Zhenyu Qian", "hidden": false}, {"_id": "698424a7e34659da7e1f500e", "name": "Zhenyun Li", "hidden": false}, {"_id": "698424a7e34659da7e1f500f", "name": "Zhi Li", "hidden": false}, {"_id": "698424a7e34659da7e1f5010", "name": "Zhichao Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f5011", "name": "Zhicheng Dong", "hidden": false}, {"_id": "698424a7e34659da7e1f5012", "name": "Zhida Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f5013", "name": "Zhifan Feng", "hidden": false}, {"_id": "698424a7e34659da7e1f5014", "name": "Zhihao Deng", "hidden": false}, {"_id": "698424a7e34659da7e1f5015", "name": "Zhijin Yu", "hidden": false}, {"_id": "698424a7e34659da7e1f5016", "name": "Zhiyang Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f5017", "name": "Zhonghui Zheng", "hidden": false}, {"_id": "698424a7e34659da7e1f5018", "name": "Zhuangzhuang Guo", "hidden": false}, {"_id": "698424a7e34659da7e1f5019", "name": "Zhujun Zhang", "hidden": false}, {"_id": "698424a7e34659da7e1f501a", "name": "Zhuo Sun", "hidden": false}, {"_id": "698424a7e34659da7e1f501b", "name": "Zichang Liu", "hidden": false}, {"_id": "698424a7e34659da7e1f501c", "name": "Zihan Lin", "hidden": false}, {"_id": "698424a7e34659da7e1f501d", "name": "Zihao Huang", "hidden": false}, {"_id": "698424a7e34659da7e1f501e", "name": "Zihe Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f501f", "name": "Ziheng Zhao", "hidden": false}, {"_id": "698424a7e34659da7e1f5020", "name": "Ziping Chen", "hidden": false}, {"_id": "698424a7e34659da7e1f5021", "name": "Zixuan Zhu", "hidden": false}, {"_id": "698424a7e34659da7e1f5022", "name": "Ziyang Xu", "hidden": false}, {"_id": "698424a7e34659da7e1f5023", "name": "Ziyi Liang", "hidden": false}, {"_id": "698424a7e34659da7e1f5024", "name": "Ziyuan Gao", "hidden": false}], "publishedAt": "2026-02-04T16:18:15.000Z", "submittedOnDailyAt": "2026-02-05T02:34:05.150Z", "title": "ERNIE 5.0 Technical Report", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "In this report, we introduce ERNIE 5.0, a natively autoregressive foundation model desinged for unified multimodal understanding and generation across text, image, video, and audio. All modalities are trained from scratch under a unified next-group-of-tokens prediction objective, based on an ultra-sparse mixture-of-experts (MoE) architecture with modality-agnostic expert routing. To address practical challenges in large-scale deployment under diverse resource constraints, ERNIE 5.0 adopts a novel elastic training paradigm. Within a single pre-training run, the model learns a family of sub-models with varying depths, expert capacities, and routing sparsity, enabling flexible trade-offs among performance, model size, and inference latency in memory- or time-constrained scenarios. Moreover, we systematically address the challenges of scaling reinforcement learning to unified foundation models, thereby guaranteeing efficient and stable post-training under ultra-sparse MoE architectures and diverse multimodal settings. Extensive experiments demonstrate that ERNIE 5.0 achieves strong and balanced performance across multiple modalities. To the best of our knowledge, among publicly disclosed models, ERNIE 5.0 represents the first production-scale realization of a trillion-parameter unified autoregressive model that supports both multimodal understanding and generation. To facilitate further research, we present detailed visualizations of modality-agnostic expert routing in the unified model, alongside comprehensive empirical analysis of elastic training, aiming to offer profound insights to the community.", "upvotes": 198, "discussionId": "698424a7e34659da7e1f5025", "ai_summary": "ERNIE 5.0 is a production-scale trillion-parameter autoregressive model that unifies multimodal understanding and generation through sparse MoE architecture and elastic training.", "ai_keywords": ["autoregressive foundation model", "unified multimodal understanding", "unified next-group-of-tokens prediction objective", "mixture-of-experts", "modality-agnostic expert routing", "elastic training paradigm", "reinforcement learning", "sparse MoE architecture"], "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-04T11:18:15.000Z", "title": "ERNIE 5.0 Technical Report", "summary": "In this report, we introduce ERNIE 5.0, a natively autoregressive foundation model desinged for unified multimodal understanding and generation across text, image, video, and audio. All modalities are trained from scratch under a unified next-group-of-tokens prediction objective, based on an ultra-sparse mixture-of-experts (MoE) architecture with modality-agnostic expert routing. To address practical challenges in large-scale deployment under diverse resource constraints, ERNIE 5.0 adopts a novel elastic training paradigm. Within a single pre-training run, the model learns a family of sub-models with varying depths, expert capacities, and routing sparsity, enabling flexible trade-offs among performance, model size, and inference latency in memory- or time-constrained scenarios. Moreover, we systematically address the challenges of scaling reinforcement learning to unified foundation models, thereby guaranteeing efficient and stable post-training under ultra-sparse MoE architectures and diverse multimodal settings. Extensive experiments demonstrate that ERNIE 5.0 achieves strong and balanced performance across multiple modalities. To the best of our knowledge, among publicly disclosed models, ERNIE 5.0 represents the first production-scale realization of a trillion-parameter unified autoregressive model that supports both multimodal understanding and generation. To facilitate further research, we present detailed visualizations of modality-agnostic expert routing in the unified model, alongside comprehensive empirical analysis of elastic training, aiming to offer profound insights to the community.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.04705.png", "numComments": 2, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 228, "isUserFollowing": false}, "isAuthorParticipating": false}, {"paper": {"id": "2602.00919", "authors": [{"_id": "698186fdce18b1862809633b", "name": "I. Apanasevich", "hidden": false}, {"_id": "698186fdce18b1862809633c", "user": {"_id": "6718963e41abf87204dddaf5", "avatarUrl": "/avatars/05d4fdb330ccb52c53cb8f99f7497ab2.svg", "isPro": false, "fullname": "Mikhail Artemyev", "user": "Mixanik-43", "type": "user"}, "name": "M. Artemyev", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:34.142Z", "hidden": false}, {"_id": "698186fdce18b1862809633d", "name": "R. Babakyan", "hidden": false}, {"_id": "698186fdce18b1862809633e", "user": {"_id": "642694c721d5f027bec07c71", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642694c721d5f027bec07c71/0hZEaZ1kFxx4GEig29X_k.jpeg", "isPro": false, "fullname": "Polina Fedotova", "user": "2pd", "type": "user"}, "name": "P. Fedotova", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:41.710Z", "hidden": false}, {"_id": "698186fdce18b1862809633f", "name": "D. Grankin", "hidden": false}, {"_id": "698186fdce18b18628096340", "name": "E. Kupryashin", "hidden": false}, {"_id": "698186fdce18b18628096341", "user": {"_id": "662ace3c4f711ee4e1dcb790", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/R5dlha7Lpy5gCYFEAtr1L.jpeg", "isPro": false, "fullname": "Anastas Misailidi", "user": "kazzart", "type": "user"}, "name": "A. Misailidi", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:18.667Z", "hidden": false}, {"_id": "698186fdce18b18628096342", "user": {"_id": "66eb27551a537888d2121ddc", "avatarUrl": "/avatars/9c807b058c972c307a24d85efbfbd4ae.svg", "isPro": false, "fullname": "Daniil", "user": "Defgy", "type": "user"}, "name": "D. Nerus", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:33.667Z", "hidden": false}, {"_id": "698186fdce18b18628096343", "user": {"_id": "65e5e3df92de33440675b5d9", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65e5e3df92de33440675b5d9/UOVd40f_Htd5oMAa_L0cM.jpeg", "isPro": false, "fullname": "Alexander Nutalapati", "user": "AlexanderNutalapati", "type": "user"}, "name": "A. Nutalapati", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:20.959Z", "hidden": false}, {"_id": "698186fdce18b18628096344", "user": {"_id": "66b51b3ad4eea6ad6adfd611", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66b51b3ad4eea6ad6adfd611/SC_01wvlLjB0FFZdDVgAp.jpeg", "isPro": false, "fullname": "Gena Sidorov", "user": "haksorus", "type": "user"}, "name": "G. Sidorov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:41.584Z", "hidden": false}, {"_id": "698186fdce18b18628096345", "user": {"_id": "631ee99d2225f12fc0ef39f4", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662970571579-631ee99d2225f12fc0ef39f4.jpeg", "isPro": false, "fullname": "Ivan Efremov", "user": "4ku", "type": "user"}, "name": "I. Efremov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:36.696Z", "hidden": false}, {"_id": "698186fdce18b18628096346", "name": "M. Gerasyov", "hidden": false}, {"_id": "698186fdce18b18628096347", "name": "D. Pikurov", "hidden": false}, {"_id": "698186fdce18b18628096348", "name": "Y. Senchenko", "hidden": false}, {"_id": "698186fdce18b18628096349", "user": {"_id": "68113993ebc57966794e23d6", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Yc3GIqYZyO97lzZ9rX8OE.png", "isPro": false, "fullname": "Sergei Davidenko", "user": "Ant346", "type": "user"}, "name": "S. Davidenko", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:21.332Z", "hidden": false}, {"_id": "698186fdce18b1862809634a", "user": {"_id": "6981bbf47f758a03b9c46550", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/oTPe_MzIrDlCeRDvWWeLK.png", "isPro": false, "fullname": "Daniil Kulikov", "user": "KulikovDR", "type": "user"}, "name": "D. Kulikov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:46.458Z", "hidden": false}, {"_id": "698186fdce18b1862809634b", "name": "M. Sultankin", "hidden": false}, {"_id": "698186fdce18b1862809634c", "user": {"_id": "63518aa5a30fc3ba88ce51dd", "avatarUrl": "/avatars/2e6a8f4a3e76fcc1afe7e777d6b45e76.svg", "isPro": false, "fullname": "Kazybek A", "user": "wanjia", "type": "user"}, "name": "K. Askarbek", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:24.567Z", "hidden": false}, {"_id": "698186fdce18b1862809634d", "name": "O. Shamanin", "hidden": false}, {"_id": "698186fdce18b1862809634e", "name": "D. Statovoy", "hidden": false}, {"_id": "698186fdce18b1862809634f", "user": {"_id": "655f32a519fd101f14bf1fb0", "avatarUrl": "/avatars/adf2c494759ebe5a0d95c15631ac6312.svg", "isPro": false, "fullname": "Eduard", "user": "rjomba3000", "type": "user"}, "name": "E. Zalyaev", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:43.976Z", "hidden": false}, {"_id": "698186fdce18b18628096350", "user": {"_id": "67dd1714817478ae84b18981", "avatarUrl": "/avatars/1209da3d4c4de3f419ebea6845bb0ed6.svg", "isPro": false, "fullname": "Zorin Ilya", "user": "Zora244", "type": "user"}, "name": "I. Zorin", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:31.637Z", "hidden": false}, {"_id": "698186fdce18b18628096351", "name": "A. Letkin", "hidden": false}, {"_id": "698186fdce18b18628096352", "name": "E. Rusakov", "hidden": false}, {"_id": "698186fdce18b18628096353", "name": "A. Silchenko", "hidden": false}, {"_id": "698186fdce18b18628096354", "user": {"_id": "6981a821165e30591e1200e7", "avatarUrl": "/avatars/af72142b8ba8772926b247c31fc8e4c8.svg", "isPro": false, "fullname": "Vlad Vorobyov", "user": "GloomARK", "type": "user"}, "name": "V. Vorobyov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T13:58:18.218Z", "hidden": false}, {"_id": "698186fdce18b18628096355", "user": {"_id": "6901ce2d911da714e754422b", "avatarUrl": "/avatars/5ed8ce189ca92a04f7165751076ff446.svg", "isPro": false, "fullname": "SERGEI", "user": "sobolnikov", "type": "user"}, "name": "S. Sobolnikov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:28.887Z", "hidden": false}, {"_id": "698186fdce18b18628096356", "user": {"_id": "640e2ef88512ec51d7f34cd5", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640e2ef88512ec51d7f34cd5/Xl8UiprL-0SvOWHeoAFW1.jpeg", "isPro": false, "fullname": "Aleksey Postnikov", "user": "AlekseyPostnikov", "type": "user"}, "name": "A. Postnikov", "status": "claimed_verified", "statusLastChangedAt": "2026-02-03T10:03:39.139Z", "hidden": false}], "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/642694c721d5f027bec07c71/cz33CQXXE3--u2_mmgA5G.png"], "publishedAt": "2026-01-31T22:13:23.000Z", "submittedOnDailyAt": "2026-02-03T03:13:09.153Z", "title": "Green-VLA: Staged Vision-Language-Action Model for Generalist Robots", "submittedOnDailyBy": {"_id": "642694c721d5f027bec07c71", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642694c721d5f027bec07c71/0hZEaZ1kFxx4GEig29X_k.jpeg", "isPro": false, "fullname": "Polina Fedotova", "user": "2pd", "type": "user"}, "summary": "We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.", "upvotes": 173, "discussionId": "698186fece18b18628096357", "projectPage": "https://greenvla.github.io", "githubRepo": "https://github.com/greenvla/GreenVLA", "githubRepoAddedBy": "user", "ai_summary": "Green-VLA is a five-stage vision-language-action framework for real-world robot deployment that achieves generalization across different robot embodiments through multimodal training and reinforcement learning.", "ai_keywords": ["Vision-Language-Action", "multimodal grounding", "multi-embodiment pretraining", "embodiment-specific adaptation", "reinforcement-learning", "episode-progress prediction", "out-of-distribution detection", "joint-prediction-based guidance"], "githubStars": 24, "organization": {"_id": "6973998bee83f4964edef012", "name": "SberRoboticsCenter", "fullname": "Sber Robotics Center", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/642694c721d5f027bec07c71/LkuEJI3abphK4MFbq8tPf.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-01-31T17:13:23.000Z", "title": "Green-VLA: Staged Vision-Language-Action Model for Generalist Robots", "summary": "We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.", "mediaUrls": ["https://cdn-uploads.huggingface.co/production/uploads/642694c721d5f027bec07c71/cz33CQXXE3--u2_mmgA5G.png"], "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.00919.png", "numComments": 1, "submittedBy": {"_id": "642694c721d5f027bec07c71", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642694c721d5f027bec07c71/0hZEaZ1kFxx4GEig29X_k.jpeg", "fullname": "Polina Fedotova", "name": "2pd", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 3, "isUserFollowing": false}, "organization": {"_id": "6973998bee83f4964edef012", "name": "SberRoboticsCenter", "fullname": "Sber Robotics Center", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/642694c721d5f027bec07c71/LkuEJI3abphK4MFbq8tPf.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.09877", "authors": [{"_id": "698c7abdeb12ea7453916869", "user": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "isPro": false, "fullname": "Chenxu Wang", "user": "xunyoyo", "type": "user"}, "name": "Chenxu Wang", "status": "admin_assigned", "statusLastChangedAt": "2026-02-12T16:49:45.534Z", "hidden": false}, {"_id": "698c7abdeb12ea745391686a", "name": "Chaozhuo Li", "hidden": false}, {"_id": "698c7abdeb12ea745391686b", "name": "Songyang Liu", "hidden": false}, {"_id": "698c7abdeb12ea745391686c", "name": "Zejian Chen", "hidden": false}, {"_id": "698c7abdeb12ea745391686d", "name": "Jinyu Hou", "hidden": false}, {"_id": "698c7abdeb12ea745391686e", "name": "Ji Qi", "hidden": false}, {"_id": "698c7abdeb12ea745391686f", "name": "Rui Li", "hidden": false}, {"_id": "698c7abdeb12ea7453916870", "name": "Litian Zhang", "hidden": false}, {"_id": "698c7abdeb12ea7453916871", "name": "Qiwei Ye", "hidden": false}, {"_id": "698c7abdeb12ea7453916872", "name": "Zheng Liu", "hidden": false}, {"_id": "698c7abdeb12ea7453916873", "name": "Xu Chen", "hidden": false}, {"_id": "698c7abdeb12ea7453916874", "name": "Xi Zhang", "hidden": false}, {"_id": "698c7abdeb12ea7453916875", "name": "Philip S. Yu", "hidden": false}], "publishedAt": "2026-02-10T15:18:19.000Z", "submittedOnDailyAt": "2026-02-13T00:53:30.377Z", "title": "The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies", "submittedOnDailyBy": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "isPro": false, "fullname": "Chenxu Wang", "user": "xunyoyo", "type": "user"}, "summary": "The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.", "upvotes": 169, "discussionId": "698c7abdeb12ea7453916876", "ai_summary": "Multi-agent LLM systems face fundamental limitations in achieving continuous self-improvement while maintaining safety alignment due to inherent statistical blind spots in isolated evolution.", "ai_keywords": ["multi-agent systems", "large language models", "self-evolution", "safety alignment", "information-theoretic framework", "anthropic value distributions", "statistical blind spots", "self-evolving AI societies", "external oversight", "safety-preserving mechanisms"], "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-10T10:18:19.000Z", "title": "The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies", "summary": "The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.09877.png", "numComments": 2, "submittedBy": {"_id": "674006451d2302f6aa9b026d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/674006451d2302f6aa9b026d/szYYX1DSwjrkHCjp_b83S.png", "fullname": "Chenxu Wang", "name": "xunyoyo", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "isUserFollowing": false}, "isAuthorParticipating": true}, {"paper": {"id": "2602.09856", "authors": [{"_id": "698bf5b66052d3bed9630aa7", "user": {"_id": "64107c7df52d7eb22e062956", "avatarUrl": "/avatars/7b1cee9a2b8454fedfbd4c3d1df9865c.svg", "isPro": false, "fullname": "Yuhao Zheng", "user": "yhzheng1031", "type": "user"}, "name": "Yuhao Zheng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:28.241Z", "hidden": false}, {"_id": "698bf5b66052d3bed9630aa8", "name": "Li'an Zhong", "hidden": false}, {"_id": "698bf5b66052d3bed9630aa9", "user": {"_id": "6773bcaa675a971ddf1e81dd", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/a8VUwZYXd7O_mq_zFvXMh.png", "isPro": false, "fullname": "CokeWang", "user": "CokeWang", "type": "user"}, "name": "Yi Wang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:30.778Z", "hidden": false}, {"_id": "698bf5b66052d3bed9630aaa", "user": {"_id": "661de9defdbc9c247f159d15", "avatarUrl": "/avatars/38e21e78327cc908201122405c48f41b.svg", "isPro": false, "fullname": "Rui Dai", "user": "DerryD", "type": "user"}, "name": "Rui Dai", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:25.982Z", "hidden": false}, {"_id": "698bf5b66052d3bed9630aab", "name": "Kaikui Liu", "hidden": false}, {"_id": "698bf5b66052d3bed9630aac", "name": "Xiangxiang Chu", "hidden": false}, {"_id": "698bf5b66052d3bed9630aad", "name": "Linyuan Lv", "hidden": false}, {"_id": "698bf5b66052d3bed9630aae", "name": "Philip Torr", "hidden": false}, {"_id": "698bf5b66052d3bed9630aaf", "user": {"_id": "64440be5af034cdfd69ca3a7", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg", "isPro": false, "fullname": "Qinghong (Kevin) Lin", "user": "KevinQHLin", "type": "user"}, "name": "Kevin Qinghong Lin", "status": "claimed_verified", "statusLastChangedAt": "2026-02-11T11:14:23.397Z", "hidden": false}], "publishedAt": "2026-02-10T14:56:19.000Z", "submittedOnDailyAt": "2026-02-11T01:02:42.385Z", "title": "Code2World: A GUI World Model via Renderable Code Generation", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.", "upvotes": 168, "discussionId": "698bf5b66052d3bed9630ab0", "projectPage": "https://amap-ml.github.io/Code2World/", "githubRepo": "https://github.com/AMAP-ML/Code2World", "githubRepoAddedBy": "user", "ai_summary": "Code2World enables autonomous GUI agents to predict next visual states through renderable code generation, achieving high visual fidelity and structural controllability while improving navigation performance.", "ai_keywords": ["vision-language coder", "GUI World model", "action-conditioned prediction", "AndroidCode", "HTML generation", "visual-feedback revision mechanism", "SFT", "Render-Aware Reinforcement Learning", "visual semantic fidelity", "action consistency", "next UI prediction", "AndroidWorld navigation"], "githubStars": 131, "organization": {"_id": "67d11771890254196d3174e5", "name": "GD-ML", "fullname": "AMAP-ML", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-10T09:56:19.000Z", "title": "Code2World: A GUI World Model via Renderable Code Generation", "summary": "Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.09856.png", "numComments": 2, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 230, "isUserFollowing": false}, "organization": {"_id": "67d11771890254196d3174e5", "name": "GD-ML", "fullname": "AMAP-ML", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.23152", "authors": [{"_id": "69a106faa13deaa449448917", "name": "Jingxuan Wei", "hidden": false}, {"_id": "69a106faa13deaa449448918", "user": {"_id": "640f7083208821a59b74c757", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678735253848-640f7083208821a59b74c757.jpeg", "isPro": false, "fullname": "Siyuan Li", "user": "Lupin1998", "type": "user"}, "name": "Siyuan Li", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:47.703Z", "hidden": false}, {"_id": "69a106faa13deaa449448919", "name": "Yuhang Xu", "hidden": false}, {"_id": "69a106faa13deaa44944891a", "name": "Zheng Sun", "hidden": false}, {"_id": "69a106faa13deaa44944891b", "name": "Junjie Jiang", "hidden": false}, {"_id": "69a106faa13deaa44944891c", "name": "Hexuan Jin", "hidden": false}, {"_id": "69a106faa13deaa44944891d", "name": "Caijun Jia", "hidden": false}, {"_id": "69a106faa13deaa44944891e", "name": "Honghao He", "hidden": false}, {"_id": "69a106faa13deaa44944891f", "name": "Xinglong Xu", "hidden": false}, {"_id": "69a106faa13deaa449448920", "name": "Xi bai", "hidden": false}, {"_id": "69a106faa13deaa449448921", "name": "Chang Yu", "hidden": false}, {"_id": "69a106faa13deaa449448922", "name": "Yumou Liu", "hidden": false}, {"_id": "69a106faa13deaa449448923", "name": "Junnan Zhu", "hidden": false}, {"_id": "69a106faa13deaa449448924", "user": {"_id": "64ef522242da8d2a897d62da", "avatarUrl": "/avatars/03611010d247da66696ac8976d4d3ed3.svg", "isPro": false, "fullname": "xuanhe zhou", "user": "zhouxh19", "type": "user"}, "name": "Xuanhe Zhou", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:45.120Z", "hidden": false}, {"_id": "69a106faa13deaa449448925", "name": "Jintao Chen", "hidden": false}, {"_id": "69a106faa13deaa449448926", "name": "Xiaobin Hu", "hidden": false}, {"_id": "69a106faa13deaa449448927", "name": "Shancheng Pang", "hidden": false}, {"_id": "69a106faa13deaa449448928", "name": "Bihui Yu", "hidden": false}, {"_id": "69a106faa13deaa449448929", "name": "Ran He", "hidden": false}, {"_id": "69a106faa13deaa44944892a", "name": "Zhen Lei", "hidden": false}, {"_id": "69a106faa13deaa44944892b", "name": "Stan Z. Li", "hidden": false}, {"_id": "69a106faa13deaa44944892c", "name": "Conghui He", "hidden": false}, {"_id": "69a106faa13deaa44944892d", "name": "Shuicheng Yan", "hidden": false}, {"_id": "69a106faa13deaa44944892e", "user": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "isPro": false, "fullname": "Cheng Tan", "user": "chengtan9907", "type": "user"}, "name": "Cheng Tan", "status": "claimed_verified", "statusLastChangedAt": "2026-02-27T16:40:37.726Z", "hidden": false}], "publishedAt": "2026-02-26T16:15:55.000Z", "submittedOnDailyAt": "2026-02-27T00:24:05.560Z", "title": "The Trinity of Consistency as a Defining Principle for General World Models", "submittedOnDailyBy": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "isPro": false, "fullname": "Cheng Tan", "user": "chengtan9907", "type": "user"}, "summary": "The construction of World Models capable of learning, simulating, and reasoning about objective physical laws constitutes a foundational challenge in the pursuit of Artificial General Intelligence. Recent advancements represented by video generation models like Sora have demonstrated the potential of data-driven scaling laws to approximate physical dynamics, while the emerging Unified Multimodal Model (UMM) offers a promising architectural paradigm for integrating perception, language, and reasoning. Despite these advances, the field still lacks a principled theoretical framework that defines the essential properties requisite for a General World Model. In this paper, we propose that a World Model must be grounded in the Trinity of Consistency: Modal Consistency as the semantic interface, Spatial Consistency as the geometric basis, and Temporal Consistency as the causal engine. Through this tripartite lens, we systematically review the evolution of multimodal learning, revealing a trajectory from loosely coupled specialized modules toward unified architectures that enable the synergistic emergence of internal world simulators. To complement this conceptual framework, we introduce CoW-Bench, a benchmark centered on multi-frame reasoning and generation scenarios. CoW-Bench evaluates both video generation models and UMMs under a unified evaluation protocol. Our work establishes a principled pathway toward general world models, clarifying both the limitations of current systems and the architectural requirements for future progress.", "upvotes": 159, "discussionId": "69a106faa13deaa44944892f", "projectPage": "https://openraiser.github.io/CoW-Bench/", "githubRepo": "https://github.com/openraiser/awesome-world-model-evolution", "githubRepoAddedBy": "user", "ai_summary": "World Models require three consistency principles\u2014modal, spatial, and temporal\u2014for general artificial intelligence, with a proposed benchmark evaluating multimodal learning systems.", "ai_keywords": ["World Models", "video generation models", "Unified Multimodal Model", "multimodal learning", "multi-frame reasoning", "CoW-Bench", "modal consistency", "spatial consistency", "temporal consistency"], "githubStars": 15, "organization": {"_id": "66ce9d1f5e180b9b9c8e6f31", "name": "opendatalab", "fullname": "OpenDataLab", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/639c3afa7432f2f5d16b7296/yqxxBknyeqkGnYsjoaR4M.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-26T11:15:55.000Z", "title": "The Trinity of Consistency as a Defining Principle for General World Models", "summary": "The construction of World Models capable of learning, simulating, and reasoning about objective physical laws constitutes a foundational challenge in the pursuit of Artificial General Intelligence. Recent advancements represented by video generation models like Sora have demonstrated the potential of data-driven scaling laws to approximate physical dynamics, while the emerging Unified Multimodal Model (UMM) offers a promising architectural paradigm for integrating perception, language, and reasoning. Despite these advances, the field still lacks a principled theoretical framework that defines the essential properties requisite for a General World Model. In this paper, we propose that a World Model must be grounded in the Trinity of Consistency: Modal Consistency as the semantic interface, Spatial Consistency as the geometric basis, and Temporal Consistency as the causal engine. Through this tripartite lens, we systematically review the evolution of multimodal learning, revealing a trajectory from loosely coupled specialized modules toward unified architectures that enable the synergistic emergence of internal world simulators. To complement this conceptual framework, we introduce CoW-Bench, a benchmark centered on multi-frame reasoning and generation scenarios. CoW-Bench evaluates both video generation models and UMMs under a unified evaluation protocol. Our work establishes a principled pathway toward general world models, clarifying both the limitations of current systems and the architectural requirements for future progress.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.23152.png", "numComments": 3, "submittedBy": {"_id": "64be296a46cc3cdfbb057f7e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64be296a46cc3cdfbb057f7e/jSHeNY2AcPifCZzJyFhr4.jpeg", "fullname": "Cheng Tan", "name": "chengtan9907", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 3, "isUserFollowing": false}, "organization": {"_id": "66ce9d1f5e180b9b9c8e6f31", "name": "opendatalab", "fullname": "OpenDataLab", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/639c3afa7432f2f5d16b7296/yqxxBknyeqkGnYsjoaR4M.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.10693", "authors": [{"_id": "6992047b50fb2c0be47837f0", "user": {"_id": "6475ff9b4c9fb8a4bf1cde76", "avatarUrl": "/avatars/61cf82cd0e15c4618f5bd8b1f7d52f37.svg", "isPro": false, "fullname": "floyed shen", "user": "floyed", "type": "user"}, "name": "Guobin Shen", "status": "claimed_verified", "statusLastChangedAt": "2026-02-17T15:52:51.206Z", "hidden": false}, {"_id": "6992047b50fb2c0be47837f1", "user": {"_id": "63fc5b724c57549ad5e54558", "avatarUrl": "/avatars/1374c1e8969533dd7543959666f16d1a.svg", "isPro": false, "fullname": "Chenxiao Zhao", "user": "ChenShawn", "type": "user"}, "name": "Chenxiao Zhao", "status": "admin_assigned", "statusLastChangedAt": "2026-02-17T17:17:12.583Z", "hidden": false}, {"_id": "6992047b50fb2c0be47837f2", "user": {"_id": "655c43d6b426ec8f4b5e7652", "avatarUrl": "/avatars/ddcf9d1ef0e2dc1f564a56ba9153f24f.svg", "isPro": false, "fullname": "Xiang Cheng", "user": "FFFc2", "type": "user"}, "name": "Xiang Cheng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-17T15:52:57.697Z", "hidden": false}, {"_id": "6992047b50fb2c0be47837f3", "user": {"_id": "61f4c2e981c4d30f58140279", "avatarUrl": "/avatars/c4a69f6563c952354e33682e86045b14.svg", "isPro": false, "fullname": "HuangMeow", "user": "Luckyyy", "type": "user"}, "name": "Lei Huang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-23T09:46:50.954Z", "hidden": false}, {"_id": "6992047b50fb2c0be47837f4", "name": "Xing Yu", "hidden": false}], "publishedAt": "2026-02-11T09:48:08.000Z", "submittedOnDailyAt": "2026-02-23T03:29:14.259Z", "title": "VESPO: Variational Sequence-Level Soft Policy Optimization for Stable Off-Policy LLM Training", "submittedOnDailyBy": {"_id": "6475ff9b4c9fb8a4bf1cde76", "avatarUrl": "/avatars/61cf82cd0e15c4618f5bd8b1f7d52f37.svg", "isPro": false, "fullname": "floyed shen", "user": "floyed", "type": "user"}, "summary": "Training stability remains a central challenge in reinforcement learning (RL) for large language models (LLMs). Policy staleness, asynchronous training, and mismatches between training and inference engines all cause the behavior policy to diverge from the current policy, risking training collapse. Importance sampling provides a principled correction for this distribution shift but suffers from high variance; existing remedies such as token-level clipping and sequence-level normalization lack a unified theoretical foundation. We propose Variational sEquence-level Soft Policy Optimization (VESPO). By incorporating variance reduction into a variational formulation over proposal distributions, VESPO derives a closed-form reshaping kernel that operates directly on sequence-level importance weights without length normalization. Experiments on mathematical reasoning benchmarks show that VESPO maintains stable training under staleness ratios up to 64x and fully asynchronous execution, and delivers consistent gains across both dense and Mixture-of-Experts models. Code is available at https://github.com/FloyedShen/VESPO", "upvotes": 158, "discussionId": "6992047c50fb2c0be47837f5", "githubRepo": "https://github.com/FloyedShen/VESPO", "githubRepoAddedBy": "user", "ai_summary": "VESPO addresses training instability in LLM reinforcement learning by using variational formulation with variance reduction to correct policy divergence without length normalization.", "ai_keywords": ["reinforcement learning", "large language models", "policy staleness", "asynchronous training", "importance sampling", "variance reduction", "variational formulation", "proposal distributions", "sequence-level importance weights", "mathematical reasoning benchmarks", "Mixture-of-Experts models"], "githubStars": 14, "organization": {"_id": "68246a0a98117c02df67a547", "name": "rednote-hilab", "fullname": "rednote-hilab", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6807a1d6504547b3554b9c73/WgnnQDsz7FqnyTtv8mmRO.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-11T04:48:08.000Z", "title": "VESPO: Variational Sequence-Level Soft Policy Optimization for Stable Off-Policy LLM Training", "summary": "Training stability remains a central challenge in reinforcement learning (RL) for large language models (LLMs). Policy staleness, asynchronous training, and mismatches between training and inference engines all cause the behavior policy to diverge from the current policy, risking training collapse. Importance sampling provides a principled correction for this distribution shift but suffers from high variance; existing remedies such as token-level clipping and sequence-level normalization lack a unified theoretical foundation. We propose Variational sEquence-level Soft Policy Optimization (VESPO). By incorporating variance reduction into a variational formulation over proposal distributions, VESPO derives a closed-form reshaping kernel that operates directly on sequence-level importance weights without length normalization. Experiments on mathematical reasoning benchmarks show that VESPO maintains stable training under staleness ratios up to 64x and fully asynchronous execution, and delivers consistent gains across both dense and Mixture-of-Experts models. Code is available at https://github.com/FloyedShen/VESPO", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.10693.png", "numComments": 2, "submittedBy": {"_id": "6475ff9b4c9fb8a4bf1cde76", "avatarUrl": "/avatars/61cf82cd0e15c4618f5bd8b1f7d52f37.svg", "fullname": "floyed shen", "name": "floyed", "type": "user", "isPro": false, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 1, "isUserFollowing": false}, "organization": {"_id": "68246a0a98117c02df67a547", "name": "rednote-hilab", "fullname": "rednote-hilab", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6807a1d6504547b3554b9c73/WgnnQDsz7FqnyTtv8mmRO.png"}, "isAuthorParticipating": true}, {"paper": {"id": "2602.10604", "authors": [{"_id": "698d417065c0d15a6d162026", "name": "Ailin Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162027", "name": "Ang Li", "hidden": false}, {"_id": "698d417065c0d15a6d162028", "name": "Aobo Kong", "hidden": false}, {"_id": "698d417065c0d15a6d162029", "name": "Bin Wang", "hidden": false}, {"_id": "698d417065c0d15a6d16202a", "name": "Binxing Jiao", "hidden": false}, {"_id": "698d417065c0d15a6d16202b", "name": "Bo Dong", "hidden": false}, {"_id": "698d417065c0d15a6d16202c", "name": "Bojun Wang", "hidden": false}, {"_id": "698d417065c0d15a6d16202d", "name": "Boyu Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16202e", "name": "Brian Li", "hidden": false}, {"_id": "698d417065c0d15a6d16202f", "name": "Buyun Ma", "hidden": false}, {"_id": "698d417065c0d15a6d162030", "name": "Chang Su", "hidden": false}, {"_id": "698d417065c0d15a6d162031", "name": "Changxin Miao", "hidden": false}, {"_id": "698d417065c0d15a6d162032", "name": "Changyi Wan", "hidden": false}, {"_id": "698d417065c0d15a6d162033", "name": "Chao Lou", "hidden": false}, {"_id": "698d417065c0d15a6d162034", "name": "Chen Hu", "hidden": false}, {"_id": "698d417065c0d15a6d162035", "name": "Chen Xu", "hidden": false}, {"_id": "698d417065c0d15a6d162036", "name": "Chenfeng Yu", "hidden": false}, {"_id": "698d417065c0d15a6d162037", "name": "Chengting Feng", "hidden": false}, {"_id": "698d417065c0d15a6d162038", "name": "Chengyuan Yao", "hidden": false}, {"_id": "698d417065c0d15a6d162039", "name": "Chunrui Han", "hidden": false}, {"_id": "698d417065c0d15a6d16203a", "name": "Dan Ma", "hidden": false}, {"_id": "698d417065c0d15a6d16203b", "name": "Dapeng Shi", "hidden": false}, {"_id": "698d417065c0d15a6d16203c", "name": "Daxin Jiang", "hidden": false}, {"_id": "698d417065c0d15a6d16203d", "name": "Dehua Ma", "hidden": false}, {"_id": "698d417065c0d15a6d16203e", "name": "Deshan Sun", "hidden": false}, {"_id": "698d417065c0d15a6d16203f", "name": "Di Qi", "hidden": false}, {"_id": "698d417065c0d15a6d162040", "name": "Enle Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162041", "name": "Fajie Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d162042", "name": "Fanqi Wan", "hidden": false}, {"_id": "698d417065c0d15a6d162043", "name": "Guanzhe Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162044", "name": "Gulin Yan", "hidden": false}, {"_id": "698d417065c0d15a6d162045", "name": "Guoliang Cao", "hidden": false}, {"_id": "698d417065c0d15a6d162046", "name": "Guopeng Li", "hidden": false}, {"_id": "698d417065c0d15a6d162047", "name": "Han Cheng", "hidden": false}, {"_id": "698d417065c0d15a6d162048", "name": "Hangyu Guo", "hidden": false}, {"_id": "698d417065c0d15a6d162049", "user": {"_id": "64b7874b9f5987572ca28461", "avatarUrl": "/avatars/d24ee0a6329ff93936aa7829481e2046.svg", "isPro": false, "fullname": "hanshanzhang", "user": "brain-zhang", "type": "user"}, "name": "Hanshan Zhang", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:52.602Z", "hidden": false}, {"_id": "698d417065c0d15a6d16204a", "name": "Hao Nie", "hidden": false}, {"_id": "698d417065c0d15a6d16204b", "name": "Haonan Jia", "hidden": false}, {"_id": "698d417065c0d15a6d16204c", "name": "Haoran Lv", "hidden": false}, {"_id": "698d417065c0d15a6d16204d", "name": "Hebin Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d16204e", "name": "Hekun Lv", "hidden": false}, {"_id": "698d417065c0d15a6d16204f", "name": "Heng Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162050", "name": "Heung-Yeung Shum", "hidden": false}, {"_id": "698d417065c0d15a6d162051", "name": "Hongbo Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162052", "name": "Hongbo Peng", "hidden": false}, {"_id": "698d417065c0d15a6d162053", "name": "Hongyu Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d162054", "name": "Hongyuan Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162055", "name": "Houyong Chen", "hidden": false}, {"_id": "698d417065c0d15a6d162056", "name": "Huangxi Zhu", "hidden": false}, {"_id": "698d417065c0d15a6d162057", "name": "Huimin Wu", "hidden": false}, {"_id": "698d417065c0d15a6d162058", "name": "Huiyong Guo", "hidden": false}, {"_id": "698d417065c0d15a6d162059", "name": "Jia Wang", "hidden": false}, {"_id": "698d417065c0d15a6d16205a", "name": "Jian Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d16205b", "name": "Jianjian Sun", "hidden": false}, {"_id": "698d417065c0d15a6d16205c", "name": "Jiaoren Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16205d", "name": "Jiaran Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d16205e", "name": "Jiashu Lv", "hidden": false}, {"_id": "698d417065c0d15a6d16205f", "name": "Jiashuo Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162060", "name": "Jiayi Fu", "hidden": false}, {"_id": "698d417065c0d15a6d162061", "name": "Jiayu Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162062", "name": "Jie Cheng", "hidden": false}, {"_id": "698d417065c0d15a6d162063", "name": "Jie Luo", "hidden": false}, {"_id": "698d417065c0d15a6d162064", "name": "Jie Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162065", "name": "Jie Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d162066", "name": "Jieyi Hou", "hidden": false}, {"_id": "698d417065c0d15a6d162067", "name": "Jing Bai", "hidden": false}, {"_id": "698d417065c0d15a6d162068", "user": {"_id": "625026b7d2d191ac43320c5e", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/625026b7d2d191ac43320c5e/2ExzHlZ-Bk8SQMyBjeY6N.jpeg", "isPro": false, "fullname": "Jingcheng Hu", "user": "reign12", "type": "user"}, "name": "Jingcheng Hu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:28:37.335Z", "hidden": false}, {"_id": "698d417065c0d15a6d162069", "name": "Jingjing Xie", "hidden": false}, {"_id": "698d417065c0d15a6d16206a", "name": "Jingwei Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16206b", "name": "Jingyang Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d16206c", "name": "Jishi Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d16206d", "name": "Junfeng Liu", "hidden": false}, {"_id": "698d417065c0d15a6d16206e", "name": "Junzhe Lin", "hidden": false}, {"_id": "698d417065c0d15a6d16206f", "name": "Ka Man Lo", "hidden": false}, {"_id": "698d417065c0d15a6d162070", "name": "Kai Liang", "hidden": false}, {"_id": "698d417065c0d15a6d162071", "name": "Kaibo Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162072", "name": "Kaijun Tan", "hidden": false}, {"_id": "698d417065c0d15a6d162073", "user": {"_id": "66668c591964b6188ee310c2", "avatarUrl": "/avatars/8a8265073dbacbb2c7139b1c8da3e055.svg", "isPro": false, "fullname": "Kaiwen Yan", "user": "linrany", "type": "user"}, "name": "Kaiwen Yan", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:58.524Z", "hidden": false}, {"_id": "698d417065c0d15a6d162074", "name": "Kaixiang Li", "hidden": false}, {"_id": "698d417065c0d15a6d162075", "name": "Kang An", "hidden": false}, {"_id": "698d417065c0d15a6d162076", "user": {"_id": "658a810665df457a55ffcd04", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/658a810665df457a55ffcd04/6Pe0mNao4mlWLIjYEoWv5.jpeg", "isPro": false, "fullname": "Linkangheng", "user": "Kangheng", "type": "user"}, "name": "Kangheng Lin", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:56.339Z", "hidden": false}, {"_id": "698d417065c0d15a6d162077", "name": "Lei Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162078", "name": "Liang Lv", "hidden": false}, {"_id": "698d417065c0d15a6d162079", "name": "Liang Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d16207a", "name": "Liangyu Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16207b", "name": "Lieyu Shi", "hidden": false}, {"_id": "698d417065c0d15a6d16207c", "name": "Liguo Tan", "hidden": false}, {"_id": "698d417065c0d15a6d16207d", "name": "Lin Lin", "hidden": false}, {"_id": "698d417065c0d15a6d16207e", "name": "Lina Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16207f", "name": "Luck Ma", "hidden": false}, {"_id": "698d417065c0d15a6d162080", "name": "Mengqiang Ren", "hidden": false}, {"_id": "698d417065c0d15a6d162081", "name": "Michael Li", "hidden": false}, {"_id": "698d417065c0d15a6d162082", "name": "Ming Li", "hidden": false}, {"_id": "698d417065c0d15a6d162083", "name": "Mingliang Li", "hidden": false}, {"_id": "698d417065c0d15a6d162084", "name": "Mingming Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d162085", "name": "Mingrui Chen", "hidden": false}, {"_id": "698d417065c0d15a6d162086", "name": "Mitt Huang", "hidden": false}, {"_id": "698d417065c0d15a6d162087", "name": "Na Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162088", "name": "Peng Liu", "hidden": false}, {"_id": "698d417065c0d15a6d162089", "name": "Qi Han", "hidden": false}, {"_id": "698d417065c0d15a6d16208a", "name": "Qian Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d16208b", "name": "Qinglin He", "hidden": false}, {"_id": "698d417065c0d15a6d16208c", "name": "Qinxin Du", "hidden": false}, {"_id": "698d417065c0d15a6d16208d", "name": "Qiuping Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16208e", "name": "Quan Sun", "hidden": false}, {"_id": "698d417065c0d15a6d16208f", "name": "Rongqiu Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162090", "name": "Ruihang Miao", "hidden": false}, {"_id": "698d417065c0d15a6d162091", "name": "Ruixin Han", "hidden": false}, {"_id": "698d417065c0d15a6d162092", "name": "Ruosi Wan", "hidden": false}, {"_id": "698d417065c0d15a6d162093", "name": "Ruyan Guo", "hidden": false}, {"_id": "698d417065c0d15a6d162094", "name": "Shan Wang", "hidden": false}, {"_id": "698d417065c0d15a6d162095", "name": "Shaoliang Pang", "hidden": false}, {"_id": "698d417065c0d15a6d162096", "name": "Shaowen Yang", "hidden": false}, {"_id": "698d417065c0d15a6d162097", "name": "Shengjie Fan", "hidden": false}, {"_id": "698d417065c0d15a6d162098", "name": "Shijie Shang", "hidden": false}, {"_id": "698d417065c0d15a6d162099", "name": "Shiliang Yang", "hidden": false}, {"_id": "698d417065c0d15a6d16209a", "name": "Shiwei Li", "hidden": false}, {"_id": "698d417065c0d15a6d16209b", "name": "Shuangshuang Tian", "hidden": false}, {"_id": "698d417065c0d15a6d16209c", "name": "Siqi Liu", "hidden": false}, {"_id": "698d417065c0d15a6d16209d", "name": "Siye Wu", "hidden": false}, {"_id": "698d417065c0d15a6d16209e", "name": "Siyu Chen", "hidden": false}, {"_id": "698d417065c0d15a6d16209f", "name": "Song Yuan", "hidden": false}, {"_id": "698d417065c0d15a6d1620a0", "name": "Tiancheng Cao", "hidden": false}, {"_id": "698d417065c0d15a6d1620a1", "name": "Tianchi Yue", "hidden": false}, {"_id": "698d417065c0d15a6d1620a2", "name": "Tianhao Cheng", "hidden": false}, {"_id": "698d417065c0d15a6d1620a3", "name": "Tianning Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620a4", "name": "Tingdan Luo", "hidden": false}, {"_id": "698d417065c0d15a6d1620a5", "name": "Wang You", "hidden": false}, {"_id": "698d417065c0d15a6d1620a6", "name": "Wei Ji", "hidden": false}, {"_id": "698d417065c0d15a6d1620a7", "name": "Wei Yuan", "hidden": false}, {"_id": "698d417065c0d15a6d1620a8", "name": "Wei Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620a9", "name": "Weibo Wu", "hidden": false}, {"_id": "698d417065c0d15a6d1620aa", "user": {"_id": "6657620ea496f7fcb67c3871", "avatarUrl": "/avatars/54fef1c835e6f6b478652d438a140d45.svg", "isPro": false, "fullname": "xieweihao", "user": "chalengr", "type": "user"}, "name": "Weihao Xie", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:48.216Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620ab", "name": "Wen Sun", "hidden": false}, {"_id": "698d417065c0d15a6d1620ac", "name": "Wenjin Deng", "hidden": false}, {"_id": "698d417065c0d15a6d1620ad", "user": {"_id": "650c04795510464e85b47470", "avatarUrl": "/avatars/98c194e77826b928c49659849f466dad.svg", "isPro": false, "fullname": "wen", "user": "zhengwenzhen", "type": "user"}, "name": "Wenzhen Zheng", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:45.930Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620ae", "name": "Wuxun Xie", "hidden": false}, {"_id": "698d417065c0d15a6d1620af", "name": "Xiangfeng Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b0", "name": "Xiangwen Kong", "hidden": false}, {"_id": "698d417065c0d15a6d1620b1", "name": "Xiangyu Liu", "hidden": false}, {"_id": "698d417065c0d15a6d1620b2", "name": "Xiangyu Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b3", "name": "Xiaobo Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b4", "name": "Xiaojia Liu", "hidden": false}, {"_id": "698d417065c0d15a6d1620b5", "name": "Xiaolan Yuan", "hidden": false}, {"_id": "698d417065c0d15a6d1620b6", "name": "Xiaoran Jiao", "hidden": false}, {"_id": "698d417065c0d15a6d1620b7", "name": "Xiaoxiao Ren", "hidden": false}, {"_id": "698d417065c0d15a6d1620b8", "name": "Xiaoyun Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620b9", "name": "Xin Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620ba", "name": "Xin Liu", "hidden": false}, {"_id": "698d417065c0d15a6d1620bb", "name": "Xin Wu", "hidden": false}, {"_id": "698d417065c0d15a6d1620bc", "name": "Xing Chen", "hidden": false}, {"_id": "698d417065c0d15a6d1620bd", "name": "Xingping Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620be", "name": "Xinran Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620bf", "name": "Xu Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620c0", "user": {"_id": "64ec5b64bfb2aa06a46ff2d6", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/Lgl55OtDWa0tzRI2ShpUe.jpeg", "isPro": false, "fullname": "xuan he", "user": "tpa115k31", "type": "user"}, "name": "Xuan He", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:36.240Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620c1", "name": "Xuanti Feng", "hidden": false}, {"_id": "698d417065c0d15a6d1620c2", "name": "Xuedan Cai", "hidden": false}, {"_id": "698d417065c0d15a6d1620c3", "name": "Xuqiang Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d1620c4", "name": "Yanbo Yu", "hidden": false}, {"_id": "698d417065c0d15a6d1620c5", "name": "Yang Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620c6", "name": "Yang Xu", "hidden": false}, {"_id": "698d417065c0d15a6d1620c7", "name": "Yanlin Lai", "hidden": false}, {"_id": "698d417065c0d15a6d1620c8", "name": "Yanming Xu", "hidden": false}, {"_id": "698d417065c0d15a6d1620c9", "name": "Yaoyu Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620ca", "name": "Yeqing Shen", "hidden": false}, {"_id": "698d417065c0d15a6d1620cb", "name": "Yibo Zhu", "hidden": false}, {"_id": "698d417065c0d15a6d1620cc", "name": "Yichen Lv", "hidden": false}, {"_id": "698d417065c0d15a6d1620cd", "name": "Yicheng Cao", "hidden": false}, {"_id": "698d417065c0d15a6d1620ce", "name": "Yifeng Gong", "hidden": false}, {"_id": "698d417065c0d15a6d1620cf", "name": "Yijing Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d0", "name": "Yikun Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d1", "name": "Yin Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620d2", "name": "Yingxiu Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620d3", "name": "Yinmin Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d4", "name": "Yitong Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d5", "name": "Yixuan Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620d6", "name": "Yiyang Chen", "hidden": false}, {"_id": "698d417065c0d15a6d1620d7", "name": "Yongchi Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620d8", "name": "Yongshen Long", "hidden": false}, {"_id": "698d417065c0d15a6d1620d9", "name": "Yongyao Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620da", "name": "Yousong Guan", "hidden": false}, {"_id": "698d417065c0d15a6d1620db", "name": "Yu Zhou", "hidden": false}, {"_id": "698d417065c0d15a6d1620dc", "name": "Yuang Peng", "hidden": false}, {"_id": "698d417065c0d15a6d1620dd", "name": "Yuanhao Ding", "hidden": false}, {"_id": "698d417065c0d15a6d1620de", "name": "Yuantao Fan", "hidden": false}, {"_id": "698d417065c0d15a6d1620df", "name": "Yuanzhen Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620e0", "name": "Yuchu Luo", "hidden": false}, {"_id": "698d417065c0d15a6d1620e1", "name": "Yudi Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620e2", "name": "Yue Peng", "hidden": false}, {"_id": "698d417065c0d15a6d1620e3", "name": "Yueqiang Lin", "hidden": false}, {"_id": "698d417065c0d15a6d1620e4", "name": "Yufan Lu", "hidden": false}, {"_id": "698d417065c0d15a6d1620e5", "name": "Yuling Zhao", "hidden": false}, {"_id": "698d417065c0d15a6d1620e6", "name": "Yunzhou Ju", "hidden": false}, {"_id": "698d417065c0d15a6d1620e7", "name": "Yurong Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620e8", "name": "Yusheng Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620e9", "name": "Yuxiang Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620ea", "name": "Yuyang Chen", "hidden": false}, {"_id": "698d417065c0d15a6d1620eb", "name": "Yuzhu Cai", "hidden": false}, {"_id": "698d417065c0d15a6d1620ec", "name": "Zejia Weng", "hidden": false}, {"_id": "698d417065c0d15a6d1620ed", "name": "Zetao Hong", "hidden": false}, {"_id": "698d417065c0d15a6d1620ee", "name": "Zexi Li", "hidden": false}, {"_id": "698d417065c0d15a6d1620ef", "name": "Zhe Xie", "hidden": false}, {"_id": "698d417065c0d15a6d1620f0", "name": "Zheng Ge", "hidden": false}, {"_id": "698d417065c0d15a6d1620f1", "name": "Zheng Gong", "hidden": false}, {"_id": "698d417065c0d15a6d1620f2", "name": "Zheng Zeng", "hidden": false}, {"_id": "698d417065c0d15a6d1620f3", "user": {"_id": "63607ace9ddc44e710e13f0f", "avatarUrl": "/avatars/b5f331549562aea4a5c8b681fd9da1ff.svg", "isPro": false, "fullname": "zy", "user": "lu-vae", "type": "user"}, "name": "Zhenyi Lu", "status": "claimed_verified", "statusLastChangedAt": "2026-02-12T13:56:50.532Z", "hidden": false}, {"_id": "698d417065c0d15a6d1620f4", "name": "Zhewei Huang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f5", "name": "Zhichao Chang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f6", "name": "Zhiguo Huang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f7", "name": "Zhiheng Hu", "hidden": false}, {"_id": "698d417065c0d15a6d1620f8", "name": "Zidong Yang", "hidden": false}, {"_id": "698d417065c0d15a6d1620f9", "name": "Zili Wang", "hidden": false}, {"_id": "698d417065c0d15a6d1620fa", "name": "Ziqi Ren", "hidden": false}, {"_id": "698d417065c0d15a6d1620fb", "name": "Zixin Zhang", "hidden": false}, {"_id": "698d417065c0d15a6d1620fc", "name": "Zixuan Wang", "hidden": false}], "publishedAt": "2026-02-11T07:53:51.000Z", "submittedOnDailyAt": "2026-02-12T00:26:49.880Z", "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters", "submittedOnDailyBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "isPro": true, "fullname": "taesiri", "user": "taesiri", "type": "user"}, "summary": "We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.", "upvotes": 150, "discussionId": "698d417165c0d15a6d1620fd", "githubRepo": "https://github.com/stepfun-ai/Step-3.5-Flash", "githubRepoAddedBy": "user", "ai_summary": "Step 3.5 Flash is a sparse Mixture-of-Experts model that achieves frontier-level agentic intelligence through efficient parameter utilization and optimized attention mechanisms, demonstrating strong performance across multiple benchmarks.", "ai_keywords": ["Mixture-of-Experts", "sparse MoE", "foundation model", "active parameters", "interleaved attention", "sliding-window attention", "full attention", "Multi-Token Prediction", "reinforcement learning", "verifiable signals", "preference feedback", "off-policy training", "self-improvement", "IMO-AnswerBench", "LiveCodeBench", "tau2-Bench", "BrowseComp", "Terminal-Bench"], "githubStars": 1245, "organization": {"_id": "66e43eae9d477f566f937935", "name": "stepfun-ai", "fullname": "StepFun", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66935cee39002fc0569c2943/Qv8QPbkgoKE3wR4jTzHiy.png"}, "summary_zh": "Translation unavailable", "summary_simple": "Summary unavailable"}, "publishedAt": "2026-02-11T02:53:51.000Z", "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters", "summary": "We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.", "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.10604.png", "numComments": 3, "submittedBy": {"_id": "6039478ab3ecf716b1a5fd4d", "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg", "fullname": "taesiri", "name": "taesiri", "type": "user", "isPro": true, "isHf": false, "isHfAdmin": false, "isMod": false, "followerCount": 231, "isUserFollowing": false}, "organization": {"_id": "66e43eae9d477f566f937935", "name": "stepfun-ai", "fullname": "StepFun", "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66935cee39002fc0569c2943/Qv8QPbkgoKE3wR4jTzHiy.png"}, "isAuthorParticipating": false}]
};
window.papersLastUpdated = "Feb 28, 2026";